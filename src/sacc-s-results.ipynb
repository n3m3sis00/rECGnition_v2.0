{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"code","source":["\n","# !pip install tensorflow==2.8.0\n","!pip install efficientnet\n","!pip install --upgrade wandb\n","!pip install boto3"],"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-28T08:00:08.615364Z","iopub.execute_input":"2023-10-28T08:00:08.615663Z","iopub.status.idle":"2023-10-28T08:00:57.947647Z","shell.execute_reply.started":"2023-10-28T08:00:08.615637Z","shell.execute_reply":"2023-10-28T08:00:57.946539Z"},"trusted":true,"id":"cdKfcbyqWvr8","outputId":"8b457833-dccc-4578-968c-81413ed91f2d"},"execution_count":null,"outputs":[{"name":"stdout","text":"Collecting efficientnet\n  Downloading efficientnet-1.1.1-py3-none-any.whl (18 kB)\nCollecting keras-applications<=1.0.8,>=1.0.7 (from efficientnet)\n  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: scikit-image in /opt/conda/lib/python3.10/site-packages (from efficientnet) (0.21.0)\nRequirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.10/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.23.5)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (3.9.0)\nRequirement already satisfied: scipy>=1.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (1.11.2)\nRequirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (3.1)\nRequirement already satisfied: pillow>=9.0.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (9.5.0)\nRequirement already satisfied: imageio>=2.27 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (2.31.1)\nRequirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (2023.4.12)\nRequirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (1.4.1)\nRequirement already satisfied: packaging>=21 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (21.3)\nRequirement already satisfied: lazy_loader>=0.2 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (0.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=21->scikit-image->efficientnet) (3.0.9)\nInstalling collected packages: keras-applications, efficientnet\nSuccessfully installed efficientnet-1.1.1 keras-applications-1.0.8\nRequirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.15.9)\nCollecting wandb\n  Downloading wandb-0.15.12-py3-none-any.whl (2.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.31)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.30.0)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0)\nRequirement already satisfied: pathtools in /opt/conda/lib/python3.10/site-packages (from wandb) (0.1.2)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.2)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (68.0.0)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\nInstalling collected packages: wandb\n  Attempting uninstall: wandb\n    Found existing installation: wandb 0.15.9\n    Uninstalling wandb-0.15.9:\n      Successfully uninstalled wandb-0.15.9\nSuccessfully installed wandb-0.15.12\nRequirement already satisfied: boto3 in /opt/conda/lib/python3.10/site-packages (1.26.100)\nCollecting botocore<1.30.0,>=1.29.100 (from boto3)\n  Downloading botocore-1.29.165-py3-none-any.whl (11.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3) (1.0.1)\nRequirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from boto3) (0.6.2)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.10/site-packages (from botocore<1.30.0,>=1.29.100->boto3) (2.8.2)\nRequirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.10/site-packages (from botocore<1.30.0,>=1.29.100->boto3) (1.26.15)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.100->boto3) (1.16.0)\nInstalling collected packages: botocore\n  Attempting uninstall: botocore\n    Found existing installation: botocore 1.31.17\n    Uninstalling botocore-1.31.17:\n      Successfully uninstalled botocore-1.31.17\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\naiobotocore 2.5.4 requires botocore<1.31.18,>=1.31.17, but you have botocore 1.29.165 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed botocore-1.29.165\n","output_type":"stream"}]},{"cell_type":"code","source":["import os\n","import re\n","import random\n","import pandas as pd\n","import numpy as np\n","import json\n","import math\n","import string\n","import uuid\n","\n","\n","### Tensorflow Imports\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import roc_auc_score,confusion_matrix\n","import tensorflow as tf\n","import tensorflow.keras.backend as K\n","from tensorflow.keras.layers import Input, Conv1D, Add, Activation, Layer, \\\n","                        UpSampling1D, Input, DepthwiseConv2D, Conv2D, \\\n","                        BatchNormalization, ReLU, AvgPool2D, Flatten, Dense\n","from tensorflow.keras.applications import MobileNet\n","\n","\n","### External models\n","import efficientnet.tfkeras as efn\n","\n","\n","### Matplotlib Imports\n","import matplotlib\n","import matplotlib.pyplot as plt\n","\n","\n","### import wandb\n","import wandb\n","from wandb.keras import WandbCallback\n"],"metadata":{"execution":{"iopub.status.busy":"2023-10-28T08:00:57.950144Z","iopub.execute_input":"2023-10-28T08:00:57.950510Z","iopub.status.idle":"2023-10-28T08:01:13.626927Z","shell.execute_reply.started":"2023-10-28T08:00:57.950470Z","shell.execute_reply":"2023-10-28T08:01:13.625979Z"},"trusted":true,"id":"cY_9qeLVWvr9","outputId":"e059e531-842c-4756-86cc-96fba3fe9077"},"execution_count":null,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":["import boto3\n","import os\n","from botocore import UNSIGNED\n","from botocore.config import Config\n","\n","\n","def download_files(bucket_name, s3_prefix, local_directory):\n","    s3 = boto3.resource('s3', config=Config(signature_version=UNSIGNED))\n","    bucket = s3.Bucket(bucket_name)\n","\n","    for obj in bucket.objects.filter(Prefix=s3_prefix):\n","        local_file = os.path.join(local_directory, obj.key)\n","\n","        if not os.path.exists(os.path.dirname(local_file)):\n","            os.makedirs(os.path.dirname(local_file))\n","\n","        bucket.download_file(obj.key, local_file)\n","        print(f\"Downloaded {obj.key} to {local_file}\")\n","\n","download_files('mitdb128x128', 'train', '/content/input')"],"metadata":{"execution":{"iopub.status.busy":"2023-10-28T08:01:13.628121Z","iopub.execute_input":"2023-10-28T08:01:13.628381Z","iopub.status.idle":"2023-10-28T08:01:20.374989Z","shell.execute_reply.started":"2023-10-28T08:01:13.628358Z","shell.execute_reply":"2023-10-28T08:01:20.374068Z"},"trusted":true,"id":"pZW9Q4m6Wvr-","outputId":"4b21c007-dca4-47fe-b1bb-ec5637ab72d4"},"execution_count":null,"outputs":[{"name":"stdout","text":"Downloaded trainfile_class10_fold0_6117.tfrec to /content/input/trainfile_class10_fold0_6117.tfrec\nDownloaded trainfile_class10_fold1_6116.tfrec to /content/input/trainfile_class10_fold1_6116.tfrec\nDownloaded trainfile_class10_fold2_6116.tfrec to /content/input/trainfile_class10_fold2_6116.tfrec\nDownloaded trainfile_class10_fold3_6116.tfrec to /content/input/trainfile_class10_fold3_6116.tfrec\nDownloaded trainfile_class10_fold4_6116.tfrec to /content/input/trainfile_class10_fold4_6116.tfrec\nDownloaded trainfile_class10_fold5_6116.tfrec to /content/input/trainfile_class10_fold5_6116.tfrec\nDownloaded trainfile_class10_fold6_6116.tfrec to /content/input/trainfile_class10_fold6_6116.tfrec\nDownloaded trainfile_class10_fold7_6117.tfrec to /content/input/trainfile_class10_fold7_6117.tfrec\nDownloaded trainfile_class10_fold8_6116.tfrec to /content/input/trainfile_class10_fold8_6116.tfrec\nDownloaded trainfile_class10_fold9_6116.tfrec to /content/input/trainfile_class10_fold9_6116.tfrec\n","output_type":"stream"}]},{"cell_type":"code","source":["!ls /content/input"],"metadata":{"execution":{"iopub.status.busy":"2023-10-28T08:01:20.378292Z","iopub.execute_input":"2023-10-28T08:01:20.378588Z","iopub.status.idle":"2023-10-28T08:01:21.348979Z","shell.execute_reply.started":"2023-10-28T08:01:20.378563Z","shell.execute_reply":"2023-10-28T08:01:21.347836Z"},"trusted":true,"id":"nZkD75DIWvr-","outputId":"c6440521-1af2-4dbf-cffb-bc1fdcac54e2"},"execution_count":null,"outputs":[{"name":"stdout","text":"trainfile_class10_fold0_6117.tfrec  trainfile_class10_fold5_6116.tfrec\ntrainfile_class10_fold1_6116.tfrec  trainfile_class10_fold6_6116.tfrec\ntrainfile_class10_fold2_6116.tfrec  trainfile_class10_fold7_6117.tfrec\ntrainfile_class10_fold3_6116.tfrec  trainfile_class10_fold8_6116.tfrec\ntrainfile_class10_fold4_6116.tfrec  trainfile_class10_fold9_6116.tfrec\n","output_type":"stream"}]},{"cell_type":"code","source":["hparams = {\n","    \"backbone\" : \"b0\",\n","    \"batch_size\" : 32,\n","    \"epochs\" : 40,\n","    \"img_size\" : 128,\n","    \"lr\" : 0.01,\n","    \"optimizer\" : \"adam\",\n","    \"seed\": 257,\n","    \"notes\": \"SACC-s-dropout-changes\"\n","}"],"metadata":{"execution":{"iopub.status.busy":"2023-10-28T09:49:44.978230Z","iopub.execute_input":"2023-10-28T09:49:44.979278Z","iopub.status.idle":"2023-10-28T09:49:44.984393Z","shell.execute_reply.started":"2023-10-28T09:49:44.979238Z","shell.execute_reply":"2023-10-28T09:49:44.983202Z"},"trusted":true,"id":"ghJBwcrkWvr-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class WandBConfigurations():\n","    def __init__(self, exp_name = \"ECG_BEAT_CLASSIFICATION_PAPER_COMMENTS\"):\n","        self.EXPERIMENT_NAME = exp_name\n","        os.environ[\"WANDB_API_KEY\"] = \"221507f411c2ddcc0c17238e115a12c528a482f6\"\n","        wandb.login()\n","\n","WB = WandBConfigurations()"],"metadata":{"execution":{"iopub.status.busy":"2023-10-28T08:01:21.359469Z","iopub.execute_input":"2023-10-28T08:01:21.360578Z","iopub.status.idle":"2023-10-28T08:01:23.305843Z","shell.execute_reply.started":"2023-10-28T08:01:21.360543Z","shell.execute_reply":"2023-10-28T08:01:23.304907Z"},"trusted":true,"id":"1doiHTw9Wvr-","outputId":"660f7a00-cdd3-448d-e088-a075e20040d5"},"execution_count":null,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshreya-srivas02\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"}]},{"cell_type":"code","source":[" class Utils():\n","    def __init__(self):\n","        self.seed_everything()\n","\n","    def id_generator(size=6):\n","        return str(uuid.uuid4())[:size]\n","\n","    def setupTPU(self):\n","\n","        try:\n","            tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n","            print('Running on TPU ', tpu.cluster_spec().as_dict())\n","        except ValueError:\n","            tpu = None\n","\n","        if tpu:\n","            tf.config.experimental_connect_to_cluster(tpu)\n","            tf.tpu.experimental.initialize_tpu_system(tpu)\n","            strategy = tf.distribute.TPUStrategy(tpu)\n","            STRATEGY = strategy\n","            BATCH_SIZE = 8 * strategy.num_replicas_in_sync\n","            # wandb.config.hardware = 'TPU'\n","        else:\n","            strategy = tf.distribute.get_strategy()\n","\n","        return strategy\n","\n","    def seed_everything(self):\n","        np.random.seed(hparams['seed'])\n","        tf.random.set_seed(hparams['seed'])\n","        random.seed(a=hparams['seed'])\n","        os.environ['PYTHONHASHSEED'] = str(hparams['seed'])\n","\n","UTILS = Utils()\n","STRATEGY = UTILS.setupTPU()"],"metadata":{"execution":{"iopub.status.busy":"2023-10-28T08:01:23.307000Z","iopub.execute_input":"2023-10-28T08:01:23.307608Z","iopub.status.idle":"2023-10-28T08:01:23.326822Z","shell.execute_reply.started":"2023-10-28T08:01:23.307580Z","shell.execute_reply":"2023-10-28T08:01:23.325950Z"},"trusted":true,"id":"S4LD2bTSWvr_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["STRATEGY"],"metadata":{"execution":{"iopub.status.busy":"2023-10-28T08:01:23.327840Z","iopub.execute_input":"2023-10-28T08:01:23.328103Z","iopub.status.idle":"2023-10-28T08:01:23.336064Z","shell.execute_reply.started":"2023-10-28T08:01:23.328081Z","shell.execute_reply":"2023-10-28T08:01:23.335056Z"},"trusted":true,"id":"OWrKAkzJWvr_","outputId":"ede40055-b1e6-469c-9583-0c327c20bc06"},"execution_count":null,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy at 0x7ee4f6ca3550>"},"metadata":{}}]},{"cell_type":"code","source":["class Config():\n","    def __init__(self):\n","        self.DO_VAL_SPLIT = True\n","        self.TRAIN_FILES = sorted(tf.io.gfile.glob('/content/input/train*.tfrec'))[:-1]\n","        self.TOTAL_TRAIN_IMG = 48929\n","        self.TOTAL_VAL_IMG = 6116\n","        self.TOTAL_TEST_IMG = 6116\n","        self.BACKBONE = hparams['backbone']\n","        self.IMG_TRAIN_SHAPE = [hparams[\"img_size\"],hparams[\"img_size\"]]\n","        self.DO_FINETUNE = True\n","        self.BATCH_SIZE = hparams[\"batch_size\"] # 16\n","        self.EPOCHES = hparams[\"epochs\"]\n","        self.SEED = hparams[\"seed\"]\n","        self.LOSS = tf.keras.losses.CategoricalCrossentropy()\n","        self.OPTIMIZER = self.get_optimizer()\n","        self.ACCURACY = []\n","        self.CALLBACKS = []\n","        self.STRATEGY = STRATEGY\n","        self.FOLDS = 9\n","        self.USE_LR_SCHEDULER = True\n","        self.FOLD_NUMBER = 0\n","        self.FOLDS_DICT = {}\n","\n","        if self.USE_LR_SCHEDULER:\n","            lrfn = self.get_cosine_schedule_with_warmup(lr=hparams['lr'])\n","            lr_schedule = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=0)\n","            self.CALLBACKS.append(lr_schedule)\n","\n","    def get_optimizer(self):\n","        if hparams['optimizer'] == 'adam':\n","            return tf.keras.optimizers.Adam(learning_rate=hparams[\"lr\"])\n","        if hparams['optimizer'] == 'rmsprop':\n","            return tf.keras.optimizers.RMSprop(learning_rate=hparams[\"lr\"])\n","        if hparams['optimizer'] == 'adagrad':\n","            return tf.keras.optimizers.Adagrad(learning_rate=hparams[\"lr\"])\n","        if hparams['optimizer'] == 'adadelta':\n","            return tf.keras.optimizers.Adadelta(learning_rate=hparams[\"lr\"])\n","\n","        return tf.keras.optimizers.Adam(learning_rate=hparams[\"lr\"])\n","\n","    def get_cosine_schedule_with_warmup(\n","        self,\n","        lr = 0.00004,\n","        num_warmup_steps = 0,\n","        num_cycles=0.5):\n","        num_training_steps = self.EPOCHES\n","        def lrfn(epoch):\n","            if epoch < num_warmup_steps:\n","                return (float(epoch) / float(max(5, num_warmup_steps))) * lr\n","            progress = float(epoch - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n","            return max(0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress))) * lr\n","\n","        return lrfn\n","\n","\n","CONFIG = Config()"],"metadata":{"execution":{"iopub.status.busy":"2023-10-28T14:23:15.784710Z","iopub.execute_input":"2023-10-28T14:23:15.785483Z","iopub.status.idle":"2023-10-28T14:23:15.807055Z","shell.execute_reply.started":"2023-10-28T14:23:15.785449Z","shell.execute_reply":"2023-10-28T14:23:15.806072Z"},"trusted":true,"id":"RfXxekr1Wvr_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["CONFIG.BATCH_SIZE"],"metadata":{"execution":{"iopub.status.busy":"2023-10-28T08:01:29.638917Z","iopub.execute_input":"2023-10-28T08:01:29.639463Z","iopub.status.idle":"2023-10-28T08:01:29.647053Z","shell.execute_reply.started":"2023-10-28T08:01:29.639415Z","shell.execute_reply":"2023-10-28T08:01:29.645978Z"},"trusted":true,"id":"hhXpP1w9Wvr_","outputId":"d41ec1be-4ed7-4adb-9e8c-b527aa3f504c"},"execution_count":null,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"32"},"metadata":{}}]},{"cell_type":"code","source":["class Data():\n","    def __init__(self):\n","        self.LABELED_TFREC_FORMAT = {\n","            \"image_id\": tf.io.FixedLenFeature([], tf.string),\n","            \"image\": tf.io.FixedLenFeature([], tf.string),\n","            'target10': tf.io.FixedLenFeature([], tf.int64),\n","            'gender' : tf.io.FixedLenFeature([], tf.int64),\n","            'age_interval' : tf.io.FixedLenFeature([], tf.int64),\n","        }\n","\n","    def process_training_data(self, data_file):\n","        data = tf.io.parse_single_example(data_file, self.LABELED_TFREC_FORMAT)\n","        img = tf.image.decode_jpeg(data['image'], channels=1)\n","        img = tf.cast(img, tf.float32) / 255.0\n","        img = tf.reshape(img, [*CONFIG.IMG_TRAIN_SHAPE, 1])\n","\n","        age = tf.cast(data['age_interval'], tf.float32) / 10.0\n","        sex = tf.cast(data['gender'], tf.float32) / 1.0\n","        tab_data = [tf.cast(tfeat, dtype = tf.float32) for tfeat in [age, sex]]\n","        tabular_data = tf.stack(tab_data)\n","\n","        target10 = tf.one_hot(data['target10'], depth=10)\n","\n","        return {'inp1' : img, 'inp2' : tabular_data}, {\"target10\" : target10 }\n","\n","    def process_testing_data(self, data_file):\n","        data = tf.io.parse_single_example(data_file, self.LABELED_TFREC_FORMAT)\n","        img = tf.image.decode_jpeg(data['image'], channels=1)\n","        img = tf.cast(img, tf.float32) / 255.0\n","        img = tf.reshape(img, [*CONFIG.IMG_TRAIN_SHAPE, 1])\n","\n","        age = tf.cast(data['age_interval'], tf.float32) / 10.0\n","        sex = tf.cast(data['gender'], tf.float32) / 1.0\n","        tab_data = [tf.cast(tfeat, dtype = tf.float32) for tfeat in [age, sex]]\n","        tabular_data = tf.stack(tab_data)\n","\n","        target10 = tf.one_hot(data['target10'], depth=10)\n","        image_id = data[\"image_id\"]\n","\n","        return {'inp1' : img, 'inp2' : tabular_data}, {\"target10\" : target10, \"image_id\":  data['image_id']}\n","\n","    def val_dataset(self):\n","        ignore_order = tf.data.Options()\n","        val_dataset = (\n","            tf.data.TFRecordDataset(\n","                CONFIG.FOLDS_DICT[\"fold_{}\".format(CONFIG.FOLD_NUMBER)][\"valfiles\"],\n","                num_parallel_reads=tf.data.experimental.AUTOTUNE\n","            ).with_options(\n","                ignore_order\n","            ).map(\n","                self.process_training_data,\n","                num_parallel_calls=tf.data.experimental.AUTOTUNE\n","            ).batch(\n","                CONFIG.BATCH_SIZE\n","            ).prefetch(\n","                tf.data.experimental.AUTOTUNE\n","            )\n","        )\n","\n","        return val_dataset\n","\n","    def train_dataset(self):\n","        ignore_order = tf.data.Options()\n","        ignore_order.experimental_deterministic = False\n","        train_dataset = (\n","            tf.data.TFRecordDataset(\n","                CONFIG.FOLDS_DICT[\"fold_{}\".format(fold_number)][\"trainfiles\"],\n","                num_parallel_reads=tf.data.experimental.AUTOTUNE\n","            ).with_options(\n","                ignore_order\n","            ).map(\n","                self.process_training_data,\n","                num_parallel_calls=tf.data.experimental.AUTOTUNE\n","            ).repeat(\n","            ).shuffle(\n","                CONFIG.SEED\n","            ).batch(\n","                CONFIG.BATCH_SIZE\n","            ).prefetch(\n","                tf.data.experimental.AUTOTUNE\n","            )\n","        )\n","\n","        return train_dataset\n","\n","    def test_dataset(self):\n","        ignore_order = tf.data.Options()\n","        TEST_FILES = sorted(tf.io.gfile.glob('/content/input/train*.tfrec'))[-1]\n","        test_dataset = (\n","            tf.data.TFRecordDataset(\n","                TEST_FILES,\n","                num_parallel_reads=tf.data.experimental.AUTOTUNE\n","            ).with_options(\n","                ignore_order\n","            ).map(\n","                self.process_testing_data,\n","                num_parallel_calls=tf.data.experimental.AUTOTUNE\n","            ).batch(\n","                CONFIG.BATCH_SIZE *  4\n","            ).prefetch(\n","                tf.data.experimental.AUTOTUNE\n","            )\n","        )\n","        return test_dataset\n"],"metadata":{"execution":{"iopub.status.busy":"2023-10-28T08:01:29.648513Z","iopub.execute_input":"2023-10-28T08:01:29.648847Z","iopub.status.idle":"2023-10-28T08:01:29.936458Z","shell.execute_reply.started":"2023-10-28T08:01:29.648819Z","shell.execute_reply":"2023-10-28T08:01:29.935431Z"},"trusted":true,"id":"zX2vobrAWvsA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class SACCLayer(tf.keras.layers.Layer):\n","    def __init__(self, output_dim, **kwargs):\n","        self.output_dim = output_dim\n","        super(SACCLayer, self).__init__(**kwargs)\n","\n","    def build(self, input_shape):\n","        self.kernel_1 = self.add_weight(name='weights_ECG',\n","                                        shape=(input_shape[0][-1], self.output_dim),\n","                                        initializer='he_normal',\n","                                        trainable=True)\n","        self.kernel_2 = self.add_weight(name='weights_Patient_Metadata',\n","                                        shape=(input_shape[1][-1], self.output_dim),\n","                                        initializer='he_normal',\n","                                        trainable=True)\n","        self.attention_weights1 = self.add_weight(name='attention_weights_ECG',\n","                                                 shape=(self.output_dim,),\n","                                                 initializer='uniform',\n","                                                 trainable=True)\n","        self.attention_weights2 = self.add_weight(name='attention_weights_Patient_metadata',\n","                                                 shape=(self.output_dim,),\n","                                                 initializer='uniform',\n","                                                 trainable=True)\n","        self.dense_layer = tf.keras.layers.Dense(self.output_dim, activation='relu', name='cca_dense')\n","        super(SACCLayer, self).build(input_shape)\n","\n","    def call(self, inputs):\n","        proj_1 = K.dot(inputs[0], self.kernel_1)\n","        proj_2 = K.dot(inputs[1], self.kernel_2)\n","\n","        # Apply non-linear transformation\n","        proj_1 = tf.keras.activations.relu(proj_1)\n","        proj_2 = tf.keras.activations.relu(proj_2)\n","\n","        # Attention mechanism\n","        attention_scores1 = tf.nn.softmax(self.attention_weights1)\n","        attention_scores2 = tf.nn.softmax(self.attention_weights2)\n","        proj_1 = attention_scores1 * proj_1\n","        proj_2 = attention_scores2 * proj_2\n","\n","        # Non-linear fusion\n","        fused_representation = tf.keras.layers.concatenate([proj_1, proj_2])\n","        fused_representation = self.dense_layer(fused_representation)\n","\n","        return fused_representation\n","\n","    def compute_output_shape(self, input_shape):\n","        return (input_shape[0][0], self.output_dim)\n","\n","\n","def depthwise_separable_conv_with_residual_block(x, filters, stride):\n","    # Depthwise Convolution\n","    depthwise = DepthwiseConv2D((3, 3), strides=stride, padding='same')(x)\n","    depthwise = BatchNormalization()(depthwise)\n","    depthwise = ReLU()(depthwise)\n","\n","    # Pointwise Convolution\n","    pointwise = Conv2D(filters, (1, 1), strides=(1, 1), padding='same')(depthwise)\n","    pointwise = BatchNormalization()(pointwise)\n","    pointwise = ReLU()(pointwise)\n","\n","\n","    return pointwise\n","\n","\n","def DualPathwayModel(inp1):\n","    # Initial Convolution Layers\n","    conv1 = Conv2D(32, (3, 3), strides=(2, 2), padding='same')(inp1)\n","    conv1 = BatchNormalization()(conv1)\n","    conv1 = ReLU()(conv1)\n","\n","    conv2 = Conv2D(32, (5, 5), strides=(2, 2), padding='same')(inp1)\n","    conv2 = BatchNormalization()(conv2)\n","    conv2 = ReLU()(conv2)\n","\n","\n","    concatenated = tf.keras.layers.concatenate([conv1, conv2])\n","\n","    x = depthwise_separable_conv_with_residual_block(concatenated, 64, (1, 1))\n","    x = depthwise_separable_conv_with_residual_block(x, 128, (2, 2))\n","    x = tf.keras.layers.Dropout(0.25)(x)\n","    x = depthwise_separable_conv_with_residual_block(x, 128, (2, 2))\n","    x = depthwise_separable_conv_with_residual_block(x, 256, (2, 2))\n","    x = tf.keras.layers.Dropout(0.25)(x)\n","    x = depthwise_separable_conv_with_residual_block(x, 256, (2, 2))\n","    x = depthwise_separable_conv_with_residual_block(x, 256, (2, 2)) #<--- Can be removed\n","\n","    return x\n","\n","\n","def dpm_sacc():\n","    inp1  = tf.keras.layers.Input(shape = (*CONFIG.IMG_TRAIN_SHAPE, 1), name='inp1')\n","    inp2  = tf.keras.layers.Input(shape = (2,), name='inp2')\n","    x1 = DualPathwayModel(inp1)\n","\n","    x1 = tf.keras.layers.GlobalMaxPooling2D()(x1) # AVG is not good\n","    x1 = tf.keras.layers.Dropout(0.2)(x1)\n","\n","    x2 = tf.keras.layers.Dense(8, name='metadata_feature_dense_1', activation='relu')(inp2)\n","    x2 = tf.keras.layers.concatenate([x2, inp2])\n","\n","    x = SACCLayer(output_dim=256)([x1, x2])\n","\n","\n","    x = tf.keras.layers.Dense(128, name='combine_feature_dense_1', activation='relu')(x)\n","    x = tf.keras.layers.Dense(64, name='combine_feature_dense_2', activation='relu')(x)\n","    x = tf.keras.layers.Dropout(0.1)(x)\n","\n","    output10 = tf.keras.layers.Dense(10, activation='softmax', name='target10')(x)\n","\n","    model = tf.keras.models.Model(inputs = [inp1, inp2], outputs = [output10])\n","\n","    return model"],"metadata":{"execution":{"iopub.status.busy":"2023-10-28T14:23:25.734295Z","iopub.execute_input":"2023-10-28T14:23:25.734716Z","iopub.status.idle":"2023-10-28T14:23:25.762603Z","shell.execute_reply.started":"2023-10-28T14:23:25.734683Z","shell.execute_reply":"2023-10-28T14:23:25.761546Z"},"trusted":true,"id":"ujkozmkIWvsA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dpm_sacc().summary()"],"metadata":{"execution":{"iopub.status.busy":"2023-10-28T14:23:28.981781Z","iopub.execute_input":"2023-10-28T14:23:28.982619Z","iopub.status.idle":"2023-10-28T14:23:29.516933Z","shell.execute_reply.started":"2023-10-28T14:23:28.982569Z","shell.execute_reply":"2023-10-28T14:23:29.516054Z"},"trusted":true,"id":"rzaRPlKAWvsA","outputId":"0288355a-0188-4837-bae5-6cccc2a242b4"},"execution_count":null,"outputs":[{"name":"stdout","text":"Model: \"model_42\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n inp1 (InputLayer)              [(None, 128, 128, 1  0           []                               \n                                )]                                                                \n                                                                                                  \n conv2d_346 (Conv2D)            (None, 64, 64, 32)   320         ['inp1[0][0]']                   \n                                                                                                  \n conv2d_347 (Conv2D)            (None, 64, 64, 32)   832         ['inp1[0][0]']                   \n                                                                                                  \n batch_normalization_604 (Batch  (None, 64, 64, 32)  128         ['conv2d_346[0][0]']             \n Normalization)                                                                                   \n                                                                                                  \n batch_normalization_605 (Batch  (None, 64, 64, 32)  128         ['conv2d_347[0][0]']             \n Normalization)                                                                                   \n                                                                                                  \n re_lu_604 (ReLU)               (None, 64, 64, 32)   0           ['batch_normalization_604[0][0]']\n                                                                                                  \n re_lu_605 (ReLU)               (None, 64, 64, 32)   0           ['batch_normalization_605[0][0]']\n                                                                                                  \n concatenate_87 (Concatenate)   (None, 64, 64, 64)   0           ['re_lu_604[0][0]',              \n                                                                  're_lu_605[0][0]']              \n                                                                                                  \n depthwise_conv2d_258 (Depthwis  (None, 64, 64, 64)  640         ['concatenate_87[0][0]']         \n eConv2D)                                                                                         \n                                                                                                  \n batch_normalization_606 (Batch  (None, 64, 64, 64)  256         ['depthwise_conv2d_258[0][0]']   \n Normalization)                                                                                   \n                                                                                                  \n re_lu_606 (ReLU)               (None, 64, 64, 64)   0           ['batch_normalization_606[0][0]']\n                                                                                                  \n conv2d_348 (Conv2D)            (None, 64, 64, 64)   4160        ['re_lu_606[0][0]']              \n                                                                                                  \n batch_normalization_607 (Batch  (None, 64, 64, 64)  256         ['conv2d_348[0][0]']             \n Normalization)                                                                                   \n                                                                                                  \n re_lu_607 (ReLU)               (None, 64, 64, 64)   0           ['batch_normalization_607[0][0]']\n                                                                                                  \n depthwise_conv2d_259 (Depthwis  (None, 32, 32, 64)  640         ['re_lu_607[0][0]']              \n eConv2D)                                                                                         \n                                                                                                  \n batch_normalization_608 (Batch  (None, 32, 32, 64)  256         ['depthwise_conv2d_259[0][0]']   \n Normalization)                                                                                   \n                                                                                                  \n re_lu_608 (ReLU)               (None, 32, 32, 64)   0           ['batch_normalization_608[0][0]']\n                                                                                                  \n conv2d_349 (Conv2D)            (None, 32, 32, 128)  8320        ['re_lu_608[0][0]']              \n                                                                                                  \n batch_normalization_609 (Batch  (None, 32, 32, 128)  512        ['conv2d_349[0][0]']             \n Normalization)                                                                                   \n                                                                                                  \n re_lu_609 (ReLU)               (None, 32, 32, 128)  0           ['batch_normalization_609[0][0]']\n                                                                                                  \n dropout_171 (Dropout)          (None, 32, 32, 128)  0           ['re_lu_609[0][0]']              \n                                                                                                  \n depthwise_conv2d_260 (Depthwis  (None, 16, 16, 128)  1280       ['dropout_171[0][0]']            \n eConv2D)                                                                                         \n                                                                                                  \n batch_normalization_610 (Batch  (None, 16, 16, 128)  512        ['depthwise_conv2d_260[0][0]']   \n Normalization)                                                                                   \n                                                                                                  \n re_lu_610 (ReLU)               (None, 16, 16, 128)  0           ['batch_normalization_610[0][0]']\n                                                                                                  \n conv2d_350 (Conv2D)            (None, 16, 16, 128)  16512       ['re_lu_610[0][0]']              \n                                                                                                  \n batch_normalization_611 (Batch  (None, 16, 16, 128)  512        ['conv2d_350[0][0]']             \n Normalization)                                                                                   \n                                                                                                  \n re_lu_611 (ReLU)               (None, 16, 16, 128)  0           ['batch_normalization_611[0][0]']\n                                                                                                  \n depthwise_conv2d_261 (Depthwis  (None, 8, 8, 128)   1280        ['re_lu_611[0][0]']              \n eConv2D)                                                                                         \n                                                                                                  \n batch_normalization_612 (Batch  (None, 8, 8, 128)   512         ['depthwise_conv2d_261[0][0]']   \n Normalization)                                                                                   \n                                                                                                  \n re_lu_612 (ReLU)               (None, 8, 8, 128)    0           ['batch_normalization_612[0][0]']\n                                                                                                  \n conv2d_351 (Conv2D)            (None, 8, 8, 256)    33024       ['re_lu_612[0][0]']              \n                                                                                                  \n batch_normalization_613 (Batch  (None, 8, 8, 256)   1024        ['conv2d_351[0][0]']             \n Normalization)                                                                                   \n                                                                                                  \n re_lu_613 (ReLU)               (None, 8, 8, 256)    0           ['batch_normalization_613[0][0]']\n                                                                                                  \n dropout_172 (Dropout)          (None, 8, 8, 256)    0           ['re_lu_613[0][0]']              \n                                                                                                  \n depthwise_conv2d_262 (Depthwis  (None, 4, 4, 256)   2560        ['dropout_172[0][0]']            \n eConv2D)                                                                                         \n                                                                                                  \n batch_normalization_614 (Batch  (None, 4, 4, 256)   1024        ['depthwise_conv2d_262[0][0]']   \n Normalization)                                                                                   \n                                                                                                  \n re_lu_614 (ReLU)               (None, 4, 4, 256)    0           ['batch_normalization_614[0][0]']\n                                                                                                  \n conv2d_352 (Conv2D)            (None, 4, 4, 256)    65792       ['re_lu_614[0][0]']              \n                                                                                                  \n batch_normalization_615 (Batch  (None, 4, 4, 256)   1024        ['conv2d_352[0][0]']             \n Normalization)                                                                                   \n                                                                                                  \n re_lu_615 (ReLU)               (None, 4, 4, 256)    0           ['batch_normalization_615[0][0]']\n                                                                                                  \n depthwise_conv2d_263 (Depthwis  (None, 2, 2, 256)   2560        ['re_lu_615[0][0]']              \n eConv2D)                                                                                         \n                                                                                                  \n batch_normalization_616 (Batch  (None, 2, 2, 256)   1024        ['depthwise_conv2d_263[0][0]']   \n Normalization)                                                                                   \n                                                                                                  \n re_lu_616 (ReLU)               (None, 2, 2, 256)    0           ['batch_normalization_616[0][0]']\n                                                                                                  \n conv2d_353 (Conv2D)            (None, 2, 2, 256)    65792       ['re_lu_616[0][0]']              \n                                                                                                  \n batch_normalization_617 (Batch  (None, 2, 2, 256)   1024        ['conv2d_353[0][0]']             \n Normalization)                                                                                   \n                                                                                                  \n re_lu_617 (ReLU)               (None, 2, 2, 256)    0           ['batch_normalization_617[0][0]']\n                                                                                                  \n inp2 (InputLayer)              [(None, 2)]          0           []                               \n                                                                                                  \n global_max_pooling2d_42 (Globa  (None, 256)         0           ['re_lu_617[0][0]']              \n lMaxPooling2D)                                                                                   \n                                                                                                  \n metadata_feature_dense_1 (Dens  (None, 8)           24          ['inp2[0][0]']                   \n e)                                                                                               \n                                                                                                  \n dropout_173 (Dropout)          (None, 256)          0           ['global_max_pooling2d_42[0][0]']\n                                                                                                  \n concatenate_88 (Concatenate)   (None, 10)           0           ['metadata_feature_dense_1[0][0]'\n                                                                 , 'inp2[0][0]']                  \n                                                                                                  \n sacc_layer_42 (SACCLayer)      (None, 256)          199936      ['dropout_173[0][0]',            \n                                                                  'concatenate_88[0][0]']         \n                                                                                                  \n combine_feature_dense_1 (Dense  (None, 128)         32896       ['sacc_layer_42[0][0]']          \n )                                                                                                \n                                                                                                  \n combine_feature_dense_2 (Dense  (None, 64)          8256        ['combine_feature_dense_1[0][0]']\n )                                                                                                \n                                                                                                  \n dropout_174 (Dropout)          (None, 64)           0           ['combine_feature_dense_2[0][0]']\n                                                                                                  \n target10 (Dense)               (None, 10)           650         ['dropout_174[0][0]']            \n                                                                                                  \n==================================================================================================\nTotal params: 453,666\nTrainable params: 449,570\nNon-trainable params: 4,096\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":["def fitengine(model, traindataset, valdataset = None, istraining = True):\n","    model.compile(\n","        optimizer   =  CONFIG.OPTIMIZER,\n","        loss        =  CONFIG.LOSS,\n","        metrics     =  CONFIG.ACCURACY\n","    )\n","\n","    history = model.fit(\n","                traindataset,\n","                epochs            =   CONFIG.EPOCHES,\n","                steps_per_epoch   =   CONFIG.TOTAL_TRAIN_IMG//CONFIG.BATCH_SIZE,\n","                callbacks         =   CONFIG.CALLBACKS,\n","                validation_data   =   valdataset,\n","                validation_steps = (CONFIG.TOTAL_VAL_IMG)//(CONFIG.BATCH_SIZE) + 1,\n","                verbose           =   1\n","            )\n","\n","    return history\n","\n","skf = KFold(n_splits=CONFIG.FOLDS,shuffle=True,random_state=CONFIG.SEED)\n","for fold_number,(idxT,idxV) in enumerate(skf.split(np.arange(len(CONFIG.TRAIN_FILES)))):\n","    CONFIG.FOLDS_DICT['fold_{}'.format(fold_number)] = {\n","                                            \"trainfiles\" : [CONFIG.TRAIN_FILES[x] for x in idxT],\n","                                            \"valfiles\"   : [CONFIG.TRAIN_FILES[x] for x in idxV]\n","                                            }\n","\n","fold_number = CONFIG.FOLD_NUMBER\n","print(CONFIG.FOLDS_DICT['fold_{}'.format(fold_number)]['trainfiles'])\n","print(CONFIG.FOLDS_DICT['fold_{}'.format(fold_number)]['valfiles'])\n","\n","run_ = wandb.init(\n","    project= WB.EXPERIMENT_NAME,\n","    reinit=True,\n","    dir = \"/root\",\n","    allow_val_change = True,\n","    config = hparams\n",")\n","\n","if CONFIG.STRATEGY is not None:\n","    with CONFIG.STRATEGY.scope():\n","        x2 = tf.keras.metrics.Precision(name='precision')\n","        x3 = tf.keras.metrics.BinaryAccuracy(name='accuracy')\n","        x4 = tf.keras.metrics.Recall(name='sensitivity')\n","\n","        CONFIG.ACCURACY.append(x2)\n","        CONFIG.ACCURACY.append(x3)\n","        CONFIG.ACCURACY.append(x4)\n","\n","        model = dpm_sacc()\n","#         CONFIG.CALLBACKS.append(InLayerLossCallback())\n","else:\n","    x2 = tf.keras.metrics.Precision(name='precision')\n","    x3 = tf.keras.metrics.BinaryAccuracy(name='accuracy')\n","    x4 = tf.keras.metrics.Recall(name='sensitivity')\n","    x4 = tf.keras.metrics.Recall(name='sensitivity')\n","\n","    CONFIG.ACCURACY.append(x2)\n","    CONFIG.ACCURACY.append(x3)\n","    CONFIG.ACCURACY.append(x4)\n","\n","    model = dpm_sacc()\n","\n","CONFIG.CALLBACKS.append(tf.keras.callbacks.ModelCheckpoint(\n","                                'model-%s.h5'%(fold_number), monitor='val_loss', verbose=1, save_best_only=True,\n","                                save_weights_only=True, mode='min', save_freq='epoch'))\n","\n","CONFIG.CALLBACKS.append(WandbCallback(save_weights_only=True,\n","                                            log_weights=True,\n","                                            log_evaluation=True))\n","\n","\n","\n","\n","DATA = Data()\n","\n","print(\"##\"*30)\n","\n","history = fitengine(model, DATA.train_dataset(), valdataset=DATA.val_dataset()) #training model\n","\n","print('##'*30)"],"metadata":{"execution":{"iopub.status.busy":"2023-10-28T14:23:29.862686Z","iopub.execute_input":"2023-10-28T14:23:29.863265Z","iopub.status.idle":"2023-10-28T15:05:15.779274Z","shell.execute_reply.started":"2023-10-28T14:23:29.863234Z","shell.execute_reply":"2023-10-28T15:05:15.778238Z"},"trusted":true,"id":"gw9sevZ8WvsB","outputId":"88b4eddc-6567-484a-ae62-4e40846ad7af"},"execution_count":null,"outputs":[{"name":"stdout","text":"['/content/input/trainfile_class10_fold0_6117.tfrec', '/content/input/trainfile_class10_fold1_6116.tfrec', '/content/input/trainfile_class10_fold2_6116.tfrec', '/content/input/trainfile_class10_fold4_6116.tfrec', '/content/input/trainfile_class10_fold5_6116.tfrec', '/content/input/trainfile_class10_fold6_6116.tfrec', '/content/input/trainfile_class10_fold7_6117.tfrec', '/content/input/trainfile_class10_fold8_6116.tfrec']\n['/content/input/trainfile_class10_fold3_6116.tfrec']\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.15.12"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/root/wandb/run-20231028_142329-i5e86gxw</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/shreya-srivas02/ECG_BEAT_CLASSIFICATION_PAPER_COMMENTS/runs/i5e86gxw' target=\"_blank\">worthy-feather-190</a></strong> to <a href='https://wandb.ai/shreya-srivas02/ECG_BEAT_CLASSIFICATION_PAPER_COMMENTS' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/shreya-srivas02/ECG_BEAT_CLASSIFICATION_PAPER_COMMENTS' target=\"_blank\">https://wandb.ai/shreya-srivas02/ECG_BEAT_CLASSIFICATION_PAPER_COMMENTS</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/shreya-srivas02/ECG_BEAT_CLASSIFICATION_PAPER_COMMENTS/runs/i5e86gxw' target=\"_blank\">https://wandb.ai/shreya-srivas02/ECG_BEAT_CLASSIFICATION_PAPER_COMMENTS/runs/i5e86gxw</a>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WandbCallback is unable to log validation data. When using a generator for validation_data, you must pass validation_steps\n","output_type":"stream"},{"name":"stdout","text":"############################################################\nEpoch 1/40\n","output_type":"stream"},{"name":"stderr","text":"2023-10-28 14:24:29.488412: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_43/dropout_175/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"1529/1529 [==============================] - ETA: 0s - loss: 0.5178 - precision: 0.9011 - accuracy: 0.9721 - sensitivity: 0.8095\nEpoch 1: val_loss improved from inf to 2.64606, saving model to model-0.h5\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/wandb/run-20231028_142329-i5e86gxw/files/model-best)... Done. 0.0s\n","output_type":"stream"},{"name":"stdout","text":"1529/1529 [==============================] - 79s 43ms/step - loss: 0.5178 - precision: 0.9011 - accuracy: 0.9721 - sensitivity: 0.8095 - val_loss: 2.6461 - val_precision: 0.2515 - val_accuracy: 0.8570 - val_sensitivity: 0.2173 - lr: 0.0100\nEpoch 2/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.2668 - precision: 0.9380 - accuracy: 0.9860 - sensitivity: 0.9212\nEpoch 2: val_loss did not improve from 2.64606\n1529/1529 [==============================] - 58s 38ms/step - loss: 0.2668 - precision: 0.9380 - accuracy: 0.9860 - sensitivity: 0.9212 - val_loss: 2.7248 - val_precision: 0.2348 - val_accuracy: 0.8486 - val_sensitivity: 0.2274 - lr: 0.0100\nEpoch 3/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.2048 - precision: 0.9506 - accuracy: 0.9892 - sensitivity: 0.9406\nEpoch 3: val_loss improved from 2.64606 to 0.47921, saving model to model-0.h5\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/wandb/run-20231028_142329-i5e86gxw/files/model-best)... Done. 0.0s\n","output_type":"stream"},{"name":"stdout","text":"1529/1529 [==============================] - 66s 43ms/step - loss: 0.2048 - precision: 0.9506 - accuracy: 0.9892 - sensitivity: 0.9406 - val_loss: 0.4792 - val_precision: 0.8935 - val_accuracy: 0.9739 - val_sensitivity: 0.8385 - lr: 0.0099\nEpoch 4/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.1750 - precision: 0.9578 - accuracy: 0.9907 - sensitivity: 0.9485\nEpoch 4: val_loss improved from 0.47921 to 0.31091, saving model to model-0.h5\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/wandb/run-20231028_142329-i5e86gxw/files/model-best)... Done. 0.0s\n","output_type":"stream"},{"name":"stdout","text":"1529/1529 [==============================] - 67s 44ms/step - loss: 0.1750 - precision: 0.9578 - accuracy: 0.9907 - sensitivity: 0.9485 - val_loss: 0.3109 - val_precision: 0.9322 - val_accuracy: 0.9817 - val_sensitivity: 0.8811 - lr: 0.0099\nEpoch 5/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.1587 - precision: 0.9599 - accuracy: 0.9910 - sensitivity: 0.9497\nEpoch 5: val_loss did not improve from 0.31091\n1529/1529 [==============================] - 58s 38ms/step - loss: 0.1587 - precision: 0.9599 - accuracy: 0.9910 - sensitivity: 0.9497 - val_loss: 1.6724 - val_precision: 0.6393 - val_accuracy: 0.9172 - val_sensitivity: 0.3955 - lr: 0.0098\nEpoch 6/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.1519 - precision: 0.9625 - accuracy: 0.9915 - sensitivity: 0.9525\nEpoch 6: val_loss did not improve from 0.31091\n1529/1529 [==============================] - 58s 38ms/step - loss: 0.1519 - precision: 0.9625 - accuracy: 0.9915 - sensitivity: 0.9525 - val_loss: 1.8496 - val_precision: 0.6731 - val_accuracy: 0.9288 - val_sensitivity: 0.5608 - lr: 0.0096\nEpoch 7/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.1493 - precision: 0.9636 - accuracy: 0.9918 - sensitivity: 0.9541\nEpoch 7: val_loss did not improve from 0.31091\n1529/1529 [==============================] - 58s 38ms/step - loss: 0.1493 - precision: 0.9636 - accuracy: 0.9918 - sensitivity: 0.9541 - val_loss: 2.2172 - val_precision: 0.6078 - val_accuracy: 0.9191 - val_sensitivity: 0.5378 - lr: 0.0095\nEpoch 8/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.1349 - precision: 0.9665 - accuracy: 0.9924 - sensitivity: 0.9570\nEpoch 8: val_loss did not improve from 0.31091\n1529/1529 [==============================] - 58s 38ms/step - loss: 0.1349 - precision: 0.9665 - accuracy: 0.9924 - sensitivity: 0.9570 - val_loss: 0.6012 - val_precision: 0.8349 - val_accuracy: 0.9594 - val_sensitivity: 0.7402 - lr: 0.0093\nEpoch 9/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.1271 - precision: 0.9684 - accuracy: 0.9929 - sensitivity: 0.9602\nEpoch 9: val_loss did not improve from 0.31091\n1529/1529 [==============================] - 58s 38ms/step - loss: 0.1271 - precision: 0.9684 - accuracy: 0.9929 - sensitivity: 0.9602 - val_loss: 3.9322 - val_precision: 0.5230 - val_accuracy: 0.9046 - val_sensitivity: 0.5227 - lr: 0.0090\nEpoch 10/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.1197 - precision: 0.9696 - accuracy: 0.9932 - sensitivity: 0.9624\nEpoch 10: val_loss did not improve from 0.31091\n1529/1529 [==============================] - 58s 38ms/step - loss: 0.1197 - precision: 0.9696 - accuracy: 0.9932 - sensitivity: 0.9624 - val_loss: 3.4476 - val_precision: 0.5222 - val_accuracy: 0.9044 - val_sensitivity: 0.5222 - lr: 0.0088\nEpoch 11/40\n1528/1529 [============================>.] - ETA: 0s - loss: 0.1112 - precision: 0.9718 - accuracy: 0.9937 - sensitivity: 0.9654\nEpoch 11: val_loss did not improve from 0.31091\n1529/1529 [==============================] - 58s 38ms/step - loss: 0.1111 - precision: 0.9718 - accuracy: 0.9937 - sensitivity: 0.9654 - val_loss: 1.7409 - val_precision: 0.5791 - val_accuracy: 0.9128 - val_sensitivity: 0.4676 - lr: 0.0085\nEpoch 12/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.1132 - precision: 0.9722 - accuracy: 0.9938 - sensitivity: 0.9659\nEpoch 12: val_loss improved from 0.31091 to 0.18137, saving model to model-0.h5\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/wandb/run-20231028_142329-i5e86gxw/files/model-best)... Done. 0.0s\n","output_type":"stream"},{"name":"stdout","text":"1529/1529 [==============================] - 67s 44ms/step - loss: 0.1132 - precision: 0.9722 - accuracy: 0.9938 - sensitivity: 0.9659 - val_loss: 0.1814 - val_precision: 0.9503 - val_accuracy: 0.9895 - val_sensitivity: 0.9442 - lr: 0.0082\nEpoch 13/40\n1528/1529 [============================>.] - ETA: 0s - loss: 0.1032 - precision: 0.9734 - accuracy: 0.9941 - sensitivity: 0.9677\nEpoch 13: val_loss did not improve from 0.18137\n1529/1529 [==============================] - 58s 38ms/step - loss: 0.1031 - precision: 0.9734 - accuracy: 0.9941 - sensitivity: 0.9677 - val_loss: 1.6718 - val_precision: 0.5668 - val_accuracy: 0.9111 - val_sensitivity: 0.4711 - lr: 0.0079\nEpoch 14/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.1007 - precision: 0.9740 - accuracy: 0.9942 - sensitivity: 0.9683\nEpoch 14: val_loss did not improve from 0.18137\n1529/1529 [==============================] - 59s 39ms/step - loss: 0.1007 - precision: 0.9740 - accuracy: 0.9942 - sensitivity: 0.9683 - val_loss: 3.5885 - val_precision: 0.4625 - val_accuracy: 0.8942 - val_sensitivity: 0.3574 - lr: 0.0076\nEpoch 15/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.0936 - precision: 0.9752 - accuracy: 0.9946 - sensitivity: 0.9705\nEpoch 15: val_loss did not improve from 0.18137\n1529/1529 [==============================] - 59s 39ms/step - loss: 0.0936 - precision: 0.9752 - accuracy: 0.9946 - sensitivity: 0.9705 - val_loss: 0.7962 - val_precision: 0.8132 - val_accuracy: 0.9523 - val_sensitivity: 0.6785 - lr: 0.0073\nEpoch 16/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.0850 - precision: 0.9772 - accuracy: 0.9951 - sensitivity: 0.9733\nEpoch 16: val_loss did not improve from 0.18137\n1529/1529 [==============================] - 60s 39ms/step - loss: 0.0850 - precision: 0.9772 - accuracy: 0.9951 - sensitivity: 0.9733 - val_loss: 10.5984 - val_precision: 0.5222 - val_accuracy: 0.9044 - val_sensitivity: 0.5222 - lr: 0.0069\nEpoch 17/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.0842 - precision: 0.9774 - accuracy: 0.9951 - sensitivity: 0.9736\nEpoch 17: val_loss improved from 0.18137 to 0.12002, saving model to model-0.h5\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/wandb/run-20231028_142329-i5e86gxw/files/model-best)... Done. 0.0s\n","output_type":"stream"},{"name":"stdout","text":"1529/1529 [==============================] - 68s 44ms/step - loss: 0.0842 - precision: 0.9774 - accuracy: 0.9951 - sensitivity: 0.9736 - val_loss: 0.1200 - val_precision: 0.9697 - val_accuracy: 0.9937 - val_sensitivity: 0.9675 - lr: 0.0065\nEpoch 18/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.0816 - precision: 0.9784 - accuracy: 0.9953 - sensitivity: 0.9744\nEpoch 18: val_loss improved from 0.12002 to 0.10606, saving model to model-0.h5\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/wandb/run-20231028_142329-i5e86gxw/files/model-best)... Done. 0.0s\n","output_type":"stream"},{"name":"stdout","text":"1529/1529 [==============================] - 69s 45ms/step - loss: 0.0816 - precision: 0.9784 - accuracy: 0.9953 - sensitivity: 0.9744 - val_loss: 0.1061 - val_precision: 0.9747 - val_accuracy: 0.9946 - val_sensitivity: 0.9711 - lr: 0.0062\nEpoch 19/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.0740 - precision: 0.9802 - accuracy: 0.9957 - sensitivity: 0.9768\nEpoch 19: val_loss did not improve from 0.10606\n1529/1529 [==============================] - 60s 39ms/step - loss: 0.0740 - precision: 0.9802 - accuracy: 0.9957 - sensitivity: 0.9768 - val_loss: 0.1676 - val_precision: 0.9550 - val_accuracy: 0.9905 - val_sensitivity: 0.9503 - lr: 0.0058\nEpoch 20/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.0734 - precision: 0.9809 - accuracy: 0.9958 - sensitivity: 0.9775\nEpoch 20: val_loss did not improve from 0.10606\n1529/1529 [==============================] - 59s 39ms/step - loss: 0.0734 - precision: 0.9809 - accuracy: 0.9958 - sensitivity: 0.9775 - val_loss: 6.8633 - val_precision: 0.5222 - val_accuracy: 0.9044 - val_sensitivity: 0.5222 - lr: 0.0054\nEpoch 21/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.0687 - precision: 0.9807 - accuracy: 0.9959 - sensitivity: 0.9780\nEpoch 21: val_loss did not improve from 0.10606\n1529/1529 [==============================] - 60s 39ms/step - loss: 0.0687 - precision: 0.9807 - accuracy: 0.9959 - sensitivity: 0.9780 - val_loss: 3.1584 - val_precision: 0.6372 - val_accuracy: 0.9264 - val_sensitivity: 0.6138 - lr: 0.0050\nEpoch 22/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.0641 - precision: 0.9828 - accuracy: 0.9963 - sensitivity: 0.9800\nEpoch 22: val_loss did not improve from 0.10606\n1529/1529 [==============================] - 60s 39ms/step - loss: 0.0641 - precision: 0.9828 - accuracy: 0.9963 - sensitivity: 0.9800 - val_loss: 0.5892 - val_precision: 0.8551 - val_accuracy: 0.9676 - val_sensitivity: 0.8143 - lr: 0.0046\nEpoch 23/40\n1528/1529 [============================>.] - ETA: 0s - loss: 0.0594 - precision: 0.9838 - accuracy: 0.9965 - sensitivity: 0.9815\nEpoch 23: val_loss did not improve from 0.10606\n1529/1529 [==============================] - 60s 39ms/step - loss: 0.0594 - precision: 0.9838 - accuracy: 0.9965 - sensitivity: 0.9815 - val_loss: 0.4610 - val_precision: 0.9063 - val_accuracy: 0.9787 - val_sensitivity: 0.8774 - lr: 0.0042\nEpoch 24/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.0567 - precision: 0.9846 - accuracy: 0.9967 - sensitivity: 0.9823\nEpoch 24: val_loss did not improve from 0.10606\n1529/1529 [==============================] - 60s 39ms/step - loss: 0.0567 - precision: 0.9846 - accuracy: 0.9967 - sensitivity: 0.9823 - val_loss: 0.2696 - val_precision: 0.9327 - val_accuracy: 0.9848 - val_sensitivity: 0.9138 - lr: 0.0038\nEpoch 25/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.0541 - precision: 0.9857 - accuracy: 0.9969 - sensitivity: 0.9830\nEpoch 25: val_loss did not improve from 0.10606\n1529/1529 [==============================] - 59s 39ms/step - loss: 0.0541 - precision: 0.9857 - accuracy: 0.9969 - sensitivity: 0.9830 - val_loss: 0.7992 - val_precision: 0.8609 - val_accuracy: 0.9704 - val_sensitivity: 0.8391 - lr: 0.0035\nEpoch 26/40\n1528/1529 [============================>.] - ETA: 0s - loss: 0.0498 - precision: 0.9864 - accuracy: 0.9971 - sensitivity: 0.9845\nEpoch 26: val_loss improved from 0.10606 to 0.10279, saving model to model-0.h5\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/wandb/run-20231028_142329-i5e86gxw/files/model-best)... Done. 0.0s\n","output_type":"stream"},{"name":"stdout","text":"1529/1529 [==============================] - 67s 44ms/step - loss: 0.0498 - precision: 0.9864 - accuracy: 0.9971 - sensitivity: 0.9845 - val_loss: 0.1028 - val_precision: 0.9803 - val_accuracy: 0.9959 - val_sensitivity: 0.9783 - lr: 0.0031\nEpoch 27/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.0483 - precision: 0.9870 - accuracy: 0.9972 - sensitivity: 0.9849\nEpoch 27: val_loss did not improve from 0.10279\n1529/1529 [==============================] - 59s 38ms/step - loss: 0.0483 - precision: 0.9870 - accuracy: 0.9972 - sensitivity: 0.9849 - val_loss: 0.1355 - val_precision: 0.9708 - val_accuracy: 0.9938 - val_sensitivity: 0.9670 - lr: 0.0027\nEpoch 28/40\n1528/1529 [============================>.] - ETA: 0s - loss: 0.0454 - precision: 0.9880 - accuracy: 0.9974 - sensitivity: 0.9862\nEpoch 28: val_loss did not improve from 0.10279\n1529/1529 [==============================] - 60s 39ms/step - loss: 0.0454 - precision: 0.9880 - accuracy: 0.9974 - sensitivity: 0.9862 - val_loss: 0.1130 - val_precision: 0.9807 - val_accuracy: 0.9960 - val_sensitivity: 0.9789 - lr: 0.0024\nEpoch 29/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.0443 - precision: 0.9883 - accuracy: 0.9975 - sensitivity: 0.9864\nEpoch 29: val_loss did not improve from 0.10279\n1529/1529 [==============================] - 60s 39ms/step - loss: 0.0443 - precision: 0.9883 - accuracy: 0.9975 - sensitivity: 0.9864 - val_loss: 0.1130 - val_precision: 0.9741 - val_accuracy: 0.9946 - val_sensitivity: 0.9720 - lr: 0.0021\nEpoch 30/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.0411 - precision: 0.9885 - accuracy: 0.9975 - sensitivity: 0.9866\nEpoch 30: val_loss did not improve from 0.10279\n1529/1529 [==============================] - 60s 39ms/step - loss: 0.0411 - precision: 0.9885 - accuracy: 0.9975 - sensitivity: 0.9866 - val_loss: 0.1681 - val_precision: 0.9659 - val_accuracy: 0.9924 - val_sensitivity: 0.9575 - lr: 0.0018\nEpoch 31/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.0398 - precision: 0.9892 - accuracy: 0.9977 - sensitivity: 0.9874\nEpoch 31: val_loss did not improve from 0.10279\n1529/1529 [==============================] - 60s 39ms/step - loss: 0.0398 - precision: 0.9892 - accuracy: 0.9977 - sensitivity: 0.9874 - val_loss: 0.1060 - val_precision: 0.9746 - val_accuracy: 0.9947 - val_sensitivity: 0.9722 - lr: 0.0015\nEpoch 32/40\n1528/1529 [============================>.] - ETA: 0s - loss: 0.0365 - precision: 0.9901 - accuracy: 0.9979 - sensitivity: 0.9885\nEpoch 32: val_loss improved from 0.10279 to 0.09881, saving model to model-0.h5\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/wandb/run-20231028_142329-i5e86gxw/files/model-best)... Done. 0.0s\n","output_type":"stream"},{"name":"stdout","text":"1529/1529 [==============================] - 67s 44ms/step - loss: 0.0365 - precision: 0.9901 - accuracy: 0.9979 - sensitivity: 0.9885 - val_loss: 0.0988 - val_precision: 0.9810 - val_accuracy: 0.9961 - val_sensitivity: 0.9804 - lr: 0.0012\nEpoch 33/40\n1528/1529 [============================>.] - ETA: 0s - loss: 0.0354 - precision: 0.9898 - accuracy: 0.9978 - sensitivity: 0.9885\nEpoch 33: val_loss improved from 0.09881 to 0.09477, saving model to model-0.h5\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/wandb/run-20231028_142329-i5e86gxw/files/model-best)... Done. 0.0s\n","output_type":"stream"},{"name":"stdout","text":"1529/1529 [==============================] - 67s 44ms/step - loss: 0.0353 - precision: 0.9898 - accuracy: 0.9978 - sensitivity: 0.9885 - val_loss: 0.0948 - val_precision: 0.9839 - val_accuracy: 0.9966 - val_sensitivity: 0.9822 - lr: 9.5492e-04\nEpoch 34/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.0347 - precision: 0.9903 - accuracy: 0.9979 - sensitivity: 0.9891\nEpoch 34: val_loss did not improve from 0.09477\n1529/1529 [==============================] - 58s 38ms/step - loss: 0.0347 - precision: 0.9903 - accuracy: 0.9979 - sensitivity: 0.9891 - val_loss: 0.1026 - val_precision: 0.9792 - val_accuracy: 0.9957 - val_sensitivity: 0.9779 - lr: 7.3680e-04\nEpoch 35/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.0317 - precision: 0.9910 - accuracy: 0.9981 - sensitivity: 0.9897\nEpoch 35: val_loss did not improve from 0.09477\n1529/1529 [==============================] - 58s 38ms/step - loss: 0.0317 - precision: 0.9910 - accuracy: 0.9981 - sensitivity: 0.9897 - val_loss: 0.1033 - val_precision: 0.9771 - val_accuracy: 0.9953 - val_sensitivity: 0.9761 - lr: 5.4497e-04\nEpoch 36/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.0322 - precision: 0.9912 - accuracy: 0.9981 - sensitivity: 0.9897\nEpoch 36: val_loss did not improve from 0.09477\n1529/1529 [==============================] - 58s 38ms/step - loss: 0.0322 - precision: 0.9912 - accuracy: 0.9981 - sensitivity: 0.9897 - val_loss: 0.0984 - val_precision: 0.9843 - val_accuracy: 0.9968 - val_sensitivity: 0.9835 - lr: 3.8060e-04\nEpoch 37/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.0319 - precision: 0.9908 - accuracy: 0.9980 - sensitivity: 0.9897\nEpoch 37: val_loss improved from 0.09477 to 0.09077, saving model to model-0.h5\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/wandb/run-20231028_142329-i5e86gxw/files/model-best)... Done. 0.0s\n","output_type":"stream"},{"name":"stdout","text":"1529/1529 [==============================] - 66s 43ms/step - loss: 0.0319 - precision: 0.9908 - accuracy: 0.9980 - sensitivity: 0.9897 - val_loss: 0.0908 - val_precision: 0.9850 - val_accuracy: 0.9970 - val_sensitivity: 0.9848 - lr: 2.4472e-04\nEpoch 38/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.0309 - precision: 0.9911 - accuracy: 0.9981 - sensitivity: 0.9901\nEpoch 38: val_loss did not improve from 0.09077\n1529/1529 [==============================] - 58s 38ms/step - loss: 0.0309 - precision: 0.9911 - accuracy: 0.9981 - sensitivity: 0.9901 - val_loss: 0.0929 - val_precision: 0.9849 - val_accuracy: 0.9969 - val_sensitivity: 0.9843 - lr: 1.3815e-04\nEpoch 39/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.0301 - precision: 0.9914 - accuracy: 0.9982 - sensitivity: 0.9903\nEpoch 39: val_loss improved from 0.09077 to 0.09068, saving model to model-0.h5\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/wandb/run-20231028_142329-i5e86gxw/files/model-best)... Done. 0.0s\n","output_type":"stream"},{"name":"stdout","text":"1529/1529 [==============================] - 66s 43ms/step - loss: 0.0301 - precision: 0.9914 - accuracy: 0.9982 - sensitivity: 0.9903 - val_loss: 0.0907 - val_precision: 0.9850 - val_accuracy: 0.9970 - val_sensitivity: 0.9848 - lr: 6.1558e-05\nEpoch 40/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.0307 - precision: 0.9909 - accuracy: 0.9981 - sensitivity: 0.9897\nEpoch 40: val_loss did not improve from 0.09068\n1529/1529 [==============================] - 58s 38ms/step - loss: 0.0307 - precision: 0.9909 - accuracy: 0.9981 - sensitivity: 0.9897 - val_loss: 0.0914 - val_precision: 0.9848 - val_accuracy: 0.9970 - val_sensitivity: 0.9848 - lr: 1.5413e-05\n############################################################\n","output_type":"stream"}]},{"cell_type":"code","source":["model.save('model_last_epoch.h5')\n","model_till_last_epoch = model\n","SAVED_MODEL_LOC = \"model-0.h5\"\n","model = dpm_sacc()\n","model.load_weights(SAVED_MODEL_LOC)"],"metadata":{"execution":{"iopub.status.busy":"2023-10-28T15:05:15.781995Z","iopub.execute_input":"2023-10-28T15:05:15.782787Z","iopub.status.idle":"2023-10-28T15:05:16.492518Z","shell.execute_reply.started":"2023-10-28T15:05:15.782745Z","shell.execute_reply":"2023-10-28T15:05:16.491512Z"},"trusted":true,"id":"LlWATFYEWvsB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["NAME = ['/', \"A\",  'F', 'L', 'N', 'R', 'V', 'a', 'f', 'j']\n","for model_type, trained_model in zip(['best_epoch', 'last_epoch'], [model, model_till_last_epoch]):\n","    test_imgs = DATA.test_dataset().map(lambda data, ids: data)\n","    img_labels_ds = DATA.test_dataset().map(lambda data, ids: ids).unbatch()\n","\n","    STEPS = (CONFIG.TOTAL_TEST_IMG)//(CONFIG.BATCH_SIZE*4) + 1\n","\n","    y_pred = trained_model.predict(test_imgs,steps = int(STEPS), verbose=1)\n","    test_labels = next(iter(img_labels_ds.batch(int(CONFIG.TOTAL_TEST_IMG) + 1)))\n","    y_true = test_labels[\"target10\"].numpy()\n","    pd.DataFrame({\n","            'image_id'  : test_labels[\"image_id\"].numpy(),\n","            'actual'  : np.argmax(y_true, axis=1),\n","            'predicted'      : np.argmax(y_pred, axis=1)\n","            }).to_csv('prediction_{}.csv'.format(model_type), index=False)\n","\n","    df = pd.read_csv(\"prediction_{}.csv\".format(model_type))\n","\n","    run_.log({f\"{model_type}_pr\": wandb.plot.pr_curve(np.argmax(y_true, axis=1), y_pred, labels=NAME)})\n","    run_.log({f\"{model_type}_roc\": wandb.plot.roc_curve(np.argmax(y_true, axis=1), y_pred, labels=NAME)})\n","\n","    cm = wandb.plot.confusion_matrix(\n","                    y_true=np.argmax(y_true, axis=1),\n","                    preds=np.argmax(y_pred, axis=1),\n","                    class_names=NAME)\n","\n","    run_.log({f\"{model_type}_conf_mat\": cm})\n","\n","    harvest = confusion_matrix(df['actual'], df['predicted'])\n","    fig, ax = plt.subplots(figsize=(8,8))\n","    im = ax.imshow(harvest)\n","    ax.set_xticks(np.arange(len(NAME)))\n","    ax.set_yticks(np.arange(len(NAME)))\n","    ax.set_xticklabels(NAME)\n","    ax.set_yticklabels(NAME)\n","\n","    # Rotate the tick labels and set their alignment.\n","    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n","            rotation_mode=\"anchor\")\n","\n","    for i in range(len(NAME)):\n","        for j in range(len(NAME)):\n","            text = ax.text(j, i, harvest[i, j],\n","                        ha=\"center\", va=\"center\", color=\"w\")\n","\n","    fig.tight_layout()\n","    run_.log({f\"{model_type}_cm\": plt})\n","\n","    from sklearn.metrics import classification_report\n","    target_names = NAME\n","    x_ = classification_report(df['actual'], df['predicted'], target_names=target_names, digits=4)\n","    x2 = classification_report(df['actual'], df['predicted'], target_names=target_names, digits=4, output_dict=True)\n","    print(x_)\n","    run_.log({f\"{model_type}_CR\": x2})\n","\n","\n","## log more\n","artifact = wandb.Artifact(\"Full_Logs\", type=\"logs\")\n","artifact.add_dir(\"/kaggle/working/\")\n","wandb.log_artifact(artifact)"],"metadata":{"execution":{"iopub.status.busy":"2023-10-28T15:05:16.493831Z","iopub.execute_input":"2023-10-28T15:05:16.494160Z","iopub.status.idle":"2023-10-28T15:05:23.528238Z","shell.execute_reply.started":"2023-10-28T15:05:16.494126Z","shell.execute_reply":"2023-10-28T15:05:23.526990Z"},"trusted":true,"id":"n-zea9owWvsB","outputId":"ab94e7a7-a5fe-4c2a-c26a-0b2c18f182f1"},"execution_count":null,"outputs":[{"name":"stdout","text":"48/48 [==============================] - 1s 21ms/step\n              precision    recall  f1-score   support\n\n           /     0.9974    0.9974    0.9974       382\n           A     0.9254    0.8612    0.8922       245\n           F     0.9104    0.8026    0.8531        76\n           L     0.9975    0.9988    0.9981       801\n           N     0.9832    0.9905    0.9868      3252\n           R     0.9932    0.9915    0.9923       586\n           V     0.9678    0.9691    0.9685       713\n           a     0.6667    0.9091    0.7692        11\n           f     1.0000    1.0000    1.0000        21\n           j     0.8077    0.7241    0.7636        29\n\n    accuracy                         0.9807      6116\n   macro avg     0.9249    0.9244    0.9221      6116\nweighted avg     0.9806    0.9807    0.9805      6116\n\n48/48 [==============================] - 1s 23ms/step\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/kaggle/working)... Done. 0.0s\n","output_type":"stream"},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           /     0.9974    0.9974    0.9974       382\n           A     0.9251    0.8571    0.8898       245\n           F     0.8971    0.8026    0.8472        76\n           L     0.9975    0.9988    0.9981       801\n           N     0.9832    0.9902    0.9867      3252\n           R     0.9915    0.9915    0.9915       586\n           V     0.9678    0.9691    0.9685       713\n           a     0.6667    0.9091    0.7692        11\n           f     1.0000    1.0000    1.0000        21\n           j     0.8077    0.7241    0.7636        29\n\n    accuracy                         0.9804      6116\n   macro avg     0.9234    0.9240    0.9212      6116\nweighted avg     0.9802    0.9804    0.9802      6116\n\n","output_type":"stream"},{"execution_count":94,"output_type":"execute_result","data":{"text/plain":"<Artifact Full_Logs>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 800x800 with 1 Axes>","image/png":"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"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 800x800 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.python.framework.convert_to_constants import  convert_variables_to_constants_v2_as_graph\n","\n","\n","def get_flops(model):\n","    concrete = tf.function(lambda inputs: model(inputs))\n","    concrete_func = concrete.get_concrete_function(\n","        [tf.TensorSpec([1, *inputs.shape[1:]]) for inputs in model.inputs])\n","    frozen_func, graph_def = convert_variables_to_constants_v2_as_graph(concrete_func)\n","    with tf.Graph().as_default() as graph:\n","        tf.graph_util.import_graph_def(graph_def, name='')\n","        run_meta = tf.compat.v1.RunMetadata()\n","        opts = tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()\n","        flops = tf.compat.v1.profiler.profile(graph=graph, run_meta=run_meta, cmd=\"op\", options=opts)\n","        return flops.total_float_ops\n","\n","model = dpm_sacc()\n","\n","print(\"The FLOPs is:{}\".format(get_flops(model)) ,flush=True )\n","\n"],"metadata":{"execution":{"iopub.status.busy":"2023-10-28T15:05:23.531564Z","iopub.execute_input":"2023-10-28T15:05:23.532275Z","iopub.status.idle":"2023-10-28T15:05:24.582751Z","shell.execute_reply.started":"2023-10-28T15:05:23.532226Z","shell.execute_reply":"2023-10-28T15:05:24.579846Z"},"trusted":true,"id":"wVQcKIYEWvsB","outputId":"7164eca2-db5c-494a-c2c8-2b1398acaa66"},"execution_count":null,"outputs":[{"name":"stdout","text":"\n=========================Options=============================\n-max_depth                  10000\n-min_bytes                  0\n-min_peak_bytes             0\n-min_residual_bytes         0\n-min_output_bytes           0\n-min_micros                 0\n-min_accelerator_micros     0\n-min_cpu_micros             0\n-min_params                 0\n-min_float_ops              1\n-min_occurrence             0\n-step                       -1\n-order_by                   float_ops\n-account_type_regexes       .*\n-start_name_regexes         .*\n-trim_name_regexes          \n-show_name_regexes          .*\n-hide_name_regexes          \n-account_displayed_op_only  true\n-select                     float_ops\n-output                     stdout:\n\n==================Model Analysis Report======================\n\nDoc:\nop: The nodes are operation kernel type, such as MatMul, Conv2D. Graph nodes belonging to the same type are aggregated together.\nflops: Number of float operations. Note: Please read the implementation for the math behind it.\n\nProfile:\nnode name | # float_ops\nConv2D                   74.45m float_ops (100.00%, 89.97%)\nDepthwiseConv2dNative    6.73m float_ops (10.03%, 8.13%)\nBiasAdd                  1.08m float_ops (1.90%, 1.31%)\nMatMul                   481.57k float_ops (0.59%, 0.58%)\nSoftmax                  2.61k float_ops (0.00%, 0.00%)\nMul                        512 float_ops (0.00%, 0.00%)\n\n======================End of Report==========================\nThe FLOPs is:82745124\n","output_type":"stream"}]},{"cell_type":"code","source":["model.summary()"],"metadata":{"execution":{"iopub.status.busy":"2023-10-28T15:05:24.583996Z","iopub.execute_input":"2023-10-28T15:05:24.584337Z","iopub.status.idle":"2023-10-28T15:05:24.795636Z","shell.execute_reply.started":"2023-10-28T15:05:24.584309Z","shell.execute_reply":"2023-10-28T15:05:24.794510Z"},"trusted":true,"id":"54rUmLmgWvsC","outputId":"4309a28e-0f3c-4594-8cb1-d0e9ebc9161d"},"execution_count":null,"outputs":[{"name":"stdout","text":"Model: \"model_45\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n inp1 (InputLayer)              [(None, 128, 128, 1  0           []                               \n                                )]                                                                \n                                                                                                  \n conv2d_370 (Conv2D)            (None, 64, 64, 32)   320         ['inp1[0][0]']                   \n                                                                                                  \n conv2d_371 (Conv2D)            (None, 64, 64, 32)   832         ['inp1[0][0]']                   \n                                                                                                  \n batch_normalization_646 (Batch  (None, 64, 64, 32)  128         ['conv2d_370[0][0]']             \n Normalization)                                                                                   \n                                                                                                  \n batch_normalization_647 (Batch  (None, 64, 64, 32)  128         ['conv2d_371[0][0]']             \n Normalization)                                                                                   \n                                                                                                  \n re_lu_646 (ReLU)               (None, 64, 64, 32)   0           ['batch_normalization_646[0][0]']\n                                                                                                  \n re_lu_647 (ReLU)               (None, 64, 64, 32)   0           ['batch_normalization_647[0][0]']\n                                                                                                  \n concatenate_93 (Concatenate)   (None, 64, 64, 64)   0           ['re_lu_646[0][0]',              \n                                                                  're_lu_647[0][0]']              \n                                                                                                  \n depthwise_conv2d_276 (Depthwis  (None, 64, 64, 64)  640         ['concatenate_93[0][0]']         \n eConv2D)                                                                                         \n                                                                                                  \n batch_normalization_648 (Batch  (None, 64, 64, 64)  256         ['depthwise_conv2d_276[0][0]']   \n Normalization)                                                                                   \n                                                                                                  \n re_lu_648 (ReLU)               (None, 64, 64, 64)   0           ['batch_normalization_648[0][0]']\n                                                                                                  \n conv2d_372 (Conv2D)            (None, 64, 64, 64)   4160        ['re_lu_648[0][0]']              \n                                                                                                  \n batch_normalization_649 (Batch  (None, 64, 64, 64)  256         ['conv2d_372[0][0]']             \n Normalization)                                                                                   \n                                                                                                  \n re_lu_649 (ReLU)               (None, 64, 64, 64)   0           ['batch_normalization_649[0][0]']\n                                                                                                  \n depthwise_conv2d_277 (Depthwis  (None, 32, 32, 64)  640         ['re_lu_649[0][0]']              \n eConv2D)                                                                                         \n                                                                                                  \n batch_normalization_650 (Batch  (None, 32, 32, 64)  256         ['depthwise_conv2d_277[0][0]']   \n Normalization)                                                                                   \n                                                                                                  \n re_lu_650 (ReLU)               (None, 32, 32, 64)   0           ['batch_normalization_650[0][0]']\n                                                                                                  \n conv2d_373 (Conv2D)            (None, 32, 32, 128)  8320        ['re_lu_650[0][0]']              \n                                                                                                  \n batch_normalization_651 (Batch  (None, 32, 32, 128)  512        ['conv2d_373[0][0]']             \n Normalization)                                                                                   \n                                                                                                  \n re_lu_651 (ReLU)               (None, 32, 32, 128)  0           ['batch_normalization_651[0][0]']\n                                                                                                  \n dropout_183 (Dropout)          (None, 32, 32, 128)  0           ['re_lu_651[0][0]']              \n                                                                                                  \n depthwise_conv2d_278 (Depthwis  (None, 16, 16, 128)  1280       ['dropout_183[0][0]']            \n eConv2D)                                                                                         \n                                                                                                  \n batch_normalization_652 (Batch  (None, 16, 16, 128)  512        ['depthwise_conv2d_278[0][0]']   \n Normalization)                                                                                   \n                                                                                                  \n re_lu_652 (ReLU)               (None, 16, 16, 128)  0           ['batch_normalization_652[0][0]']\n                                                                                                  \n conv2d_374 (Conv2D)            (None, 16, 16, 128)  16512       ['re_lu_652[0][0]']              \n                                                                                                  \n batch_normalization_653 (Batch  (None, 16, 16, 128)  512        ['conv2d_374[0][0]']             \n Normalization)                                                                                   \n                                                                                                  \n re_lu_653 (ReLU)               (None, 16, 16, 128)  0           ['batch_normalization_653[0][0]']\n                                                                                                  \n depthwise_conv2d_279 (Depthwis  (None, 8, 8, 128)   1280        ['re_lu_653[0][0]']              \n eConv2D)                                                                                         \n                                                                                                  \n batch_normalization_654 (Batch  (None, 8, 8, 128)   512         ['depthwise_conv2d_279[0][0]']   \n Normalization)                                                                                   \n                                                                                                  \n re_lu_654 (ReLU)               (None, 8, 8, 128)    0           ['batch_normalization_654[0][0]']\n                                                                                                  \n conv2d_375 (Conv2D)            (None, 8, 8, 256)    33024       ['re_lu_654[0][0]']              \n                                                                                                  \n batch_normalization_655 (Batch  (None, 8, 8, 256)   1024        ['conv2d_375[0][0]']             \n Normalization)                                                                                   \n                                                                                                  \n re_lu_655 (ReLU)               (None, 8, 8, 256)    0           ['batch_normalization_655[0][0]']\n                                                                                                  \n dropout_184 (Dropout)          (None, 8, 8, 256)    0           ['re_lu_655[0][0]']              \n                                                                                                  \n depthwise_conv2d_280 (Depthwis  (None, 4, 4, 256)   2560        ['dropout_184[0][0]']            \n eConv2D)                                                                                         \n                                                                                                  \n batch_normalization_656 (Batch  (None, 4, 4, 256)   1024        ['depthwise_conv2d_280[0][0]']   \n Normalization)                                                                                   \n                                                                                                  \n re_lu_656 (ReLU)               (None, 4, 4, 256)    0           ['batch_normalization_656[0][0]']\n                                                                                                  \n conv2d_376 (Conv2D)            (None, 4, 4, 256)    65792       ['re_lu_656[0][0]']              \n                                                                                                  \n batch_normalization_657 (Batch  (None, 4, 4, 256)   1024        ['conv2d_376[0][0]']             \n Normalization)                                                                                   \n                                                                                                  \n re_lu_657 (ReLU)               (None, 4, 4, 256)    0           ['batch_normalization_657[0][0]']\n                                                                                                  \n depthwise_conv2d_281 (Depthwis  (None, 2, 2, 256)   2560        ['re_lu_657[0][0]']              \n eConv2D)                                                                                         \n                                                                                                  \n batch_normalization_658 (Batch  (None, 2, 2, 256)   1024        ['depthwise_conv2d_281[0][0]']   \n Normalization)                                                                                   \n                                                                                                  \n re_lu_658 (ReLU)               (None, 2, 2, 256)    0           ['batch_normalization_658[0][0]']\n                                                                                                  \n conv2d_377 (Conv2D)            (None, 2, 2, 256)    65792       ['re_lu_658[0][0]']              \n                                                                                                  \n batch_normalization_659 (Batch  (None, 2, 2, 256)   1024        ['conv2d_377[0][0]']             \n Normalization)                                                                                   \n                                                                                                  \n re_lu_659 (ReLU)               (None, 2, 2, 256)    0           ['batch_normalization_659[0][0]']\n                                                                                                  \n inp2 (InputLayer)              [(None, 2)]          0           []                               \n                                                                                                  \n global_max_pooling2d_45 (Globa  (None, 256)         0           ['re_lu_659[0][0]']              \n lMaxPooling2D)                                                                                   \n                                                                                                  \n metadata_feature_dense_1 (Dens  (None, 8)           24          ['inp2[0][0]']                   \n e)                                                                                               \n                                                                                                  \n dropout_185 (Dropout)          (None, 256)          0           ['global_max_pooling2d_45[0][0]']\n                                                                                                  \n concatenate_94 (Concatenate)   (None, 10)           0           ['metadata_feature_dense_1[0][0]'\n                                                                 , 'inp2[0][0]']                  \n                                                                                                  \n sacc_layer_45 (SACCLayer)      (None, 256)          199936      ['dropout_185[0][0]',            \n                                                                  'concatenate_94[0][0]']         \n                                                                                                  \n combine_feature_dense_1 (Dense  (None, 128)         32896       ['sacc_layer_45[0][0]']          \n )                                                                                                \n                                                                                                  \n combine_feature_dense_2 (Dense  (None, 64)          8256        ['combine_feature_dense_1[0][0]']\n )                                                                                                \n                                                                                                  \n dropout_186 (Dropout)          (None, 64)           0           ['combine_feature_dense_2[0][0]']\n                                                                                                  \n target10 (Dense)               (None, 10)           650         ['dropout_186[0][0]']            \n                                                                                                  \n==================================================================================================\nTotal params: 453,666\nTrainable params: 449,570\nNon-trainable params: 4,096\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":["tf.keras.utils.plot_model(\n","    dpm_sacc(),\n","    to_file='model.png',\n","    show_shapes=True,\n","    show_dtype=False,\n","    show_layer_names=False,\n","    rankdir='TB',\n","    expand_nested=False,\n","    dpi=96,\n","    layer_range=None,\n","    show_layer_activations=True,\n","    show_trainable=True\n",")\n","\n","run_.finish()"],"metadata":{"execution":{"iopub.status.busy":"2023-10-28T15:05:24.797258Z","iopub.execute_input":"2023-10-28T15:05:24.797517Z","iopub.status.idle":"2023-10-28T15:05:30.204841Z","shell.execute_reply.started":"2023-10-28T15:05:24.797494Z","shell.execute_reply":"2023-10-28T15:05:30.204064Z"},"trusted":true,"id":"dj6mOPUsWvsC","outputId":"577f02c9-d7f1-42fb-f0da-38eb1081271d","colab":{"referenced_widgets":["d4c4ed0c582649d1817aee736a91af74"]}},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='84.446 MB of 84.446 MB uploaded (0.520 MB deduped)\\r'), FloatProgress(value=1.0, m…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4c4ed0c582649d1817aee736a91af74"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████████████████</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr</td><td>███████▇▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>precision</td><td>▁▄▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇████████████████</td></tr><tr><td>sensitivity</td><td>▁▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████████████</td></tr><tr><td>val_accuracy</td><td>▁▁▇▇▄▅▄▆▄▄▄█▄▃▆▄███▄▅▇▇▇▇███████████████</td></tr><tr><td>val_loss</td><td>▃▃▁▁▂▂▂▁▄▃▂▁▂▃▁█▁▁▁▆▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_precision</td><td>▁▁▇█▅▅▄▇▄▄▄█▄▃▆▄███▄▅▇▇█▇███████████████</td></tr><tr><td>val_sensitivity</td><td>▁▁▇▇▃▄▄▆▄▄▃█▃▂▅▄███▄▅▆▇▇▇███████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.99805</td></tr><tr><td>best_epoch</td><td>38</td></tr><tr><td>best_val_loss</td><td>0.09068</td></tr><tr><td>epoch</td><td>39</td></tr><tr><td>loss</td><td>0.0307</td></tr><tr><td>lr</td><td>2e-05</td></tr><tr><td>precision</td><td>0.99085</td></tr><tr><td>sensitivity</td><td>0.98968</td></tr><tr><td>val_accuracy</td><td>0.99696</td></tr><tr><td>val_loss</td><td>0.09138</td></tr><tr><td>val_precision</td><td>0.98479</td></tr><tr><td>val_sensitivity</td><td>0.98479</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">worthy-feather-190</strong> at: <a href='https://wandb.ai/shreya-srivas02/ECG_BEAT_CLASSIFICATION_PAPER_COMMENTS/runs/i5e86gxw' target=\"_blank\">https://wandb.ai/shreya-srivas02/ECG_BEAT_CLASSIFICATION_PAPER_COMMENTS/runs/i5e86gxw</a><br/>Synced 6 W&B file(s), 9 media file(s), 66 artifact file(s) and 1 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>/root/wandb/run-20231028_142329-i5e86gxw/logs</code>"},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"L1DCLhOXWvsC"},"execution_count":null,"outputs":[]}]}