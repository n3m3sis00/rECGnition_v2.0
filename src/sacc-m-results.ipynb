{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.8.17","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# SACC-m-Results","metadata":{}},{"cell_type":"code","source":"# !pip install tensorflow==2.8.0\n!pip install efficientnet\n!pip install --upgrade wandb\n!pip install boto3","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-29T05:22:00.207810Z","iopub.execute_input":"2023-10-29T05:22:00.208101Z","iopub.status.idle":"2023-10-29T05:22:22.975580Z","shell.execute_reply.started":"2023-10-29T05:22:00.208077Z","shell.execute_reply":"2023-10-29T05:22:22.974403Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting efficientnet\n  Downloading efficientnet-1.1.1-py3-none-any.whl (18 kB)\nCollecting keras-applications<=1.0.8,>=1.0.7\n  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting scikit-image\n  Downloading scikit_image-0.21.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.9/13.9 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.8/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (3.9.0)\nRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.8/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.23.5)\nCollecting imageio>=2.27\n  Downloading imageio-2.31.6-py3-none-any.whl (313 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.2/313.2 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pillow>=9.0.1 in /usr/local/lib/python3.8/site-packages (from scikit-image->efficientnet) (10.0.0)\nCollecting tifffile>=2022.8.12\n  Downloading tifffile-2023.7.10-py3-none-any.whl (220 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.9/220.9 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: scipy>=1.8 in /usr/local/lib/python3.8/site-packages (from scikit-image->efficientnet) (1.10.1)\nCollecting PyWavelets>=1.1.1\n  Downloading PyWavelets-1.4.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.8/site-packages (from scikit-image->efficientnet) (3.1)\nRequirement already satisfied: packaging>=21 in /usr/local/lib/python3.8/site-packages (from scikit-image->efficientnet) (23.1)\nRequirement already satisfied: lazy_loader>=0.2 in /usr/local/lib/python3.8/site-packages (from scikit-image->efficientnet) (0.3)\nInstalling collected packages: tifffile, PyWavelets, imageio, scikit-image, keras-applications, efficientnet\nSuccessfully installed PyWavelets-1.4.1 efficientnet-1.1.1 imageio-2.31.6 keras-applications-1.0.8 scikit-image-0.21.0 tifffile-2023.7.10\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\nRequirement already satisfied: wandb in /usr/local/lib/python3.8/site-packages (0.12.16)\nCollecting wandb\n  Downloading wandb-0.15.12-py3-none-any.whl (2.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.8/site-packages (from wandb) (2.31.0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.8/site-packages (from wandb) (57.5.0)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/site-packages (from wandb) (4.7.1)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.8/site-packages (from wandb) (1.27.1)\nRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.8/site-packages (from wandb) (8.1.4)\nRequirement already satisfied: setproctitle in /usr/local/lib/python3.8/site-packages (from wandb) (1.3.2)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.8/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.8/site-packages (from wandb) (1.4.4)\nRequirement already satisfied: PyYAML in /usr/local/lib/python3.8/site-packages (from wandb) (6.0)\nRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.8/site-packages (from wandb) (5.9.5)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.12.0 in /usr/local/lib/python3.8/site-packages (from wandb) (4.23.4)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.8/site-packages (from wandb) (3.1.31)\nRequirement already satisfied: pathtools in /usr/local/lib/python3.8/site-packages (from wandb) (0.1.2)\nRequirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.8/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.8/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (2023.5.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (1.26.16)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (3.2.0)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\nInstalling collected packages: wandb\n  Attempting uninstall: wandb\n    Found existing installation: wandb 0.12.16\n    Uninstalling wandb-0.12.16:\n      Successfully uninstalled wandb-0.12.16\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nelegy 0.8.6 requires wandb<0.13.0,>=0.12.10, but you have wandb 0.15.12 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed wandb-0.15.12\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\nCollecting boto3\n  Downloading boto3-1.28.73-py3-none-any.whl (135 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting s3transfer<0.8.0,>=0.7.0\n  Downloading s3transfer-0.7.0-py3-none-any.whl (79 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\nCollecting botocore<1.32.0,>=1.31.73\n  Downloading botocore-1.31.73-py3-none-any.whl (11.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.8/site-packages (from botocore<1.32.0,>=1.31.73->boto3) (1.26.16)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.8/site-packages (from botocore<1.32.0,>=1.31.73->boto3) (2.8.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.32.0,>=1.31.73->boto3) (1.16.0)\nInstalling collected packages: jmespath, botocore, s3transfer, boto3\nSuccessfully installed boto3-1.28.73 botocore-1.31.73 jmespath-1.0.1 s3transfer-0.7.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport re\nimport random\nimport pandas as pd\nimport numpy as np\nimport json\nimport math\nimport string\nimport uuid\n\n\n### Tensorflow Imports\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score,confusion_matrix\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.layers import Input, Conv1D, Add, Activation, Layer, \\\n                        UpSampling1D, Input, DepthwiseConv2D, Conv2D, \\\n                        BatchNormalization, ReLU, AvgPool2D, Flatten, Dense\nfrom tensorflow.keras.applications import MobileNet\n\n\n### External models\nimport efficientnet.tfkeras as efn\n\n\n### Matplotlib Imports\nimport matplotlib\nimport matplotlib.pyplot as plt\n\n\n### import wandb\nimport wandb\nfrom wandb.keras import WandbCallback\n","metadata":{"execution":{"iopub.status.busy":"2023-10-29T05:22:22.977420Z","iopub.execute_input":"2023-10-29T05:22:22.977746Z","iopub.status.idle":"2023-10-29T05:23:04.048511Z","shell.execute_reply.started":"2023-10-29T05:22:22.977716Z","shell.execute_reply":"2023-10-29T05:23:04.047357Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"D1029 05:22:55.175467693      15 config.cc:119]                        gRPC EXPERIMENT tcp_frame_size_tuning               OFF (default:OFF)\nD1029 05:22:55.175510953      15 config.cc:119]                        gRPC EXPERIMENT tcp_rcv_lowat                       OFF (default:OFF)\nD1029 05:22:55.175515102      15 config.cc:119]                        gRPC EXPERIMENT peer_state_based_framing            OFF (default:OFF)\nD1029 05:22:55.175517763      15 config.cc:119]                        gRPC EXPERIMENT flow_control_fixes                  ON  (default:ON)\nD1029 05:22:55.175520460      15 config.cc:119]                        gRPC EXPERIMENT memory_pressure_controller          OFF (default:OFF)\nD1029 05:22:55.175523169      15 config.cc:119]                        gRPC EXPERIMENT unconstrained_max_quota_buffer_size OFF (default:OFF)\nD1029 05:22:55.175525663      15 config.cc:119]                        gRPC EXPERIMENT new_hpack_huffman_decoder           ON  (default:ON)\nD1029 05:22:55.175528213      15 config.cc:119]                        gRPC EXPERIMENT event_engine_client                 OFF (default:OFF)\nD1029 05:22:55.175530557      15 config.cc:119]                        gRPC EXPERIMENT monitoring_experiment               ON  (default:ON)\nD1029 05:22:55.175532986      15 config.cc:119]                        gRPC EXPERIMENT promise_based_client_call           OFF (default:OFF)\nD1029 05:22:55.175535227      15 config.cc:119]                        gRPC EXPERIMENT free_large_allocator                OFF (default:OFF)\nD1029 05:22:55.175537473      15 config.cc:119]                        gRPC EXPERIMENT promise_based_server_call           OFF (default:OFF)\nD1029 05:22:55.175539936      15 config.cc:119]                        gRPC EXPERIMENT transport_supplies_client_latency   OFF (default:OFF)\nD1029 05:22:55.175542300      15 config.cc:119]                        gRPC EXPERIMENT event_engine_listener               OFF (default:OFF)\nI1029 05:22:55.175785877      15 ev_epoll1_linux.cc:122]               grpc epoll fd: 62\nD1029 05:22:55.185708123      15 ev_posix.cc:144]                      Using polling engine: epoll1\nD1029 05:22:55.185737700      15 dns_resolver_ares.cc:822]             Using ares dns resolver\nD1029 05:22:55.186156712      15 lb_policy_registry.cc:46]             registering LB policy factory for \"priority_experimental\"\nD1029 05:22:55.186169375      15 lb_policy_registry.cc:46]             registering LB policy factory for \"outlier_detection_experimental\"\nD1029 05:22:55.186173494      15 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_target_experimental\"\nD1029 05:22:55.186176582      15 lb_policy_registry.cc:46]             registering LB policy factory for \"pick_first\"\nD1029 05:22:55.186179686      15 lb_policy_registry.cc:46]             registering LB policy factory for \"round_robin\"\nD1029 05:22:55.186182674      15 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_round_robin_experimental\"\nD1029 05:22:55.186191050      15 lb_policy_registry.cc:46]             registering LB policy factory for \"ring_hash_experimental\"\nD1029 05:22:55.186214936      15 lb_policy_registry.cc:46]             registering LB policy factory for \"grpclb\"\nD1029 05:22:55.186250107      15 lb_policy_registry.cc:46]             registering LB policy factory for \"rls_experimental\"\nD1029 05:22:55.186269397      15 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_manager_experimental\"\nD1029 05:22:55.186273105      15 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_impl_experimental\"\nD1029 05:22:55.186276760      15 lb_policy_registry.cc:46]             registering LB policy factory for \"cds_experimental\"\nD1029 05:22:55.186284570      15 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_resolver_experimental\"\nD1029 05:22:55.186288279      15 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_override_host_experimental\"\nD1029 05:22:55.186291901      15 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_wrr_locality_experimental\"\nD1029 05:22:55.186296873      15 certificate_provider_registry.cc:35]  registering certificate provider factory for \"file_watcher\"\nI1029 05:22:55.190047866      15 socket_utils_common_posix.cc:408]     Disabling AF_INET6 sockets because ::1 is not available.\nI1029 05:22:55.205172516     388 socket_utils_common_posix.cc:337]     TCP_USER_TIMEOUT is available. TCP_USER_TIMEOUT will be used thereafter\nE1029 05:22:55.210866129     388 oauth2_credentials.cc:236]            oauth_fetch: UNKNOWN:C-ares status is not ARES_SUCCESS qtype=A name=metadata.google.internal. is_balancer=0: Domain name not found {grpc_status:2, created_time:\"2023-10-29T05:22:55.210846195+00:00\"}\n","output_type":"stream"}]},{"cell_type":"code","source":"import boto3\nimport os\nfrom botocore import UNSIGNED\nfrom botocore.config import Config\n\n\ndef download_files(bucket_name, s3_prefix, local_directory):\n    s3 = boto3.resource('s3', config=Config(signature_version=UNSIGNED))\n    bucket = s3.Bucket(bucket_name)\n\n    for obj in bucket.objects.filter(Prefix=s3_prefix):\n        local_file = os.path.join(local_directory, obj.key)\n\n        if not os.path.exists(os.path.dirname(local_file)):\n            os.makedirs(os.path.dirname(local_file))\n\n        bucket.download_file(obj.key, local_file)\n        print(f\"Downloaded {obj.key} to {local_file}\")\n\ndownload_files('mitdb256x256', 'train', '/content/input')","metadata":{"execution":{"iopub.status.busy":"2023-10-29T05:38:44.127315Z","iopub.execute_input":"2023-10-29T05:38:44.128286Z","iopub.status.idle":"2023-10-29T05:38:46.671077Z","shell.execute_reply.started":"2023-10-29T05:38:44.128248Z","shell.execute_reply":"2023-10-29T05:38:46.669935Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Downloaded trainfile_class10_fold0_6117.tfrec to /content/input/trainfile_class10_fold0_6117.tfrec\nDownloaded trainfile_class10_fold1_6116.tfrec to /content/input/trainfile_class10_fold1_6116.tfrec\nDownloaded trainfile_class10_fold2_6116.tfrec to /content/input/trainfile_class10_fold2_6116.tfrec\nDownloaded trainfile_class10_fold3_6116.tfrec to /content/input/trainfile_class10_fold3_6116.tfrec\nDownloaded trainfile_class10_fold4_6116.tfrec to /content/input/trainfile_class10_fold4_6116.tfrec\nDownloaded trainfile_class10_fold5_6116.tfrec to /content/input/trainfile_class10_fold5_6116.tfrec\nDownloaded trainfile_class10_fold6_6116.tfrec to /content/input/trainfile_class10_fold6_6116.tfrec\nDownloaded trainfile_class10_fold7_6117.tfrec to /content/input/trainfile_class10_fold7_6117.tfrec\nDownloaded trainfile_class10_fold8_6116.tfrec to /content/input/trainfile_class10_fold8_6116.tfrec\nDownloaded trainfile_class10_fold9_6116.tfrec to /content/input/trainfile_class10_fold9_6116.tfrec\n","output_type":"stream"}]},{"cell_type":"code","source":"!ls /content/input","metadata":{"execution":{"iopub.status.busy":"2023-10-29T05:38:50.721761Z","iopub.execute_input":"2023-10-29T05:38:50.722751Z","iopub.status.idle":"2023-10-29T05:38:51.959515Z","shell.execute_reply.started":"2023-10-29T05:38:50.722676Z","shell.execute_reply":"2023-10-29T05:38:51.958153Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"trainfile_class10_fold0_6117.tfrec  trainfile_class10_fold5_6116.tfrec\ntrainfile_class10_fold1_6116.tfrec  trainfile_class10_fold6_6116.tfrec\ntrainfile_class10_fold2_6116.tfrec  trainfile_class10_fold7_6117.tfrec\ntrainfile_class10_fold3_6116.tfrec  trainfile_class10_fold8_6116.tfrec\ntrainfile_class10_fold4_6116.tfrec  trainfile_class10_fold9_6116.tfrec\n","output_type":"stream"}]},{"cell_type":"code","source":"hparams = {\n    \"backbone\" : \"b0\",\n    \"batch_size\" : 32,\n    \"epochs\" : 40,\n    \"img_size\" : 256,\n    \"lr\" : 0.01,\n    \"optimizer\" : \"adam\",\n    \"seed\": 257,\n    \"notes\": \"MobileNet-base\"\n}","metadata":{"execution":{"iopub.status.busy":"2023-10-29T05:23:11.356437Z","iopub.execute_input":"2023-10-29T05:23:11.356721Z","iopub.status.idle":"2023-10-29T05:23:11.361785Z","shell.execute_reply.started":"2023-10-29T05:23:11.356693Z","shell.execute_reply":"2023-10-29T05:23:11.360975Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class WandBConfigurations():\n    def __init__(self, exp_name = \"ECG_BEAT_CLASSIFICATION_PAPER_COMMENTS\"):\n        self.EXPERIMENT_NAME = exp_name\n        os.environ[\"WANDB_API_KEY\"] = \"221507f411c2ddcc0c17238e115a12c528a482f6\"\n        wandb.login()\n\nWB = WandBConfigurations()","metadata":{"execution":{"iopub.status.busy":"2023-10-29T05:23:11.362865Z","iopub.execute_input":"2023-10-29T05:23:11.363141Z","iopub.status.idle":"2023-10-29T05:23:13.377034Z","shell.execute_reply.started":"2023-10-29T05:23:11.363106Z","shell.execute_reply":"2023-10-29T05:23:13.375731Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshreya-srivas02\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"}]},{"cell_type":"code","source":" class Utils():\n    def __init__(self):\n        self.seed_everything()\n\n    def id_generator(size=6):\n        return str(uuid.uuid4())[:size]\n\n    def setupTPU(self):\n\n        try:\n            tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n            print('Running on TPU ', tpu.cluster_spec().as_dict())\n        except ValueError:\n            tpu = None\n\n        if tpu:\n            tf.config.experimental_connect_to_cluster(tpu)\n            tf.tpu.experimental.initialize_tpu_system(tpu)\n            strategy = tf.distribute.TPUStrategy(tpu)\n            STRATEGY = strategy\n            BATCH_SIZE = 8 * strategy.num_replicas_in_sync\n            # wandb.config.hardware = 'TPU'\n        else:\n            strategy = tf.distribute.get_strategy()\n            \n        return strategy\n\n    def seed_everything(self):\n        np.random.seed(hparams['seed'])\n        tf.random.set_seed(hparams['seed'])\n        random.seed(a=hparams['seed'])\n        os.environ['PYTHONHASHSEED'] = str(hparams['seed'])\n\nUTILS = Utils()\nSTRATEGY = UTILS.setupTPU()","metadata":{"execution":{"iopub.status.busy":"2023-10-29T05:23:13.378640Z","iopub.execute_input":"2023-10-29T05:23:13.379281Z","iopub.status.idle":"2023-10-29T05:23:20.951250Z","shell.execute_reply.started":"2023-10-29T05:23:13.379240Z","shell.execute_reply":"2023-10-29T05:23:20.950159Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Running on TPU  {}\nINFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\nINFO:tensorflow:Initializing the TPU system: local\nINFO:tensorflow:Finished initializing TPU system.\nINFO:tensorflow:Found TPU system:\nINFO:tensorflow:*** Num TPU Cores: 8\nINFO:tensorflow:*** Num TPU Workers: 1\nINFO:tensorflow:*** Num TPU Cores Per Worker: 8\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:0, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:1, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:2, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:3, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:4, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:5, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:6, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:7, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n","output_type":"stream"}]},{"cell_type":"code","source":"STRATEGY","metadata":{"execution":{"iopub.status.busy":"2023-10-29T05:23:20.952470Z","iopub.execute_input":"2023-10-29T05:23:20.952759Z","iopub.status.idle":"2023-10-29T05:23:20.961061Z","shell.execute_reply.started":"2023-10-29T05:23:20.952734Z","shell.execute_reply":"2023-10-29T05:23:20.960159Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.distribute.tpu_strategy.TPUStrategyV2 at 0x7d8d84faffd0>"},"metadata":{}}]},{"cell_type":"code","source":"class Config():\n    def __init__(self):\n        self.DO_VAL_SPLIT = True\n        self.TRAIN_FILES = sorted(tf.io.gfile.glob('/content/input/train*.tfrec'))[:-1]\n        self.TOTAL_TRAIN_IMG = 48929\n        self.TOTAL_VAL_IMG = 6116\n        self.TOTAL_TEST_IMG = 6116\n        self.BACKBONE = hparams['backbone']\n        self.IMG_TRAIN_SHAPE = [hparams[\"img_size\"],hparams[\"img_size\"]]\n        self.DO_FINETUNE = True\n        self.BATCH_SIZE = hparams[\"batch_size\"] # 16\n        self.EPOCHES = hparams[\"epochs\"]\n        self.SEED = hparams[\"seed\"]\n        self.LOSS = tf.keras.losses.CategoricalCrossentropy()\n        self.OPTIMIZER = self.get_optimizer()\n        self.ACCURACY = []\n        self.CALLBACKS = []\n        self.STRATEGY = STRATEGY\n        self.FOLDS = 9\n        self.USE_LR_SCHEDULER = True\n        self.FOLD_NUMBER = 0\n        self.FOLDS_DICT = {}\n\n        if self.USE_LR_SCHEDULER:\n            lrfn = self.get_cosine_schedule_with_warmup(lr=hparams['lr'])\n            lr_schedule = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=0)\n            self.CALLBACKS.append(lr_schedule)\n\n    def get_optimizer(self):\n        if hparams['optimizer'] == 'adam':\n            return tf.keras.optimizers.Adam(learning_rate=hparams[\"lr\"])\n        if hparams['optimizer'] == 'rmsprop':\n            return tf.keras.optimizers.RMSprop(learning_rate=hparams[\"lr\"])\n        if hparams['optimizer'] == 'adagrad':\n            return tf.keras.optimizers.Adagrad(learning_rate=hparams[\"lr\"])\n        if hparams['optimizer'] == 'adadelta':\n            return tf.keras.optimizers.Adadelta(learning_rate=hparams[\"lr\"])\n\n        return tf.keras.optimizers.Adam(learning_rate=hparams[\"lr\"])\n\n    def get_cosine_schedule_with_warmup(\n        self,\n        lr = 0.00004,\n        num_warmup_steps = 0,\n        num_cycles=0.5):\n        num_training_steps = self.EPOCHES\n        def lrfn(epoch):\n            if epoch < num_warmup_steps:\n                return (float(epoch) / float(max(5, num_warmup_steps))) * lr\n            progress = float(epoch - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n            return max(0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress))) * lr\n\n        return lrfn\n\n\nCONFIG = Config()","metadata":{"execution":{"iopub.status.busy":"2023-10-29T05:38:56.255673Z","iopub.execute_input":"2023-10-29T05:38:56.256740Z","iopub.status.idle":"2023-10-29T05:38:56.281250Z","shell.execute_reply.started":"2023-10-29T05:38:56.256701Z","shell.execute_reply":"2023-10-29T05:38:56.280269Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"CONFIG.BATCH_SIZE","metadata":{"execution":{"iopub.status.busy":"2023-10-29T05:23:20.996658Z","iopub.execute_input":"2023-10-29T05:23:20.996948Z","iopub.status.idle":"2023-10-29T05:23:21.002275Z","shell.execute_reply.started":"2023-10-29T05:23:20.996925Z","shell.execute_reply":"2023-10-29T05:23:21.001426Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"32"},"metadata":{}}]},{"cell_type":"code","source":"class Data():\n    def __init__(self):\n        self.LABELED_TFREC_FORMAT = {\n            \"image_id\": tf.io.FixedLenFeature([], tf.string),\n            \"image\": tf.io.FixedLenFeature([], tf.string),\n            'target10': tf.io.FixedLenFeature([], tf.int64),\n            'gender' : tf.io.FixedLenFeature([], tf.int64),\n            'age_interval' : tf.io.FixedLenFeature([], tf.int64),\n        }\n\n    def process_training_data(self, data_file):\n        data = tf.io.parse_single_example(data_file, self.LABELED_TFREC_FORMAT)\n        img = tf.image.decode_jpeg(data['image'], channels=1)\n        img = tf.cast(img, tf.float32) / 255.0\n        img = tf.reshape(img, [*CONFIG.IMG_TRAIN_SHAPE, 1])\n\n        age = tf.cast(data['age_interval'], tf.float32) / 10.0\n        sex = tf.cast(data['gender'], tf.float32) / 1.0\n        tab_data = [tf.cast(tfeat, dtype = tf.float32) for tfeat in [age, sex]]\n        tabular_data = tf.stack(tab_data)\n\n        target10 = tf.one_hot(data['target10'], depth=10)\n\n        return {'inp1' : img, 'inp2' : tabular_data}, {\"target10\" : target10 }\n\n    def process_testing_data(self, data_file):\n        data = tf.io.parse_single_example(data_file, self.LABELED_TFREC_FORMAT)\n        img = tf.image.decode_jpeg(data['image'], channels=1)\n        img = tf.cast(img, tf.float32) / 255.0\n        img = tf.reshape(img, [*CONFIG.IMG_TRAIN_SHAPE, 1])\n\n        age = tf.cast(data['age_interval'], tf.float32) / 10.0\n        sex = tf.cast(data['gender'], tf.float32) / 1.0\n        tab_data = [tf.cast(tfeat, dtype = tf.float32) for tfeat in [age, sex]]\n        tabular_data = tf.stack(tab_data)\n\n        target10 = tf.one_hot(data['target10'], depth=10)\n        image_id = data[\"image_id\"]\n\n        return {'inp1' : img, 'inp2' : tabular_data}, {\"target10\" : target10, \"image_id\":  data['image_id']}\n\n    def val_dataset(self):\n        ignore_order = tf.data.Options()\n        val_dataset = (\n            tf.data.TFRecordDataset(\n                CONFIG.FOLDS_DICT[\"fold_{}\".format(CONFIG.FOLD_NUMBER)][\"valfiles\"],\n                num_parallel_reads=tf.data.experimental.AUTOTUNE\n            ).with_options(\n                ignore_order\n            ).map(\n                self.process_training_data,\n                num_parallel_calls=tf.data.experimental.AUTOTUNE\n            ).batch(\n                CONFIG.BATCH_SIZE\n            ).prefetch(\n                tf.data.experimental.AUTOTUNE\n            )\n        )\n\n        return val_dataset\n\n    def train_dataset(self):\n        ignore_order = tf.data.Options()\n        ignore_order.experimental_deterministic = False\n        train_dataset = (\n            tf.data.TFRecordDataset(\n                CONFIG.FOLDS_DICT[\"fold_{}\".format(fold_number)][\"trainfiles\"],\n                num_parallel_reads=tf.data.experimental.AUTOTUNE\n            ).with_options(\n                ignore_order\n            ).map(\n                self.process_training_data,\n                num_parallel_calls=tf.data.experimental.AUTOTUNE\n            ).repeat(\n            ).shuffle(\n                CONFIG.SEED\n            ).batch(\n                CONFIG.BATCH_SIZE\n            ).prefetch(\n                tf.data.experimental.AUTOTUNE\n            )\n        )\n\n        return train_dataset\n\n    def test_dataset(self):\n        ignore_order = tf.data.Options()\n        TEST_FILES = sorted(tf.io.gfile.glob('/content/input/train*.tfrec'))[-1]\n        test_dataset = (\n            tf.data.TFRecordDataset(\n                TEST_FILES,\n                num_parallel_reads=tf.data.experimental.AUTOTUNE\n            ).with_options(\n                ignore_order\n            ).map(\n                self.process_testing_data,\n                num_parallel_calls=tf.data.experimental.AUTOTUNE\n            ).batch(\n                CONFIG.BATCH_SIZE *  4\n            ).prefetch(\n                tf.data.experimental.AUTOTUNE\n            )\n        )\n        return test_dataset\n","metadata":{"execution":{"iopub.status.busy":"2023-10-29T05:23:21.003304Z","iopub.execute_input":"2023-10-29T05:23:21.003561Z","iopub.status.idle":"2023-10-29T05:23:21.025881Z","shell.execute_reply.started":"2023-10-29T05:23:21.003539Z","shell.execute_reply":"2023-10-29T05:23:21.025034Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"class SACCLayer(tf.keras.layers.Layer):\n    def __init__(self, output_dim, **kwargs):\n        self.output_dim = output_dim\n        super(SACCLayer, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        self.kernel_1 = self.add_weight(name='weights_ECG',\n                                        shape=(input_shape[0][-1], self.output_dim),\n                                        initializer='he_normal',\n                                        trainable=True)\n        self.kernel_2 = self.add_weight(name='weights_Patient_Metadata',\n                                        shape=(input_shape[1][-1], self.output_dim),\n                                        initializer='he_normal',\n                                        trainable=True)\n        self.attention_weights1 = self.add_weight(name='attention_weights_ECG',\n                                                 shape=(self.output_dim,),\n                                                 initializer='uniform',\n                                                 trainable=True)\n        self.attention_weights2 = self.add_weight(name='attention_weights_Patient_metadata',\n                                                 shape=(self.output_dim,),\n                                                 initializer='uniform',\n                                                 trainable=True)\n        self.dense_layer = tf.keras.layers.Dense(self.output_dim, activation='relu', name='cca_dense')\n        super(SACCLayer, self).build(input_shape)\n\n    def call(self, inputs):\n        proj_1 = K.dot(inputs[0], self.kernel_1)\n        proj_2 = K.dot(inputs[1], self.kernel_2)\n\n        # Apply non-linear transformation\n        proj_1 = tf.keras.activations.relu(proj_1)\n        proj_2 = tf.keras.activations.relu(proj_2)\n\n        # Attention mechanism\n        attention_scores1 = tf.nn.softmax(self.attention_weights1)\n        attention_scores2 = tf.nn.softmax(self.attention_weights2)\n        proj_1 = attention_scores1 * proj_1\n        proj_2 = attention_scores2 * proj_2\n\n        # Non-linear fusion\n        fused_representation = tf.keras.layers.concatenate([proj_1, proj_2])\n        fused_representation = self.dense_layer(fused_representation)\n\n        return fused_representation\n\n    def compute_output_shape(self, input_shape):\n        return (input_shape[0][0], self.output_dim)\n\n\ndef depthwise_separable_conv_with_residual_block(x, filters, stride):\n    # Depthwise Convolution\n    depthwise = DepthwiseConv2D((3, 3), strides=stride, padding='same')(x)\n    depthwise = BatchNormalization()(depthwise)\n    depthwise = ReLU()(depthwise)\n\n    # Pointwise Convolution\n    pointwise = Conv2D(filters, (1, 1), strides=(1, 1), padding='same')(depthwise)\n    pointwise = BatchNormalization()(pointwise)\n    pointwise = ReLU()(pointwise)\n\n\n    return pointwise\n\n\ndef DualPathwayModel(inp1):\n    # Initial Convolution Layers\n    conv1 = Conv2D(32, (3, 3), strides=(2, 2), padding='same')(inp1)\n    conv1 = BatchNormalization()(conv1)\n    conv1 = ReLU()(conv1)\n    \n    conv1 = Conv2D(32, (3, 3), strides=(2, 2), padding='same')(conv1)\n    conv1 = BatchNormalization()(conv1)\n    conv1 = ReLU()(conv1)\n\n\n    conv2 = Conv2D(32, (5, 5), strides=(2, 2), padding='same')(inp1)\n    conv2 = BatchNormalization()(conv2)\n    conv2 = ReLU()(conv2)\n    \n    conv2 = Conv2D(32, (7, 7), strides=(2, 2), padding='same')(conv2)\n    conv2 = BatchNormalization()(conv2)\n    conv2 = ReLU()(conv2)\n\n\n    concatenated = tf.keras.layers.concatenate([conv1, conv2])\n\n    x = depthwise_separable_conv_with_residual_block(concatenated, 64, (1, 1))\n    x = depthwise_separable_conv_with_residual_block(x, 64, (2, 2))\n    x = depthwise_separable_conv_with_residual_block(x, 128, (1, 1))\n    x = tf.keras.layers.Dropout(0.3)(x)\n    x = depthwise_separable_conv_with_residual_block(x, 128, (2, 2))\n    x = depthwise_separable_conv_with_residual_block(x, 256, (1, 1))\n    x = tf.keras.layers.Dropout(0.3)(x)\n    x = depthwise_separable_conv_with_residual_block(x, 256, (2, 2))\n    x = depthwise_separable_conv_with_residual_block(x, 256, (2, 2))\n    x = tf.keras.layers.Dropout(0.3)(x)\n    x = depthwise_separable_conv_with_residual_block(x, 512, (1, 1))\n    x = depthwise_separable_conv_with_residual_block(x, 512, (2, 2))\n\n    return x\n\n    \ndef dpm_sacc():\n    inp1  = tf.keras.layers.Input(shape = (*CONFIG.IMG_TRAIN_SHAPE, 1), name='inp1')\n    inp2  = tf.keras.layers.Input(shape = (2,), name='inp2')\n    x1 = DualPathwayModel(inp1)\n\n    x1 = tf.keras.layers.GlobalMaxPooling2D()(x1) # AVG is not good\n    x1 = tf.keras.layers.Dropout(0.2)(x1)\n\n    x2 = tf.keras.layers.Dense(8, name='metadata_feature_dense_1', activation='relu')(inp2)\n    x2 = tf.keras.layers.concatenate([x2, inp2])\n\n    x = SACCLayer(output_dim=512)([x1, x2])\n    \n    \n    x = tf.keras.layers.Dense(128, name='combine_feature_dense_1', activation='relu')(x)\n    x = tf.keras.layers.Dense(64, name='combine_feature_dense_2', activation='relu')(x)\n    x = tf.keras.layers.Dropout(0.1)(x)\n\n    output10 = tf.keras.layers.Dense(10, activation='softmax', name='target10')(x)\n\n    model = tf.keras.models.Model(inputs = [inp1, inp2], outputs = [output10])\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-10-29T05:23:21.026998Z","iopub.execute_input":"2023-10-29T05:23:21.027241Z","iopub.status.idle":"2023-10-29T05:23:21.052090Z","shell.execute_reply.started":"2023-10-29T05:23:21.027220Z","shell.execute_reply":"2023-10-29T05:23:21.051218Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"dpm_sacc().summary()","metadata":{"execution":{"iopub.status.busy":"2023-10-29T05:23:21.053149Z","iopub.execute_input":"2023-10-29T05:23:21.053414Z","iopub.status.idle":"2023-10-29T05:23:21.856086Z","shell.execute_reply.started":"2023-10-29T05:23:21.053392Z","shell.execute_reply":"2023-10-29T05:23:21.846944Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n inp1 (InputLayer)              [(None, 256, 256, 1  0           []                               \n                                )]                                                                \n                                                                                                  \n conv2d (Conv2D)                (None, 128, 128, 32  320         ['inp1[0][0]']                   \n                                )                                                                 \n                                                                                                  \n conv2d_2 (Conv2D)              (None, 128, 128, 32  832         ['inp1[0][0]']                   \n                                )                                                                 \n                                                                                                  \n batch_normalization (BatchNorm  (None, 128, 128, 32  128        ['conv2d[0][0]']                 \n alization)                     )                                                                 \n                                                                                                  \n batch_normalization_2 (BatchNo  (None, 128, 128, 32  128        ['conv2d_2[0][0]']               \n rmalization)                   )                                                                 \n                                                                                                  \n re_lu (ReLU)                   (None, 128, 128, 32  0           ['batch_normalization[0][0]']    \n                                )                                                                 \n                                                                                                  \n re_lu_2 (ReLU)                 (None, 128, 128, 32  0           ['batch_normalization_2[0][0]']  \n                                )                                                                 \n                                                                                                  \n conv2d_1 (Conv2D)              (None, 64, 64, 32)   9248        ['re_lu[0][0]']                  \n                                                                                                  \n conv2d_3 (Conv2D)              (None, 64, 64, 32)   50208       ['re_lu_2[0][0]']                \n                                                                                                  \n batch_normalization_1 (BatchNo  (None, 64, 64, 32)  128         ['conv2d_1[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n batch_normalization_3 (BatchNo  (None, 64, 64, 32)  128         ['conv2d_3[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n re_lu_1 (ReLU)                 (None, 64, 64, 32)   0           ['batch_normalization_1[0][0]']  \n                                                                                                  \n re_lu_3 (ReLU)                 (None, 64, 64, 32)   0           ['batch_normalization_3[0][0]']  \n                                                                                                  \n concatenate (Concatenate)      (None, 64, 64, 64)   0           ['re_lu_1[0][0]',                \n                                                                  're_lu_3[0][0]']                \n                                                                                                  \n depthwise_conv2d (DepthwiseCon  (None, 64, 64, 64)  640         ['concatenate[0][0]']            \n v2D)                                                                                             \n                                                                                                  \n batch_normalization_4 (BatchNo  (None, 64, 64, 64)  256         ['depthwise_conv2d[0][0]']       \n rmalization)                                                                                     \n                                                                                                  \n re_lu_4 (ReLU)                 (None, 64, 64, 64)   0           ['batch_normalization_4[0][0]']  \n                                                                                                  \n conv2d_4 (Conv2D)              (None, 64, 64, 64)   4160        ['re_lu_4[0][0]']                \n                                                                                                  \n batch_normalization_5 (BatchNo  (None, 64, 64, 64)  256         ['conv2d_4[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n re_lu_5 (ReLU)                 (None, 64, 64, 64)   0           ['batch_normalization_5[0][0]']  \n                                                                                                  \n depthwise_conv2d_1 (DepthwiseC  (None, 32, 32, 64)  640         ['re_lu_5[0][0]']                \n onv2D)                                                                                           \n                                                                                                  \n batch_normalization_6 (BatchNo  (None, 32, 32, 64)  256         ['depthwise_conv2d_1[0][0]']     \n rmalization)                                                                                     \n                                                                                                  \n re_lu_6 (ReLU)                 (None, 32, 32, 64)   0           ['batch_normalization_6[0][0]']  \n                                                                                                  \n conv2d_5 (Conv2D)              (None, 32, 32, 64)   4160        ['re_lu_6[0][0]']                \n                                                                                                  \n batch_normalization_7 (BatchNo  (None, 32, 32, 64)  256         ['conv2d_5[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n re_lu_7 (ReLU)                 (None, 32, 32, 64)   0           ['batch_normalization_7[0][0]']  \n                                                                                                  \n depthwise_conv2d_2 (DepthwiseC  (None, 32, 32, 64)  640         ['re_lu_7[0][0]']                \n onv2D)                                                                                           \n                                                                                                  \n batch_normalization_8 (BatchNo  (None, 32, 32, 64)  256         ['depthwise_conv2d_2[0][0]']     \n rmalization)                                                                                     \n                                                                                                  \n re_lu_8 (ReLU)                 (None, 32, 32, 64)   0           ['batch_normalization_8[0][0]']  \n                                                                                                  \n conv2d_6 (Conv2D)              (None, 32, 32, 128)  8320        ['re_lu_8[0][0]']                \n                                                                                                  \n batch_normalization_9 (BatchNo  (None, 32, 32, 128)  512        ['conv2d_6[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n re_lu_9 (ReLU)                 (None, 32, 32, 128)  0           ['batch_normalization_9[0][0]']  \n                                                                                                  \n dropout (Dropout)              (None, 32, 32, 128)  0           ['re_lu_9[0][0]']                \n                                                                                                  \n depthwise_conv2d_3 (DepthwiseC  (None, 16, 16, 128)  1280       ['dropout[0][0]']                \n onv2D)                                                                                           \n                                                                                                  \n batch_normalization_10 (BatchN  (None, 16, 16, 128)  512        ['depthwise_conv2d_3[0][0]']     \n ormalization)                                                                                    \n                                                                                                  \n re_lu_10 (ReLU)                (None, 16, 16, 128)  0           ['batch_normalization_10[0][0]'] \n                                                                                                  \n conv2d_7 (Conv2D)              (None, 16, 16, 128)  16512       ['re_lu_10[0][0]']               \n                                                                                                  \n batch_normalization_11 (BatchN  (None, 16, 16, 128)  512        ['conv2d_7[0][0]']               \n ormalization)                                                                                    \n                                                                                                  \n re_lu_11 (ReLU)                (None, 16, 16, 128)  0           ['batch_normalization_11[0][0]'] \n                                                                                                  \n depthwise_conv2d_4 (DepthwiseC  (None, 16, 16, 128)  1280       ['re_lu_11[0][0]']               \n onv2D)                                                                                           \n                                                                                                  \n batch_normalization_12 (BatchN  (None, 16, 16, 128)  512        ['depthwise_conv2d_4[0][0]']     \n ormalization)                                                                                    \n                                                                                                  \n re_lu_12 (ReLU)                (None, 16, 16, 128)  0           ['batch_normalization_12[0][0]'] \n ormalization)                                                                                    \n                                                                                                  \n re_lu_12 (ReLU)                (None, 16, 16, 128)  0           ['batch_normalization_12[0][0]'] \n                                                                                                  \n conv2d_8 (Conv2D)              (None, 16, 16, 256)  33024       ['re_lu_12[0][0]']               \n                                                                                                  \n batch_normalization_13 (BatchN  (None, 16, 16, 256)  1024       ['conv2d_8[0][0]']               \n ormalization)                                                                                    \n                                                                                                  \n re_lu_13 (ReLU)                (None, 16, 16, 256)  0           ['batch_normalization_13[0][0]'] \n                                                                                                  \n dropout_1 (Dropout)            (None, 16, 16, 256)  0           ['re_lu_13[0][0]']               \n                                                                                                  \n depthwise_conv2d_5 (DepthwiseC  (None, 8, 8, 256)   2560        ['dropout_1[0][0]']              \n onv2D)                                                                                           \n                                                                                                  \n batch_normalization_14 (BatchN  (None, 8, 8, 256)   1024        ['depthwise_conv2d_5[0][0]']     \n ormalization)                                                                                    \n                                                                                                  \n re_lu_14 (ReLU)                (None, 8, 8, 256)    0           ['batch_normalization_14[0][0]'] \n                                                                                                  \n conv2d_9 (Conv2D)              (None, 8, 8, 256)    65792       ['re_lu_14[0][0]']               \n                                                                                                  \n batch_normalization_15 (BatchN  (None, 8, 8, 256)   1024        ['conv2d_9[0][0]']               \n ormalization)                                                                                    \n                                                                                                  \n re_lu_15 (ReLU)                (None, 8, 8, 256)    0           ['batch_normalization_15[0][0]'] \n                                                                                                  \n depthwise_conv2d_6 (DepthwiseC  (None, 4, 4, 256)   2560        ['re_lu_15[0][0]']               \n onv2D)                                                                                           \n                                                                                                  \n batch_normalization_16 (BatchN  (None, 4, 4, 256)   1024        ['depthwise_conv2d_6[0][0]']     \n ormalization)                                                                                    \n                                                                                                  \n re_lu_16 (ReLU)                (None, 4, 4, 256)    0           ['batch_normalization_16[0][0]'] \n                                                                                                  \n conv2d_10 (Conv2D)             (None, 4, 4, 256)    65792       ['re_lu_16[0][0]']               \n                                                                                                  \n batch_normalization_17 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_10[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n re_lu_17 (ReLU)                (None, 4, 4, 256)    0           ['batch_normalization_17[0][0]'] \n                                                                                                  \n dropout_2 (Dropout)            (None, 4, 4, 256)    0           ['re_lu_17[0][0]']               \n                                                                                                  \n depthwise_conv2d_7 (DepthwiseC  (None, 4, 4, 256)   2560        ['dropout_2[0][0]']              \n onv2D)                                                                                           \n                                                                                                  \n batch_normalization_18 (BatchN  (None, 4, 4, 256)   1024        ['depthwise_conv2d_7[0][0]']     \n ormalization)                                                                                    \n                                                                                                  \n re_lu_18 (ReLU)                (None, 4, 4, 256)    0           ['batch_normalization_18[0][0]'] \n                                                                                                  \n conv2d_11 (Conv2D)             (None, 4, 4, 512)    131584      ['re_lu_18[0][0]']               \n                                                                                                  \n batch_normalization_19 (BatchN  (None, 4, 4, 512)   2048        ['conv2d_11[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n re_lu_19 (ReLU)                (None, 4, 4, 512)    0           ['batch_normalization_19[0][0]'] \n                                                                                                  \n depthwise_conv2d_8 (DepthwiseC  (None, 2, 2, 512)   5120        ['re_lu_19[0][0]']               \n onv2D)                                                                                           \n                                                                                                  \n ormalization)                                                                                    \n                                                                                                  \n re_lu_21 (ReLU)                (None, 2, 2, 512)    0           ['batch_normalization_21[0][0]'] \n                                                                                                  \n inp2 (InputLayer)              [(None, 2)]          0           []                               \n                                                                                                  \n global_max_pooling2d (GlobalMa  (None, 512)         0           ['re_lu_21[0][0]']               \n xPooling2D)                                                                                      \n                                                                                                  \n metadata_feature_dense_1 (Dens  (None, 8)           24          ['inp2[0][0]']                   \n e)                                                                                               \n                                                                                                  \n dropout_3 (Dropout)            (None, 512)          0           ['global_max_pooling2d[0][0]']   \n                                                                                                  \n concatenate_1 (Concatenate)    (None, 10)           0           ['metadata_feature_dense_1[0][0]'\n                                                                 , 'inp2[0][0]']                  \n                                                                                                  \n sacc_layer (SACCLayer)         (None, 512)          793088      ['dropout_3[0][0]',              \n                                                                  'concatenate_1[0][0]']          \n                                                                                                  \n combine_feature_dense_1 (Dense  (None, 128)         65664       ['sacc_layer[0][0]']             \n )                                                                                                \n                                                                                                  \n combine_feature_dense_2 (Dense  (None, 64)          8256        ['combine_feature_dense_1[0][0]']\n )                                                                                                \n                                                                                                  \n dropout_4 (Dropout)            (None, 64)           0           ['combine_feature_dense_2[0][0]']\n                                                                                                  \n target10 (Dense)               (None, 10)           650         ['dropout_4[0][0]']              \n                                                                                                  \n==================================================================================================\nTotal params: 1,553,698\nTrainable params: 1,545,634\nNon-trainable params: 8,064\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"def fitengine(model, traindataset, valdataset = None, istraining = True):\n    model.compile(\n        optimizer   =  CONFIG.OPTIMIZER,\n        loss        =  CONFIG.LOSS,\n        metrics     =  CONFIG.ACCURACY\n    )\n\n    history = model.fit(\n                traindataset,\n                epochs            =   CONFIG.EPOCHES,\n                steps_per_epoch   =   CONFIG.TOTAL_TRAIN_IMG//CONFIG.BATCH_SIZE,\n                callbacks         =   CONFIG.CALLBACKS,\n                validation_data   =   valdataset,\n                validation_steps = (CONFIG.TOTAL_VAL_IMG)//(CONFIG.BATCH_SIZE) + 1,\n                verbose           =   1\n            )\n\n    return history\n\nskf = KFold(n_splits=CONFIG.FOLDS,shuffle=True,random_state=CONFIG.SEED)\nfor fold_number,(idxT,idxV) in enumerate(skf.split(np.arange(len(CONFIG.TRAIN_FILES)))):\n    CONFIG.FOLDS_DICT['fold_{}'.format(fold_number)] = {\n                                            \"trainfiles\" : [CONFIG.TRAIN_FILES[x] for x in idxT],\n                                            \"valfiles\"   : [CONFIG.TRAIN_FILES[x] for x in idxV]\n                                            }\n\nfold_number = CONFIG.FOLD_NUMBER\nprint(CONFIG.FOLDS_DICT['fold_{}'.format(fold_number)]['trainfiles'])\nprint(CONFIG.FOLDS_DICT['fold_{}'.format(fold_number)]['valfiles'])\n\nrun_ = wandb.init(\n    project= WB.EXPERIMENT_NAME,\n    reinit=True,\n    dir = \"/root\",\n    allow_val_change = True,\n    config = hparams\n)\n\nif CONFIG.STRATEGY is not None:\n    with CONFIG.STRATEGY.scope():\n        x2 = tf.keras.metrics.Precision(name='precision')\n        x3 = tf.keras.metrics.BinaryAccuracy(name='accuracy')\n        x4 = tf.keras.metrics.Recall(name='sensitivity')\n\n        CONFIG.ACCURACY.append(x2)\n        CONFIG.ACCURACY.append(x3)\n        CONFIG.ACCURACY.append(x4)\n\n        model = dpm_sacc()\n#         CONFIG.CALLBACKS.append(InLayerLossCallback())\nelse:\n    x2 = tf.keras.metrics.Precision(name='precision')\n    x3 = tf.keras.metrics.BinaryAccuracy(name='accuracy')\n    x4 = tf.keras.metrics.Recall(name='sensitivity')\n    x4 = tf.keras.metrics.Recall(name='sensitivity')\n\n    CONFIG.ACCURACY.append(x2)\n    CONFIG.ACCURACY.append(x3)\n    CONFIG.ACCURACY.append(x4)\n\n    model = dpm_sacc()\n\nCONFIG.CALLBACKS.append(tf.keras.callbacks.ModelCheckpoint(\n                                'model-%s.h5'%(fold_number), monitor='val_loss', verbose=1, save_best_only=True,\n                                save_weights_only=True, mode='min', save_freq='epoch'))\n\nCONFIG.CALLBACKS.append(WandbCallback(save_weights_only=True,\n                                            log_weights=True,\n                                            log_evaluation=True))\n\n\n\n\nDATA = Data()\n\nprint(\"##\"*30)\n\nhistory = fitengine(model, DATA.train_dataset(), valdataset=DATA.val_dataset()) #training model\n\nprint('##'*30)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T05:39:04.007993Z","iopub.execute_input":"2023-10-29T05:39:04.009091Z","iopub.status.idle":"2023-10-29T06:14:23.260873Z","shell.execute_reply.started":"2023-10-29T05:39:04.009061Z","shell.execute_reply":"2023-10-29T06:14:23.259676Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"['/content/input/trainfile_class10_fold0_6117.tfrec', '/content/input/trainfile_class10_fold1_6116.tfrec', '/content/input/trainfile_class10_fold2_6116.tfrec', '/content/input/trainfile_class10_fold4_6116.tfrec', '/content/input/trainfile_class10_fold5_6116.tfrec', '/content/input/trainfile_class10_fold6_6116.tfrec', '/content/input/trainfile_class10_fold7_6117.tfrec', '/content/input/trainfile_class10_fold8_6116.tfrec']\n['/content/input/trainfile_class10_fold3_6116.tfrec']\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Finishing last run (ID:d8x4td8u) before initializing another..."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">jumping-cherry-197</strong> at: <a href='https://wandb.ai/shreya-srivas02/ECG_BEAT_CLASSIFICATION_PAPER_COMMENTS/runs/d8x4td8u' target=\"_blank\">https://wandb.ai/shreya-srivas02/ECG_BEAT_CLASSIFICATION_PAPER_COMMENTS/runs/d8x4td8u</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>/root/wandb/run-20231029_052321-d8x4td8u/logs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Successfully finished last run (ID:d8x4td8u). Initializing new run:<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.15.12"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/root/wandb/run-20231029_053904-a09wy3h6</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/shreya-srivas02/ECG_BEAT_CLASSIFICATION_PAPER_COMMENTS/runs/a09wy3h6' target=\"_blank\">flowing-jazz-198</a></strong> to <a href='https://wandb.ai/shreya-srivas02/ECG_BEAT_CLASSIFICATION_PAPER_COMMENTS' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/shreya-srivas02/ECG_BEAT_CLASSIFICATION_PAPER_COMMENTS' target=\"_blank\">https://wandb.ai/shreya-srivas02/ECG_BEAT_CLASSIFICATION_PAPER_COMMENTS</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/shreya-srivas02/ECG_BEAT_CLASSIFICATION_PAPER_COMMENTS/runs/a09wy3h6' target=\"_blank\">https://wandb.ai/shreya-srivas02/ECG_BEAT_CLASSIFICATION_PAPER_COMMENTS/runs/a09wy3h6</a>"},"metadata":{}},{"name":"stdout","text":"############################################################\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WandbCallback is unable to log validation data. When using a generator for validation_data, you must pass validation_steps\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/40\n","output_type":"stream"},{"name":"stderr","text":"2023-10-29 05:39:25.303511: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Add_204/ReadVariableOp.\n2023-10-29 05:39:25.648463: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Add_204/ReadVariableOp.\n","output_type":"stream"},{"name":"stdout","text":"1529/1529 [==============================] - ETA: 0s - loss: 0.6049 - precision: 0.8765 - accuracy: 0.9662 - sensitivity: 0.7704","output_type":"stream"},{"name":"stderr","text":"2023-10-29 05:40:21.471037: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Add/ReadVariableOp.\n2023-10-29 05:40:21.652479: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Add/ReadVariableOp.\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_loss improved from inf to 0.28973, saving model to model-0.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 25). These functions will not be directly callable after loading.\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Assets written to: /root/wandb/run-20231029_053904-a09wy3h6/files/model-best/assets\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Assets written to: /root/wandb/run-20231029_053904-a09wy3h6/files/model-best/assets\n\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/wandb/run-20231029_053904-a09wy3h6/files/model-best)... Done. 0.1s\n","output_type":"stream"},{"name":"stdout","text":"1529/1529 [==============================] - 90s 42ms/step - loss: 0.6049 - precision: 0.8765 - accuracy: 0.9662 - sensitivity: 0.7704 - val_loss: 0.2897 - val_precision: 0.9307 - val_accuracy: 0.9856 - val_sensitivity: 0.9245 - lr: 0.0100\nEpoch 2/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.3137 - precision: 0.9274 - accuracy: 0.9835 - sensitivity: 0.9057\nEpoch 2: val_loss improved from 0.28973 to 0.24863, saving model to model-0.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 25). These functions will not be directly callable after loading.\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Assets written to: /root/wandb/run-20231029_053904-a09wy3h6/files/model-best/assets\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Assets written to: /root/wandb/run-20231029_053904-a09wy3h6/files/model-best/assets\n\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/wandb/run-20231029_053904-a09wy3h6/files/model-best)... Done. 0.1s\n","output_type":"stream"},{"name":"stdout","text":"1529/1529 [==============================] - 57s 37ms/step - loss: 0.3137 - precision: 0.9274 - accuracy: 0.9835 - sensitivity: 0.9057 - val_loss: 0.2486 - val_precision: 0.9407 - val_accuracy: 0.9872 - val_sensitivity: 0.9310 - lr: 0.0100\nEpoch 3/40\n1528/1529 [============================>.] - ETA: 0s - loss: 0.2580 - precision: 0.9381 - accuracy: 0.9864 - sensitivity: 0.9255\nEpoch 3: val_loss improved from 0.24863 to 0.22762, saving model to model-0.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 25). These functions will not be directly callable after loading.\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Assets written to: /root/wandb/run-20231029_053904-a09wy3h6/files/model-best/assets\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Assets written to: /root/wandb/run-20231029_053904-a09wy3h6/files/model-best/assets\n\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/wandb/run-20231029_053904-a09wy3h6/files/model-best)... Done. 0.1s\n","output_type":"stream"},{"name":"stdout","text":"1529/1529 [==============================] - 58s 38ms/step - loss: 0.2581 - precision: 0.9381 - accuracy: 0.9864 - sensitivity: 0.9255 - val_loss: 0.2276 - val_precision: 0.9466 - val_accuracy: 0.9890 - val_sensitivity: 0.9428 - lr: 0.0099\nEpoch 4/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.2322 - precision: 0.9433 - accuracy: 0.9878 - sensitivity: 0.9339\nEpoch 4: val_loss improved from 0.22762 to 0.20218, saving model to model-0.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 25). These functions will not be directly callable after loading.\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Assets written to: /root/wandb/run-20231029_053904-a09wy3h6/files/model-best/assets\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Assets written to: /root/wandb/run-20231029_053904-a09wy3h6/files/model-best/assets\n\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/wandb/run-20231029_053904-a09wy3h6/files/model-best)... Done. 0.1s\n","output_type":"stream"},{"name":"stdout","text":"1529/1529 [==============================] - 58s 38ms/step - loss: 0.2322 - precision: 0.9433 - accuracy: 0.9878 - sensitivity: 0.9339 - val_loss: 0.2022 - val_precision: 0.9500 - val_accuracy: 0.9898 - val_sensitivity: 0.9475 - lr: 0.0099\nEpoch 5/40\n1528/1529 [============================>.] - ETA: 0s - loss: 0.2166 - precision: 0.9462 - accuracy: 0.9885 - sensitivity: 0.9384\nEpoch 5: val_loss did not improve from 0.20218\n1529/1529 [==============================] - 43s 28ms/step - loss: 0.2165 - precision: 0.9462 - accuracy: 0.9885 - sensitivity: 0.9384 - val_loss: 0.2464 - val_precision: 0.9348 - val_accuracy: 0.9866 - val_sensitivity: 0.9305 - lr: 0.0098\nEpoch 6/40\n1528/1529 [============================>.] - ETA: 0s - loss: 0.2094 - precision: 0.9478 - accuracy: 0.9888 - sensitivity: 0.9398\nEpoch 6: val_loss improved from 0.20218 to 0.19224, saving model to model-0.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 25). These functions will not be directly callable after loading.\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Assets written to: /root/wandb/run-20231029_053904-a09wy3h6/files/model-best/assets\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Assets written to: /root/wandb/run-20231029_053904-a09wy3h6/files/model-best/assets\n\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/wandb/run-20231029_053904-a09wy3h6/files/model-best)... Done. 0.2s\n","output_type":"stream"},{"name":"stdout","text":"1529/1529 [==============================] - 58s 38ms/step - loss: 0.2093 - precision: 0.9478 - accuracy: 0.9888 - sensitivity: 0.9398 - val_loss: 0.1922 - val_precision: 0.9555 - val_accuracy: 0.9908 - val_sensitivity: 0.9524 - lr: 0.0096\nEpoch 7/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.1973 - precision: 0.9500 - accuracy: 0.9894 - sensitivity: 0.9434\nEpoch 7: val_loss improved from 0.19224 to 0.18636, saving model to model-0.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 25). These functions will not be directly callable after loading.\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Assets written to: /root/wandb/run-20231029_053904-a09wy3h6/files/model-best/assets\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Assets written to: /root/wandb/run-20231029_053904-a09wy3h6/files/model-best/assets\n\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/wandb/run-20231029_053904-a09wy3h6/files/model-best)... Done. 0.1s\n","output_type":"stream"},{"name":"stdout","text":"1529/1529 [==============================] - 56s 37ms/step - loss: 0.1973 - precision: 0.9500 - accuracy: 0.9894 - sensitivity: 0.9434 - val_loss: 0.1864 - val_precision: 0.9541 - val_accuracy: 0.9903 - val_sensitivity: 0.9485 - lr: 0.0095\nEpoch 8/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.1990 - precision: 0.9501 - accuracy: 0.9893 - sensitivity: 0.9425\nEpoch 8: val_loss did not improve from 0.18636\n1529/1529 [==============================] - 43s 28ms/step - loss: 0.1990 - precision: 0.9501 - accuracy: 0.9893 - sensitivity: 0.9425 - val_loss: 0.2003 - val_precision: 0.9510 - val_accuracy: 0.9901 - val_sensitivity: 0.9496 - lr: 0.0093\nEpoch 9/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.1786 - precision: 0.9530 - accuracy: 0.9901 - sensitivity: 0.9473\nEpoch 9: val_loss did not improve from 0.18636\n1529/1529 [==============================] - 43s 28ms/step - loss: 0.1786 - precision: 0.9530 - accuracy: 0.9901 - sensitivity: 0.9473 - val_loss: 0.1882 - val_precision: 0.9532 - val_accuracy: 0.9903 - val_sensitivity: 0.9493 - lr: 0.0090\nEpoch 10/40\n1528/1529 [============================>.] - ETA: 0s - loss: 0.1717 - precision: 0.9550 - accuracy: 0.9905 - sensitivity: 0.9497\nEpoch 10: val_loss improved from 0.18636 to 0.16985, saving model to model-0.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 25). These functions will not be directly callable after loading.\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Assets written to: /root/wandb/run-20231029_053904-a09wy3h6/files/model-best/assets\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Assets written to: /root/wandb/run-20231029_053904-a09wy3h6/files/model-best/assets\n\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/wandb/run-20231029_053904-a09wy3h6/files/model-best)... Done. 0.1s\n","output_type":"stream"},{"name":"stdout","text":"1529/1529 [==============================] - 58s 38ms/step - loss: 0.1717 - precision: 0.9550 - accuracy: 0.9905 - sensitivity: 0.9497 - val_loss: 0.1699 - val_precision: 0.9595 - val_accuracy: 0.9917 - val_sensitivity: 0.9577 - lr: 0.0088\nEpoch 11/40\n1528/1529 [============================>.] - ETA: 0s - loss: 0.1735 - precision: 0.9555 - accuracy: 0.9904 - sensitivity: 0.9487\nEpoch 11: val_loss improved from 0.16985 to 0.16286, saving model to model-0.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 25). These functions will not be directly callable after loading.\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Assets written to: /root/wandb/run-20231029_053904-a09wy3h6/files/model-best/assets\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Assets written to: /root/wandb/run-20231029_053904-a09wy3h6/files/model-best/assets\n\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/wandb/run-20231029_053904-a09wy3h6/files/model-best)... Done. 0.1s\n","output_type":"stream"},{"name":"stdout","text":"1529/1529 [==============================] - 58s 38ms/step - loss: 0.1735 - precision: 0.9555 - accuracy: 0.9904 - sensitivity: 0.9487 - val_loss: 0.1629 - val_precision: 0.9603 - val_accuracy: 0.9918 - val_sensitivity: 0.9577 - lr: 0.0085\nEpoch 12/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.1665 - precision: 0.9575 - accuracy: 0.9909 - sensitivity: 0.9512\nEpoch 12: val_loss improved from 0.16286 to 0.15970, saving model to model-0.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 25). These functions will not be directly callable after loading.\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Assets written to: /root/wandb/run-20231029_053904-a09wy3h6/files/model-best/assets\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Assets written to: /root/wandb/run-20231029_053904-a09wy3h6/files/model-best/assets\n\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/wandb/run-20231029_053904-a09wy3h6/files/model-best)... Done. 0.1s\n","output_type":"stream"},{"name":"stdout","text":"1529/1529 [==============================] - 59s 39ms/step - loss: 0.1665 - precision: 0.9575 - accuracy: 0.9909 - sensitivity: 0.9512 - val_loss: 0.1597 - val_precision: 0.9605 - val_accuracy: 0.9918 - val_sensitivity: 0.9577 - lr: 0.0082\nEpoch 13/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.1640 - precision: 0.9561 - accuracy: 0.9907 - sensitivity: 0.9501\nEpoch 13: val_loss improved from 0.15970 to 0.14055, saving model to model-0.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 25). These functions will not be directly callable after loading.\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Assets written to: /root/wandb/run-20231029_053904-a09wy3h6/files/model-best/assets\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Assets written to: /root/wandb/run-20231029_053904-a09wy3h6/files/model-best/assets\n\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/wandb/run-20231029_053904-a09wy3h6/files/model-best)... Done. 0.1s\n","output_type":"stream"},{"name":"stdout","text":"1529/1529 [==============================] - 59s 39ms/step - loss: 0.1640 - precision: 0.9561 - accuracy: 0.9907 - sensitivity: 0.9501 - val_loss: 0.1406 - val_precision: 0.9603 - val_accuracy: 0.9919 - val_sensitivity: 0.9581 - lr: 0.0079\nEpoch 14/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.1543 - precision: 0.9580 - accuracy: 0.9910 - sensitivity: 0.9522\nEpoch 14: val_loss did not improve from 0.14055\n1529/1529 [==============================] - 43s 28ms/step - loss: 0.1543 - precision: 0.9580 - accuracy: 0.9910 - sensitivity: 0.9522 - val_loss: 0.1474 - val_precision: 0.9598 - val_accuracy: 0.9917 - val_sensitivity: 0.9568 - lr: 0.0076\nEpoch 15/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.1478 - precision: 0.9590 - accuracy: 0.9912 - sensitivity: 0.9527\nEpoch 15: val_loss improved from 0.14055 to 0.13759, saving model to model-0.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 25). These functions will not be directly callable after loading.\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Assets written to: /root/wandb/run-20231029_053904-a09wy3h6/files/model-best/assets\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Assets written to: /root/wandb/run-20231029_053904-a09wy3h6/files/model-best/assets\n\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/wandb/run-20231029_053904-a09wy3h6/files/model-best)... Done. 0.1s\n","output_type":"stream"},{"name":"stdout","text":"1529/1529 [==============================] - 58s 38ms/step - loss: 0.1478 - precision: 0.9590 - accuracy: 0.9912 - sensitivity: 0.9527 - val_loss: 0.1376 - val_precision: 0.9625 - val_accuracy: 0.9919 - val_sensitivity: 0.9565 - lr: 0.0073\nEpoch 16/40\n1528/1529 [============================>.] - ETA: 0s - loss: 0.1420 - precision: 0.9608 - accuracy: 0.9916 - sensitivity: 0.9547\nEpoch 16: val_loss did not improve from 0.13759\n1529/1529 [==============================] - 44s 29ms/step - loss: 0.1420 - precision: 0.9608 - accuracy: 0.9916 - sensitivity: 0.9548 - val_loss: 0.1393 - val_precision: 0.9581 - val_accuracy: 0.9911 - val_sensitivity: 0.9523 - lr: 0.0069\nEpoch 17/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.1308 - precision: 0.9640 - accuracy: 0.9923 - sensitivity: 0.9584\nEpoch 17: val_loss improved from 0.13759 to 0.12964, saving model to model-0.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 25). These functions will not be directly callable after loading.\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Assets written to: /root/wandb/run-20231029_053904-a09wy3h6/files/model-best/assets\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Assets written to: /root/wandb/run-20231029_053904-a09wy3h6/files/model-best/assets\n\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/wandb/run-20231029_053904-a09wy3h6/files/model-best)... Done. 0.1s\n","output_type":"stream"},{"name":"stdout","text":"1529/1529 [==============================] - 59s 38ms/step - loss: 0.1308 - precision: 0.9640 - accuracy: 0.9923 - sensitivity: 0.9584 - val_loss: 0.1296 - val_precision: 0.9641 - val_accuracy: 0.9925 - val_sensitivity: 0.9611 - lr: 0.0065\nEpoch 18/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.1242 - precision: 0.9665 - accuracy: 0.9928 - sensitivity: 0.9610\nEpoch 18: val_loss improved from 0.12964 to 0.11117, saving model to model-0.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 25). These functions will not be directly callable after loading.\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Assets written to: /root/wandb/run-20231029_053904-a09wy3h6/files/model-best/assets\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Assets written to: /root/wandb/run-20231029_053904-a09wy3h6/files/model-best/assets\n\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/wandb/run-20231029_053904-a09wy3h6/files/model-best)... Done. 0.1s\n","output_type":"stream"},{"name":"stdout","text":"1529/1529 [==============================] - 58s 38ms/step - loss: 0.1242 - precision: 0.9665 - accuracy: 0.9928 - sensitivity: 0.9610 - val_loss: 0.1112 - val_precision: 0.9715 - val_accuracy: 0.9941 - val_sensitivity: 0.9699 - lr: 0.0062\nEpoch 19/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.1157 - precision: 0.9694 - accuracy: 0.9935 - sensitivity: 0.9654\nEpoch 19: val_loss improved from 0.11117 to 0.10702, saving model to model-0.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 25). These functions will not be directly callable after loading.\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Assets written to: /root/wandb/run-20231029_053904-a09wy3h6/files/model-best/assets\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Assets written to: /root/wandb/run-20231029_053904-a09wy3h6/files/model-best/assets\n\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/wandb/run-20231029_053904-a09wy3h6/files/model-best)... Done. 0.1s\n","output_type":"stream"},{"name":"stdout","text":"1529/1529 [==============================] - 60s 39ms/step - loss: 0.1157 - precision: 0.9694 - accuracy: 0.9935 - sensitivity: 0.9654 - val_loss: 0.1070 - val_precision: 0.9731 - val_accuracy: 0.9945 - val_sensitivity: 0.9717 - lr: 0.0058\nEpoch 20/40\n1527/1529 [============================>.] - ETA: 0s - loss: 0.1105 - precision: 0.9704 - accuracy: 0.9937 - sensitivity: 0.9667\nEpoch 20: val_loss improved from 0.10702 to 0.10678, saving model to model-0.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 25). These functions will not be directly callable after loading.\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Assets written to: /root/wandb/run-20231029_053904-a09wy3h6/files/model-best/assets\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Assets written to: /root/wandb/run-20231029_053904-a09wy3h6/files/model-best/assets\n\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/wandb/run-20231029_053904-a09wy3h6/files/model-best)... Done. 0.1s\n","output_type":"stream"},{"name":"stdout","text":"1529/1529 [==============================] - 58s 38ms/step - loss: 0.1104 - precision: 0.9704 - accuracy: 0.9937 - sensitivity: 0.9667 - val_loss: 0.1068 - val_precision: 0.9718 - val_accuracy: 0.9942 - val_sensitivity: 0.9698 - lr: 0.0054\nEpoch 21/40\n1528/1529 [============================>.] - ETA: 0s - loss: 0.1060 - precision: 0.9715 - accuracy: 0.9940 - sensitivity: 0.9679\nEpoch 21: val_loss improved from 0.10678 to 0.09762, saving model to model-0.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 25). These functions will not be directly callable after loading.\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Assets written to: /root/wandb/run-20231029_053904-a09wy3h6/files/model-best/assets\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Assets written to: /root/wandb/run-20231029_053904-a09wy3h6/files/model-best/assets\n\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/wandb/run-20231029_053904-a09wy3h6/files/model-best)... Done. 0.1s\n","output_type":"stream"},{"name":"stdout","text":"1529/1529 [==============================] - 58s 38ms/step - loss: 0.1060 - precision: 0.9715 - accuracy: 0.9940 - sensitivity: 0.9679 - val_loss: 0.0976 - val_precision: 0.9736 - val_accuracy: 0.9946 - val_sensitivity: 0.9724 - lr: 0.0050\nEpoch 22/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.1013 - precision: 0.9717 - accuracy: 0.9940 - sensitivity: 0.9682\nEpoch 22: val_loss improved from 0.09762 to 0.09624, saving model to model-0.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 25). These functions will not be directly callable after loading.\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Assets written to: /root/wandb/run-20231029_053904-a09wy3h6/files/model-best/assets\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Assets written to: /root/wandb/run-20231029_053904-a09wy3h6/files/model-best/assets\n\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/wandb/run-20231029_053904-a09wy3h6/files/model-best)... Done. 0.1s\n","output_type":"stream"},{"name":"stdout","text":"1529/1529 [==============================] - 58s 38ms/step - loss: 0.1013 - precision: 0.9717 - accuracy: 0.9940 - sensitivity: 0.9682 - val_loss: 0.0962 - val_precision: 0.9756 - val_accuracy: 0.9950 - val_sensitivity: 0.9747 - lr: 0.0046\nEpoch 23/40\n1528/1529 [============================>.] - ETA: 0s - loss: 0.0979 - precision: 0.9738 - accuracy: 0.9944 - sensitivity: 0.9697\nEpoch 23: val_loss improved from 0.09624 to 0.09099, saving model to model-0.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 25). These functions will not be directly callable after loading.\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Assets written to: /root/wandb/run-20231029_053904-a09wy3h6/files/model-best/assets\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Assets written to: /root/wandb/run-20231029_053904-a09wy3h6/files/model-best/assets\n\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/wandb/run-20231029_053904-a09wy3h6/files/model-best)... Done. 0.1s\n","output_type":"stream"},{"name":"stdout","text":"1529/1529 [==============================] - 57s 37ms/step - loss: 0.0979 - precision: 0.9739 - accuracy: 0.9944 - sensitivity: 0.9697 - val_loss: 0.0910 - val_precision: 0.9767 - val_accuracy: 0.9951 - val_sensitivity: 0.9742 - lr: 0.0042\nEpoch 24/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.0930 - precision: 0.9746 - accuracy: 0.9946 - sensitivity: 0.9714\nEpoch 24: val_loss did not improve from 0.09099\n1529/1529 [==============================] - 43s 28ms/step - loss: 0.0930 - precision: 0.9746 - accuracy: 0.9946 - sensitivity: 0.9714 - val_loss: 0.1053 - val_precision: 0.9782 - val_accuracy: 0.9954 - val_sensitivity: 0.9758 - lr: 0.0038\nEpoch 25/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.0903 - precision: 0.9755 - accuracy: 0.9947 - sensitivity: 0.9717\nEpoch 25: val_loss improved from 0.09099 to 0.08885, saving model to model-0.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 25). These functions will not be directly callable after loading.\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Assets written to: /root/wandb/run-20231029_053904-a09wy3h6/files/model-best/assets\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Assets written to: /root/wandb/run-20231029_053904-a09wy3h6/files/model-best/assets\n\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/wandb/run-20231029_053904-a09wy3h6/files/model-best)... Done. 0.1s\n","output_type":"stream"},{"name":"stdout","text":"1529/1529 [==============================] - 58s 38ms/step - loss: 0.0903 - precision: 0.9755 - accuracy: 0.9947 - sensitivity: 0.9717 - val_loss: 0.0888 - val_precision: 0.9763 - val_accuracy: 0.9951 - val_sensitivity: 0.9750 - lr: 0.0035\nEpoch 26/40\n1528/1529 [============================>.] - ETA: 0s - loss: 0.0865 - precision: 0.9768 - accuracy: 0.9950 - sensitivity: 0.9727\nEpoch 26: val_loss improved from 0.08885 to 0.08057, saving model to model-0.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 25). These functions will not be directly callable after loading.\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Assets written to: /root/wandb/run-20231029_053904-a09wy3h6/files/model-best/assets\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Assets written to: /root/wandb/run-20231029_053904-a09wy3h6/files/model-best/assets\n\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/wandb/run-20231029_053904-a09wy3h6/files/model-best)... Done. 0.3s\n","output_type":"stream"},{"name":"stdout","text":"1529/1529 [==============================] - 60s 39ms/step - loss: 0.0865 - precision: 0.9768 - accuracy: 0.9950 - sensitivity: 0.9727 - val_loss: 0.0806 - val_precision: 0.9801 - val_accuracy: 0.9955 - val_sensitivity: 0.9748 - lr: 0.0031\nEpoch 27/40\n1528/1529 [============================>.] - ETA: 0s - loss: 0.0823 - precision: 0.9774 - accuracy: 0.9951 - sensitivity: 0.9736\nEpoch 27: val_loss did not improve from 0.08057\n1529/1529 [==============================] - 43s 28ms/step - loss: 0.0823 - precision: 0.9774 - accuracy: 0.9951 - sensitivity: 0.9736 - val_loss: 0.0820 - val_precision: 0.9777 - val_accuracy: 0.9954 - val_sensitivity: 0.9760 - lr: 0.0027\nEpoch 28/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.0792 - precision: 0.9777 - accuracy: 0.9952 - sensitivity: 0.9744\nEpoch 28: val_loss did not improve from 0.08057\n1529/1529 [==============================] - 44s 29ms/step - loss: 0.0792 - precision: 0.9777 - accuracy: 0.9952 - sensitivity: 0.9744 - val_loss: 0.0929 - val_precision: 0.9767 - val_accuracy: 0.9951 - val_sensitivity: 0.9740 - lr: 0.0024\nEpoch 29/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.0738 - precision: 0.9794 - accuracy: 0.9955 - sensitivity: 0.9759\nEpoch 29: val_loss did not improve from 0.08057\n1529/1529 [==============================] - 44s 29ms/step - loss: 0.0738 - precision: 0.9794 - accuracy: 0.9955 - sensitivity: 0.9759 - val_loss: 0.1039 - val_precision: 0.9764 - val_accuracy: 0.9950 - val_sensitivity: 0.9740 - lr: 0.0021\nEpoch 30/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.0746 - precision: 0.9789 - accuracy: 0.9955 - sensitivity: 0.9758\nEpoch 30: val_loss did not improve from 0.08057\n1529/1529 [==============================] - 44s 29ms/step - loss: 0.0746 - precision: 0.9789 - accuracy: 0.9955 - sensitivity: 0.9758 - val_loss: 0.0821 - val_precision: 0.9793 - val_accuracy: 0.9956 - val_sensitivity: 0.9768 - lr: 0.0018\nEpoch 31/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.0679 - precision: 0.9808 - accuracy: 0.9959 - sensitivity: 0.9780\nEpoch 31: val_loss did not improve from 0.08057\n1529/1529 [==============================] - 42s 28ms/step - loss: 0.0679 - precision: 0.9808 - accuracy: 0.9959 - sensitivity: 0.9780 - val_loss: 0.0858 - val_precision: 0.9782 - val_accuracy: 0.9954 - val_sensitivity: 0.9756 - lr: 0.0015\nEpoch 32/40\n1528/1529 [============================>.] - ETA: 0s - loss: 0.0669 - precision: 0.9807 - accuracy: 0.9959 - sensitivity: 0.9779\nEpoch 32: val_loss improved from 0.08057 to 0.07784, saving model to model-0.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 25). These functions will not be directly callable after loading.\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Assets written to: /root/wandb/run-20231029_053904-a09wy3h6/files/model-best/assets\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Assets written to: /root/wandb/run-20231029_053904-a09wy3h6/files/model-best/assets\n\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/wandb/run-20231029_053904-a09wy3h6/files/model-best)... Done. 0.1s\n","output_type":"stream"},{"name":"stdout","text":"1529/1529 [==============================] - 58s 38ms/step - loss: 0.0669 - precision: 0.9807 - accuracy: 0.9959 - sensitivity: 0.9779 - val_loss: 0.0778 - val_precision: 0.9808 - val_accuracy: 0.9959 - val_sensitivity: 0.9779 - lr: 0.0012\nEpoch 33/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.0637 - precision: 0.9818 - accuracy: 0.9961 - sensitivity: 0.9789\nEpoch 33: val_loss improved from 0.07784 to 0.07602, saving model to model-0.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 25). These functions will not be directly callable after loading.\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Assets written to: /root/wandb/run-20231029_053904-a09wy3h6/files/model-best/assets\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Assets written to: /root/wandb/run-20231029_053904-a09wy3h6/files/model-best/assets\n\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/wandb/run-20231029_053904-a09wy3h6/files/model-best)... Done. 0.1s\n","output_type":"stream"},{"name":"stdout","text":"1529/1529 [==============================] - 58s 38ms/step - loss: 0.0637 - precision: 0.9818 - accuracy: 0.9961 - sensitivity: 0.9789 - val_loss: 0.0760 - val_precision: 0.9810 - val_accuracy: 0.9959 - val_sensitivity: 0.9779 - lr: 9.5492e-04\nEpoch 34/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.0618 - precision: 0.9822 - accuracy: 0.9961 - sensitivity: 0.9791\nEpoch 34: val_loss did not improve from 0.07602\n1529/1529 [==============================] - 44s 29ms/step - loss: 0.0618 - precision: 0.9822 - accuracy: 0.9961 - sensitivity: 0.9791 - val_loss: 0.0764 - val_precision: 0.9805 - val_accuracy: 0.9959 - val_sensitivity: 0.9787 - lr: 7.3680e-04\nEpoch 35/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.0635 - precision: 0.9820 - accuracy: 0.9961 - sensitivity: 0.9788\nEpoch 35: val_loss improved from 0.07602 to 0.07202, saving model to model-0.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 25). These functions will not be directly callable after loading.\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Assets written to: /root/wandb/run-20231029_053904-a09wy3h6/files/model-best/assets\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Assets written to: /root/wandb/run-20231029_053904-a09wy3h6/files/model-best/assets\n\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/wandb/run-20231029_053904-a09wy3h6/files/model-best)... Done. 0.1s\n","output_type":"stream"},{"name":"stdout","text":"1529/1529 [==============================] - 58s 38ms/step - loss: 0.0635 - precision: 0.9820 - accuracy: 0.9961 - sensitivity: 0.9788 - val_loss: 0.0720 - val_precision: 0.9821 - val_accuracy: 0.9963 - val_sensitivity: 0.9805 - lr: 5.4497e-04\nEpoch 36/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.0584 - precision: 0.9833 - accuracy: 0.9964 - sensitivity: 0.9807\nEpoch 36: val_loss did not improve from 0.07202\n1529/1529 [==============================] - 44s 29ms/step - loss: 0.0584 - precision: 0.9833 - accuracy: 0.9964 - sensitivity: 0.9807 - val_loss: 0.0783 - val_precision: 0.9797 - val_accuracy: 0.9958 - val_sensitivity: 0.9784 - lr: 3.8060e-04\nEpoch 37/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.0597 - precision: 0.9829 - accuracy: 0.9963 - sensitivity: 0.9802\nEpoch 37: val_loss did not improve from 0.07202\n1529/1529 [==============================] - 44s 29ms/step - loss: 0.0597 - precision: 0.9829 - accuracy: 0.9963 - sensitivity: 0.9802 - val_loss: 0.0757 - val_precision: 0.9817 - val_accuracy: 0.9962 - val_sensitivity: 0.9799 - lr: 2.4472e-04\nEpoch 38/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.0582 - precision: 0.9833 - accuracy: 0.9964 - sensitivity: 0.9807\nEpoch 38: val_loss did not improve from 0.07202\n1529/1529 [==============================] - 44s 28ms/step - loss: 0.0582 - precision: 0.9833 - accuracy: 0.9964 - sensitivity: 0.9807 - val_loss: 0.0758 - val_precision: 0.9805 - val_accuracy: 0.9959 - val_sensitivity: 0.9787 - lr: 1.3815e-04\nEpoch 39/40\n1528/1529 [============================>.] - ETA: 0s - loss: 0.0590 - precision: 0.9831 - accuracy: 0.9964 - sensitivity: 0.9804\nEpoch 39: val_loss did not improve from 0.07202\n1529/1529 [==============================] - 43s 28ms/step - loss: 0.0590 - precision: 0.9831 - accuracy: 0.9964 - sensitivity: 0.9805 - val_loss: 0.0760 - val_precision: 0.9810 - val_accuracy: 0.9960 - val_sensitivity: 0.9794 - lr: 6.1558e-05\nEpoch 40/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.0569 - precision: 0.9831 - accuracy: 0.9963 - sensitivity: 0.9803\nEpoch 40: val_loss did not improve from 0.07202\n1529/1529 [==============================] - 42s 28ms/step - loss: 0.0569 - precision: 0.9831 - accuracy: 0.9963 - sensitivity: 0.9803 - val_loss: 0.0760 - val_precision: 0.9802 - val_accuracy: 0.9959 - val_sensitivity: 0.9786 - lr: 1.5413e-05\n############################################################\n","output_type":"stream"}]},{"cell_type":"code","source":"model.save('model_last_epoch.h5')\nmodel_till_last_epoch = model\nSAVED_MODEL_LOC = \"model-0.h5\"\nmodel = dpm_sacc()\nmodel.load_weights(SAVED_MODEL_LOC)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T06:14:31.952580Z","iopub.execute_input":"2023-10-29T06:14:31.953237Z","iopub.status.idle":"2023-10-29T06:14:33.364695Z","shell.execute_reply.started":"2023-10-29T06:14:31.953206Z","shell.execute_reply":"2023-10-29T06:14:33.363659Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"NAME = ['/', \"A\",  'F', 'L', 'N', 'R', 'V', 'a', 'f', 'j']\nfor model_type, trained_model in zip(['best_epoch', 'last_epoch'], [model, model_till_last_epoch]):\n    test_imgs = DATA.test_dataset().map(lambda data, ids: data)\n    img_labels_ds = DATA.test_dataset().map(lambda data, ids: ids).unbatch()\n\n    STEPS = (CONFIG.TOTAL_TEST_IMG)//(CONFIG.BATCH_SIZE*4) + 1\n\n    y_pred = trained_model.predict(test_imgs,steps = int(STEPS), verbose=1)\n    test_labels = next(iter(img_labels_ds.batch(int(CONFIG.TOTAL_TEST_IMG) + 1)))\n    y_true = test_labels[\"target10\"].numpy()\n    pd.DataFrame({\n            'image_id'  : test_labels[\"image_id\"].numpy(),\n            'actual'  : np.argmax(y_true, axis=1),\n            'predicted'      : np.argmax(y_pred, axis=1)\n            }).to_csv('prediction_{}.csv'.format(model_type), index=False)\n\n    df = pd.read_csv(\"prediction_{}.csv\".format(model_type))\n\n    run_.log({f\"{model_type}_pr\": wandb.plot.pr_curve(np.argmax(y_true, axis=1), y_pred, labels=NAME)})\n    run_.log({f\"{model_type}_roc\": wandb.plot.roc_curve(np.argmax(y_true, axis=1), y_pred, labels=NAME)})\n\n    cm = wandb.plot.confusion_matrix(\n                    y_true=np.argmax(y_true, axis=1),\n                    preds=np.argmax(y_pred, axis=1),\n                    class_names=NAME)\n\n    run_.log({f\"{model_type}_conf_mat\": cm})\n\n    harvest = confusion_matrix(df['actual'], df['predicted'])\n    fig, ax = plt.subplots(figsize=(8,8))\n    im = ax.imshow(harvest)\n    ax.set_xticks(np.arange(len(NAME)))\n    ax.set_yticks(np.arange(len(NAME)))\n    ax.set_xticklabels(NAME)\n    ax.set_yticklabels(NAME)\n\n    # Rotate the tick labels and set their alignment.\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n            rotation_mode=\"anchor\")\n\n    for i in range(len(NAME)):\n        for j in range(len(NAME)):\n            text = ax.text(j, i, harvest[i, j],\n                        ha=\"center\", va=\"center\", color=\"w\")\n\n    fig.tight_layout()\n    run_.log({f\"{model_type}_cm\": plt})\n\n    from sklearn.metrics import classification_report\n    target_names = NAME\n    x_ = classification_report(df['actual'], df['predicted'], target_names=target_names, digits=4)\n    x2 = classification_report(df['actual'], df['predicted'], target_names=target_names, digits=4, output_dict=True)\n    print(x_)\n    run_.log({f\"{model_type}_CR\": x2})\n\n\n## log more\nartifact = wandb.Artifact(\"Full_Logs\", type=\"logs\")\nartifact.add_dir(\"/kaggle/working/\")\nwandb.log_artifact(artifact)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T06:15:12.778398Z","iopub.execute_input":"2023-10-29T06:15:12.778751Z","iopub.status.idle":"2023-10-29T06:16:04.061859Z","shell.execute_reply.started":"2023-10-29T06:15:12.778724Z","shell.execute_reply":"2023-10-29T06:16:04.060703Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"48/48 [==============================] - 26s 542ms/step\n              precision    recall  f1-score   support\n\n           /     1.0000    1.0000    1.0000       330\n           A     0.8914    0.8347    0.8621       236\n           F     0.8974    0.7955    0.8434        88\n           L     1.0000    0.9953    0.9976       850\n           N     0.9776    0.9890    0.9833      3269\n           R     0.9913    0.9895    0.9904       574\n           V     0.9591    0.9645    0.9618       705\n           a     0.8000    0.5714    0.6667         7\n           f     1.0000    1.0000    1.0000        33\n           j     0.7143    0.4167    0.5263        24\n\n    accuracy                         0.9763      6116\n   macro avg     0.9231    0.8557    0.8832      6116\nweighted avg     0.9755    0.9763    0.9756      6116\n\n","output_type":"stream"},{"name":"stderr","text":"2023-10-29 06:15:43.692967: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n2023-10-29 06:15:43.914785: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n","output_type":"stream"},{"name":"stdout","text":"48/48 [==============================] - 19s 197ms/step\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/kaggle/working)... Done. 0.1s\n","output_type":"stream"},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           /     1.0000    1.0000    1.0000       330\n           A     0.8919    0.8390    0.8646       236\n           F     0.9014    0.7273    0.8050        88\n           L     1.0000    0.9953    0.9976       850\n           N     0.9794    0.9893    0.9843      3269\n           R     0.9895    0.9895    0.9895       574\n           V     0.9515    0.9730    0.9621       705\n           a     0.8000    0.5714    0.6667         7\n           f     1.0000    1.0000    1.0000        33\n           j     0.8333    0.4167    0.5556        24\n\n    accuracy                         0.9766      6116\n   macro avg     0.9347    0.8502    0.8826      6116\nweighted avg     0.9759    0.9766    0.9758      6116\n\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"<Artifact Full_Logs>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 800x800 with 1 Axes>","image/png":"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"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 800x800 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.python.framework.convert_to_constants import  convert_variables_to_constants_v2_as_graph\n\n\ndef get_flops(model):\n    concrete = tf.function(lambda inputs: model(inputs))\n    concrete_func = concrete.get_concrete_function(\n        [tf.TensorSpec([1, *inputs.shape[1:]]) for inputs in model.inputs])\n    frozen_func, graph_def = convert_variables_to_constants_v2_as_graph(concrete_func)\n    with tf.Graph().as_default() as graph:\n        tf.graph_util.import_graph_def(graph_def, name='')\n        run_meta = tf.compat.v1.RunMetadata()\n        opts = tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()\n        flops = tf.compat.v1.profiler.profile(graph=graph, run_meta=run_meta, cmd=\"op\", options=opts)\n        return flops.total_float_ops\n\nmodel = dpm_sacc()\n\nprint(\"The FLOPs is:{}\".format(get_flops(model)) ,flush=True )\n\nrun_.finish()","metadata":{"execution":{"iopub.status.busy":"2023-10-29T06:16:36.154595Z","iopub.execute_input":"2023-10-29T06:16:36.154957Z","iopub.status.idle":"2023-10-29T06:16:43.648855Z","shell.execute_reply.started":"2023-10-29T06:16:36.154931Z","shell.execute_reply":"2023-10-29T06:16:43.647970Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"WARNING:tensorflow:From /usr/local/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py:5250: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\nInstructions for updating:\nThis API was designed for TensorFlow v1. See https://www.tensorflow.org/guide/migrate for instructions on how to migrate your code to TensorFlow v2.\n","output_type":"stream"},{"name":"stderr","text":"WARNING:tensorflow:From /usr/local/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py:5250: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\nInstructions for updating:\nThis API was designed for TensorFlow v1. See https://www.tensorflow.org/guide/migrate for instructions on how to migrate your code to TensorFlow v2.\n","output_type":"stream"},{"name":"stdout","text":"\n=========================Options=============================\n-max_depth                  10000\n-min_bytes                  0\n-min_peak_bytes             0\n-min_residual_bytes         0\n-min_output_bytes           0\n-min_micros                 0\n-min_accelerator_micros     0\n-min_cpu_micros             0\n-min_params                 0\n-min_float_ops              1\n-min_occurrence             0\n-step                       -1\n-order_by                   float_ops\n-account_type_regexes       .*\n-start_name_regexes         .*\n-trim_name_regexes          \n-show_name_regexes          .*\n-hide_name_regexes          \n-account_displayed_op_only  true\n-select                     float_ops\n-output                     stdout:\n\n==================Model Analysis Report======================\n\nDoc:\nop: The nodes are operation kernel type, such as MatMul, Conv2D. Graph nodes belonging to the same type are aggregated together.\nflops: Number of float operations. Note: Please read the implementation for the math behind it.\n\nProfile:\nnode name | # float_ops\nConv2D                   622.85m float_ops (100.00%, 97.98%)\nDepthwiseConv2dNative    8.74m float_ops (2.02%, 1.37%)\nBiasAdd                  2.38m float_ops (0.65%, 0.38%)\nMatMul                   1.73m float_ops (0.27%, 0.27%)\nSoftmax                  5.17k float_ops (0.00%, 0.00%)\nMul                      1.02k float_ops (0.00%, 0.00%)\n\n======================End of Report==========================\nThe FLOPs is:635713572\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████████████████</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr</td><td>███████▇▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>precision</td><td>▁▄▅▅▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇███████████████</td></tr><tr><td>sensitivity</td><td>▁▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████████████</td></tr><tr><td>val_accuracy</td><td>▁▂▃▄▂▄▄▄▄▅▅▅▅▅▅▅▆▇▇▇▇▇▇▇▇▇▇▇▇█▇█████████</td></tr><tr><td>val_loss</td><td>█▇▆▅▇▅▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_precision</td><td>▁▂▃▄▂▄▄▄▄▅▅▅▅▅▅▅▆▇▇▇▇▇▇▇▇█▇▇▇█▇█████████</td></tr><tr><td>val_sensitivity</td><td>▁▂▃▄▂▄▄▄▄▅▅▅▅▅▅▄▆▇▇▇▇▇▇▇▇▇▇▇▇█▇█████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.99635</td></tr><tr><td>best_epoch</td><td>34</td></tr><tr><td>best_val_loss</td><td>0.07202</td></tr><tr><td>epoch</td><td>39</td></tr><tr><td>loss</td><td>0.0569</td></tr><tr><td>lr</td><td>2e-05</td></tr><tr><td>precision</td><td>0.98311</td></tr><tr><td>sensitivity</td><td>0.9803</td></tr><tr><td>val_accuracy</td><td>0.99588</td></tr><tr><td>val_loss</td><td>0.07604</td></tr><tr><td>val_precision</td><td>0.98018</td></tr><tr><td>val_sensitivity</td><td>0.97858</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">flowing-jazz-198</strong> at: <a href='https://wandb.ai/shreya-srivas02/ECG_BEAT_CLASSIFICATION_PAPER_COMMENTS/runs/a09wy3h6' target=\"_blank\">https://wandb.ai/shreya-srivas02/ECG_BEAT_CLASSIFICATION_PAPER_COMMENTS/runs/a09wy3h6</a><br/>Synced 5 W&B file(s), 9 media file(s), 125 artifact file(s) and 1 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>/root/wandb/run-20231029_053904-a09wy3h6/logs</code>"},"metadata":{}}]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-10-29T06:16:43.650384Z","iopub.execute_input":"2023-10-29T06:16:43.650656Z","iopub.status.idle":"2023-10-29T06:16:43.781959Z","shell.execute_reply.started":"2023-10-29T06:16:43.650631Z","shell.execute_reply":"2023-10-29T06:16:43.779391Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Model: \"model_4\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n inp1 (InputLayer)              [(None, 256, 256, 1  0           []                               \n                                )]                                                                \n                                                                                                  \n conv2d_52 (Conv2D)             (None, 128, 128, 32  320         ['inp1[0][0]']                   \n                                )                                                                 \n                                                                                                  \n conv2d_54 (Conv2D)             (None, 128, 128, 32  832         ['inp1[0][0]']                   \n                                )                                                                 \n                                                                                                  \n batch_normalization_88 (BatchN  (None, 128, 128, 32  128        ['conv2d_52[0][0]']              \n ormalization)                  )                                                                 \n                                                                                                  \n batch_normalization_90 (BatchN  (None, 128, 128, 32  128        ['conv2d_54[0][0]']              \n ormalization)                  )                                                                 \n                                                                                                  \n re_lu_88 (ReLU)                (None, 128, 128, 32  0           ['batch_normalization_88[0][0]'] \n                                )                                                                 \n                                                                                                  \n re_lu_90 (ReLU)                (None, 128, 128, 32  0           ['batch_normalization_90[0][0]'] \n                                )                                                                 \n                                                                                                  \n conv2d_53 (Conv2D)             (None, 64, 64, 32)   9248        ['re_lu_88[0][0]']               \n                                                                                                  \n conv2d_55 (Conv2D)             (None, 64, 64, 32)   50208       ['re_lu_90[0][0]']               \n                                                                                                  \n batch_normalization_89 (BatchN  (None, 64, 64, 32)  128         ['conv2d_53[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n batch_normalization_91 (BatchN  (None, 64, 64, 32)  128         ['conv2d_55[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n re_lu_89 (ReLU)                (None, 64, 64, 32)   0           ['batch_normalization_89[0][0]'] \n                                                                                                  \n re_lu_91 (ReLU)                (None, 64, 64, 32)   0           ['batch_normalization_91[0][0]'] \n                                                                                                  \n concatenate_8 (Concatenate)    (None, 64, 64, 64)   0           ['re_lu_89[0][0]',               \n                                                                  're_lu_91[0][0]']               \n                                                                                                  \n depthwise_conv2d_36 (Depthwise  (None, 64, 64, 64)  640         ['concatenate_8[0][0]']          \n Conv2D)                                                                                          \n                                                                                                  \n batch_normalization_92 (BatchN  (None, 64, 64, 64)  256         ['depthwise_conv2d_36[0][0]']    \n ormalization)                                                                                    \n                                                                                                  \n re_lu_92 (ReLU)                (None, 64, 64, 64)   0           ['batch_normalization_92[0][0]'] \n                                                                                                  \n conv2d_56 (Conv2D)             (None, 64, 64, 64)   4160        ['re_lu_92[0][0]']               \n                                                                                                  \n batch_normalization_93 (BatchN  (None, 64, 64, 64)  256         ['conv2d_56[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n re_lu_93 (ReLU)                (None, 64, 64, 64)   0           ['batch_normalization_93[0][0]'] \n                                                                                                  \n depthwise_conv2d_37 (Depthwise  (None, 32, 32, 64)  640         ['re_lu_93[0][0]']               \n Conv2D)                                                                                          \n                                                                                                  \n batch_normalization_94 (BatchN  (None, 32, 32, 64)  256         ['depthwise_conv2d_37[0][0]']    \n ormalization)                                                                                    \n                                                                                                  \n re_lu_94 (ReLU)                (None, 32, 32, 64)   0           ['batch_normalization_94[0][0]'] \n                                                                                                  \n conv2d_57 (Conv2D)             (None, 32, 32, 64)   4160        ['re_lu_94[0][0]']               \n                                                                                                  \n batch_normalization_95 (BatchN  (None, 32, 32, 64)  256         ['conv2d_57[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n re_lu_95 (ReLU)                (None, 32, 32, 64)   0           ['batch_normalization_95[0][0]'] \n                                                                                                  \n depthwise_conv2d_38 (Depthwise  (None, 32, 32, 64)  640         ['re_lu_95[0][0]']               \n Conv2D)                                                                                          \n                                                                                                  \n batch_normalization_96 (BatchN  (None, 32, 32, 64)  256         ['depthwise_conv2d_38[0][0]']    \n ormalization)                                                                                    \n                                                                                                  \n re_lu_96 (ReLU)                (None, 32, 32, 64)   0           ['batch_normalization_96[0][0]'] \n                                                                                                  \n conv2d_58 (Conv2D)             (None, 32, 32, 128)  8320        ['re_lu_96[0][0]']               \n                                                                                                  \n batch_normalization_97 (BatchN  (None, 32, 32, 128)  512        ['conv2d_58[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n re_lu_97 (ReLU)                (None, 32, 32, 128)  0           ['batch_normalization_97[0][0]'] \n                                                                                                  \n dropout_20 (Dropout)           (None, 32, 32, 128)  0           ['re_lu_97[0][0]']               \n                                                                                                  \n depthwise_conv2d_39 (Depthwise  (None, 16, 16, 128)  1280       ['dropout_20[0][0]']             \n Conv2D)                                                                                          \n                                                                                                  \n batch_normalization_98 (BatchN  (None, 16, 16, 128)  512        ['depthwise_conv2d_39[0][0]']    \n ormalization)                                                                                    \n                                                                                                  \n re_lu_98 (ReLU)                (None, 16, 16, 128)  0           ['batch_normalization_98[0][0]'] \n                                                                                                  \n conv2d_59 (Conv2D)             (None, 16, 16, 128)  16512       ['re_lu_98[0][0]']               \n                                                                                                  \n batch_normalization_99 (BatchN  (None, 16, 16, 128)  512        ['conv2d_59[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n re_lu_99 (ReLU)                (None, 16, 16, 128)  0           ['batch_normalization_99[0][0]'] \n                                                                                                  \n depthwise_conv2d_40 (Depthwise  (None, 16, 16, 128)  1280       ['re_lu_99[0][0]']               \n Conv2D)                                                                                          \n                                                                                                  \n batch_normalization_100 (Batch  (None, 16, 16, 128)  512        ['depthwise_conv2d_40[0][0]']    \n Normalization)                                                                                   \n                                                                                                  \n re_lu_100 (ReLU)               (None, 16, 16, 128)  0           ['batch_normalization_100[0][0]']\n                                                                                                  \n conv2d_60 (Conv2D)             (None, 16, 16, 256)  33024       ['re_lu_100[0][0]']              \n                                                                                                  \n batch_normalization_101 (Batch  (None, 16, 16, 256)  1024       ['conv2d_60[0][0]']              \n Normalization)                                                                                   \n                                                                                                  \n re_lu_101 (ReLU)               (None, 16, 16, 256)  0           ['batch_normalization_101[0][0]']\n                                                                                                  \n dropout_21 (Dropout)           (None, 16, 16, 256)  0           ['re_lu_101[0][0]']              \n                                                                                                  \n depthwise_conv2d_41 (Depthwise  (None, 8, 8, 256)   2560        ['dropout_21[0][0]']             \n Conv2D)                                                                                          \n                                                                                                  \n batch_normalization_102 (Batch  (None, 8, 8, 256)   1024        ['depthwise_conv2d_41[0][0]']    \n Normalization)                                                                                   \n                                                                                                  \n re_lu_102 (ReLU)               (None, 8, 8, 256)    0           ['batch_normalization_102[0][0]']\n                                                                                                  \n conv2d_61 (Conv2D)             (None, 8, 8, 256)    65792       ['re_lu_102[0][0]']              \n                                                                                                  \n batch_normalization_103 (Batch  (None, 8, 8, 256)   1024        ['conv2d_61[0][0]']              \n Normalization)                                                                                   \n                                                                                                  \n re_lu_103 (ReLU)               (None, 8, 8, 256)    0           ['batch_normalization_103[0][0]']\n                                                                                                  \n depthwise_conv2d_42 (Depthwise  (None, 4, 4, 256)   2560        ['re_lu_103[0][0]']              \n Conv2D)                                                                                          \n                                                                                                  \n batch_normalization_104 (Batch  (None, 4, 4, 256)   1024        ['depthwise_conv2d_42[0][0]']    \n Normalization)                                                                                   \n                                                                                                  \n re_lu_104 (ReLU)               (None, 4, 4, 256)    0           ['batch_normalization_104[0][0]']\n                                                                                                  \n conv2d_62 (Conv2D)             (None, 4, 4, 256)    65792       ['re_lu_104[0][0]']              \n                                                                                                  \n batch_normalization_105 (Batch  (None, 4, 4, 256)   1024        ['conv2d_62[0][0]']              \n Normalization)                                                                                   \n                                                                                                  \n re_lu_105 (ReLU)               (None, 4, 4, 256)    0           ['batch_normalization_105[0][0]']\n                                                                                                  \n dropout_22 (Dropout)           (None, 4, 4, 256)    0           ['re_lu_105[0][0]']              \n                                                                                                  \n depthwise_conv2d_43 (Depthwise  (None, 4, 4, 256)   2560        ['dropout_22[0][0]']             \n Conv2D)                                                                                          \n                                                                                                  \n batch_normalization_106 (Batch  (None, 4, 4, 256)   1024        ['depthwise_conv2d_43[0][0]']    \n Normalization)                                                                                   \n                                                                                                  \n re_lu_106 (ReLU)               (None, 4, 4, 256)    0           ['batch_normalization_106[0][0]']\n                                                                                                  \n conv2d_63 (Conv2D)             (None, 4, 4, 512)    131584      ['re_lu_106[0][0]']              \n                                                                                                  \n batch_normalization_107 (Batch  (None, 4, 4, 512)   2048        ['conv2d_63[0][0]']              \n Normalization)                                                                                   \n                                                                                                  \n re_lu_107 (ReLU)               (None, 4, 4, 512)    0           ['batch_normalization_107[0][0]']\n                                                                                                  \n depthwise_conv2d_44 (Depthwise  (None, 2, 2, 512)   5120        ['re_lu_107[0][0]']              \n Conv2D)                                                                                          \n                                                                                                  \n batch_normalization_108 (Batch  (None, 2, 2, 512)   2048        ['depthwise_conv2d_44[0][0]']    \n Normalization)                                                                                   \n                                                                                                  \n re_lu_108 (ReLU)               (None, 2, 2, 512)    0           ['batch_normalization_108[0][0]']\n                                                                                                  \n conv2d_64 (Conv2D)             (None, 2, 2, 512)    262656      ['re_lu_108[0][0]']              \n                                                                                                  \n batch_normalization_109 (Batch  (None, 2, 2, 512)   2048        ['conv2d_64[0][0]']              \n Normalization)                                                                                   \n                                                                                                  \n re_lu_109 (ReLU)               (None, 2, 2, 512)    0           ['batch_normalization_109[0][0]']\n                                                                                                  \n inp2 (InputLayer)              [(None, 2)]          0           []                               \n                                                                                                  \n global_max_pooling2d_4 (Global  (None, 512)         0           ['re_lu_109[0][0]']              \n MaxPooling2D)                                                                                    \n                                                                                                  \n metadata_feature_dense_1 (Dens  (None, 8)           24          ['inp2[0][0]']                   \n e)                                                                                               \n                                                                                                  \n dropout_23 (Dropout)           (None, 512)          0           ['global_max_pooling2d_4[0][0]'] \n                                                                                                  \n concatenate_9 (Concatenate)    (None, 10)           0           ['metadata_feature_dense_1[0][0]'\n                                                                 , 'inp2[0][0]']                  \n                                                                                                  \n sacc_layer_4 (SACCLayer)       (None, 512)          793088      ['dropout_23[0][0]',             \n                                                                  'concatenate_9[0][0]']          \n                                                                                                  \n combine_feature_dense_1 (Dense  (None, 128)         65664       ['sacc_layer_4[0][0]']           \n )                                                                                                \n                                                                                                  \n combine_feature_dense_2 (Dense  (None, 64)          8256        ['combine_feature_dense_1[0][0]']\n )                                                                                                \n                                                                                                  \n dropout_24 (Dropout)           (None, 64)           0           ['combine_feature_dense_2[0][0]']\n                                                                                                  \n target10 (Dense)               (None, 10)           650         ['dropout_24[0][0]']             \n                                                                                                  \n==================================================================================================\nTotal params: 1,553,698\nTrainable params: 1,545,634\nNon-trainable params: 8,064\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"tf.keras.utils.plot_model(\n    dpm_sacc(),\n    to_file='model.png',\n    show_shapes=True,\n    show_dtype=False,\n    show_layer_names=False,\n    rankdir='TB',\n    expand_nested=False,\n    dpi=96,\n    layer_range=None,\n    show_layer_activations=True,\n    show_trainable=True\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T06:16:43.782913Z","iopub.execute_input":"2023-10-29T06:16:43.783161Z","iopub.status.idle":"2023-10-29T06:16:44.282045Z","shell.execute_reply.started":"2023-10-29T06:16:43.783139Z","shell.execute_reply":"2023-10-29T06:16:44.281121Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}