{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install tensorflow==2.8.0\n!pip install efficientnet\n!pip install --upgrade wandb\n!pip install boto3","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-03T18:10:02.142617Z","iopub.execute_input":"2023-11-03T18:10:02.142950Z","iopub.status.idle":"2023-11-03T18:10:52.033378Z","shell.execute_reply.started":"2023-11-03T18:10:02.142920Z","shell.execute_reply":"2023-11-03T18:10:52.032259Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting efficientnet\n  Downloading efficientnet-1.1.1-py3-none-any.whl (18 kB)\nCollecting keras-applications<=1.0.8,>=1.0.7 (from efficientnet)\n  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: scikit-image in /opt/conda/lib/python3.10/site-packages (from efficientnet) (0.21.0)\nRequirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.10/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.23.5)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (3.9.0)\nRequirement already satisfied: scipy>=1.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (1.11.2)\nRequirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (3.1)\nRequirement already satisfied: pillow>=9.0.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (9.5.0)\nRequirement already satisfied: imageio>=2.27 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (2.31.1)\nRequirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (2023.4.12)\nRequirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (1.4.1)\nRequirement already satisfied: packaging>=21 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (21.3)\nRequirement already satisfied: lazy_loader>=0.2 in /opt/conda/lib/python3.10/site-packages (from scikit-image->efficientnet) (0.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=21->scikit-image->efficientnet) (3.0.9)\nInstalling collected packages: keras-applications, efficientnet\nSuccessfully installed efficientnet-1.1.1 keras-applications-1.0.8\nRequirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.15.9)\nCollecting wandb\n  Downloading wandb-0.15.12-py3-none-any.whl (2.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.31)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.30.0)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0)\nRequirement already satisfied: pathtools in /opt/conda/lib/python3.10/site-packages (from wandb) (0.1.2)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.2)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (68.0.0)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\nInstalling collected packages: wandb\n  Attempting uninstall: wandb\n    Found existing installation: wandb 0.15.9\n    Uninstalling wandb-0.15.9:\n      Successfully uninstalled wandb-0.15.9\nSuccessfully installed wandb-0.15.12\nRequirement already satisfied: boto3 in /opt/conda/lib/python3.10/site-packages (1.26.100)\nCollecting botocore<1.30.0,>=1.29.100 (from boto3)\n  Downloading botocore-1.29.165-py3-none-any.whl (11.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3) (1.0.1)\nRequirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from boto3) (0.6.2)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.10/site-packages (from botocore<1.30.0,>=1.29.100->boto3) (2.8.2)\nRequirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.10/site-packages (from botocore<1.30.0,>=1.29.100->boto3) (1.26.15)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.100->boto3) (1.16.0)\nInstalling collected packages: botocore\n  Attempting uninstall: botocore\n    Found existing installation: botocore 1.31.17\n    Uninstalling botocore-1.31.17:\n      Successfully uninstalled botocore-1.31.17\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\naiobotocore 2.5.4 requires botocore<1.31.18,>=1.31.17, but you have botocore 1.29.165 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed botocore-1.29.165\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport re\nimport random\nimport pandas as pd\nimport numpy as np\nimport json\nimport math\nimport string\nimport uuid\n\n\n### Tensorflow Imports\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score,confusion_matrix\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.layers import Input, Conv1D, Add, Activation, Layer, \\\n                        UpSampling1D, Input, DepthwiseConv2D, Conv2D, \\\n                        BatchNormalization, ReLU, AvgPool2D, Flatten, Dense\nfrom tensorflow.keras.applications import MobileNet\n\n\n### External models\nimport efficientnet.tfkeras as efn\n\n\n### Matplotlib Imports\nimport matplotlib\nimport matplotlib.pyplot as plt\n\n\n### import wandb\nimport wandb\nfrom wandb.keras import WandbCallback\n","metadata":{"execution":{"iopub.status.busy":"2023-11-03T18:10:52.035935Z","iopub.execute_input":"2023-11-03T18:10:52.036377Z","iopub.status.idle":"2023-11-03T18:11:02.294170Z","shell.execute_reply.started":"2023-11-03T18:10:52.036336Z","shell.execute_reply":"2023-11-03T18:11:02.293274Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"import boto3\nimport os\nfrom botocore import UNSIGNED\nfrom botocore.config import Config\n\n\ndef download_files(bucket_name, s3_prefix, local_directory):\n    s3 = boto3.resource('s3', config=Config(signature_version=UNSIGNED))\n    bucket = s3.Bucket(bucket_name)\n\n    for obj in bucket.objects.filter(Prefix=s3_prefix):\n        local_file = os.path.join(local_directory, obj.key)\n\n        if not os.path.exists(os.path.dirname(local_file)):\n            os.makedirs(os.path.dirname(local_file))\n\n        bucket.download_file(obj.key, local_file)\n        print(f\"Downloaded {obj.key} to {local_file}\")\n\ndownload_files('mitdb128x128', 'train', '/content/input')","metadata":{"execution":{"iopub.status.busy":"2023-11-03T18:11:02.295393Z","iopub.execute_input":"2023-11-03T18:11:02.295769Z","iopub.status.idle":"2023-11-03T18:11:07.003613Z","shell.execute_reply.started":"2023-11-03T18:11:02.295734Z","shell.execute_reply":"2023-11-03T18:11:07.002587Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Downloaded trainfile_class10_fold0_6117.tfrec to /content/input/trainfile_class10_fold0_6117.tfrec\nDownloaded trainfile_class10_fold1_6116.tfrec to /content/input/trainfile_class10_fold1_6116.tfrec\nDownloaded trainfile_class10_fold2_6116.tfrec to /content/input/trainfile_class10_fold2_6116.tfrec\nDownloaded trainfile_class10_fold3_6116.tfrec to /content/input/trainfile_class10_fold3_6116.tfrec\nDownloaded trainfile_class10_fold4_6116.tfrec to /content/input/trainfile_class10_fold4_6116.tfrec\nDownloaded trainfile_class10_fold5_6116.tfrec to /content/input/trainfile_class10_fold5_6116.tfrec\nDownloaded trainfile_class10_fold6_6116.tfrec to /content/input/trainfile_class10_fold6_6116.tfrec\nDownloaded trainfile_class10_fold7_6117.tfrec to /content/input/trainfile_class10_fold7_6117.tfrec\nDownloaded trainfile_class10_fold8_6116.tfrec to /content/input/trainfile_class10_fold8_6116.tfrec\nDownloaded trainfile_class10_fold9_6116.tfrec to /content/input/trainfile_class10_fold9_6116.tfrec\n","output_type":"stream"}]},{"cell_type":"code","source":"!ls /content/input","metadata":{"execution":{"iopub.status.busy":"2023-11-03T18:11:07.006545Z","iopub.execute_input":"2023-11-03T18:11:07.006859Z","iopub.status.idle":"2023-11-03T18:11:08.083822Z","shell.execute_reply.started":"2023-11-03T18:11:07.006833Z","shell.execute_reply":"2023-11-03T18:11:08.082455Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"trainfile_class10_fold0_6117.tfrec  trainfile_class10_fold5_6116.tfrec\ntrainfile_class10_fold1_6116.tfrec  trainfile_class10_fold6_6116.tfrec\ntrainfile_class10_fold2_6116.tfrec  trainfile_class10_fold7_6117.tfrec\ntrainfile_class10_fold3_6116.tfrec  trainfile_class10_fold8_6116.tfrec\ntrainfile_class10_fold4_6116.tfrec  trainfile_class10_fold9_6116.tfrec\n","output_type":"stream"}]},{"cell_type":"code","source":"hparams = {\n    \"backbone\" : \"b0\",\n    \"batch_size\" : 32,\n    \"epochs\" : 40,\n    \"img_size\" : 128,\n    \"lr\" : 0.01,\n    \"optimizer\" : \"adam\",\n    \"seed\": 257,\n    \"notes\": \"SACC-s-dropout-changes\"\n}","metadata":{"execution":{"iopub.status.busy":"2023-11-03T18:11:08.085554Z","iopub.execute_input":"2023-11-03T18:11:08.086007Z","iopub.status.idle":"2023-11-03T18:11:08.092265Z","shell.execute_reply.started":"2023-11-03T18:11:08.085959Z","shell.execute_reply":"2023-11-03T18:11:08.091270Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class WandBConfigurations():\n    def __init__(self, exp_name = \"ECG_BEAT_CLASSIFICATION_PAPER_COMMENTS\"):\n        self.EXPERIMENT_NAME = exp_name\n        os.environ[\"WANDB_API_KEY\"] = \"221507f411c2ddcc0c17238e115a12c528a482f6\"\n        wandb.login()\n\nWB = WandBConfigurations()","metadata":{"execution":{"iopub.status.busy":"2023-11-03T18:11:08.093868Z","iopub.execute_input":"2023-11-03T18:11:08.094551Z","iopub.status.idle":"2023-11-03T18:11:10.461650Z","shell.execute_reply.started":"2023-11-03T18:11:08.094521Z","shell.execute_reply":"2023-11-03T18:11:10.460788Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshreya-srivas02\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"}]},{"cell_type":"code","source":" class Utils():\n    def __init__(self):\n        self.seed_everything()\n\n    def id_generator(size=6):\n        return str(uuid.uuid4())[:size]\n\n    def setupTPU(self):\n\n        try:\n            tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n            print('Running on TPU ', tpu.cluster_spec().as_dict())\n        except ValueError:\n            tpu = None\n\n        if tpu:\n            tf.config.experimental_connect_to_cluster(tpu)\n            tf.tpu.experimental.initialize_tpu_system(tpu)\n            strategy = tf.distribute.TPUStrategy(tpu)\n            STRATEGY = strategy\n            BATCH_SIZE = 8 * strategy.num_replicas_in_sync\n            # wandb.config.hardware = 'TPU'\n        else:\n            strategy = tf.distribute.get_strategy()\n            \n        return strategy\n\n    def seed_everything(self):\n        np.random.seed(hparams['seed'])\n        tf.random.set_seed(hparams['seed'])\n        random.seed(a=hparams['seed'])\n        os.environ['PYTHONHASHSEED'] = str(hparams['seed'])\n\nUTILS = Utils()\nSTRATEGY = UTILS.setupTPU()","metadata":{"execution":{"iopub.status.busy":"2023-11-03T18:11:10.462762Z","iopub.execute_input":"2023-11-03T18:11:10.463345Z","iopub.status.idle":"2023-11-03T18:11:10.480135Z","shell.execute_reply.started":"2023-11-03T18:11:10.463318Z","shell.execute_reply":"2023-11-03T18:11:10.479132Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"STRATEGY","metadata":{"execution":{"iopub.status.busy":"2023-11-03T18:11:10.481537Z","iopub.execute_input":"2023-11-03T18:11:10.481935Z","iopub.status.idle":"2023-11-03T18:11:10.495772Z","shell.execute_reply.started":"2023-11-03T18:11:10.481899Z","shell.execute_reply":"2023-11-03T18:11:10.494858Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.distribute.distribute_lib._DefaultDistributionStrategy at 0x7cfc1be47eb0>"},"metadata":{}}]},{"cell_type":"code","source":"class Config():\n    def __init__(self):\n        self.DO_VAL_SPLIT = True\n        self.TRAIN_FILES = sorted(tf.io.gfile.glob('/content/input/train*.tfrec'))[:-1]\n        self.TOTAL_TRAIN_IMG = 48929\n        self.TOTAL_VAL_IMG = 6116\n        self.TOTAL_TEST_IMG = 6116\n        self.BACKBONE = hparams['backbone']\n        self.IMG_TRAIN_SHAPE = [hparams[\"img_size\"],hparams[\"img_size\"]]\n        self.DO_FINETUNE = True\n        self.BATCH_SIZE = hparams[\"batch_size\"] # 16\n        self.EPOCHES = hparams[\"epochs\"]\n        self.SEED = hparams[\"seed\"]\n        self.LOSS = tf.keras.losses.CategoricalCrossentropy()\n        self.OPTIMIZER = self.get_optimizer()\n        self.ACCURACY = []\n        self.CALLBACKS = []\n        self.STRATEGY = STRATEGY\n        self.FOLDS = 9\n        self.USE_LR_SCHEDULER = True\n        self.FOLD_NUMBER = 0\n        self.FOLDS_DICT = {}\n\n        if self.USE_LR_SCHEDULER:\n            lrfn = self.get_cosine_schedule_with_warmup(lr=hparams['lr'])\n            lr_schedule = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=0)\n            self.CALLBACKS.append(lr_schedule)\n\n    def get_optimizer(self):\n        if hparams['optimizer'] == 'adam':\n            return tf.keras.optimizers.Adam(learning_rate=hparams[\"lr\"])\n        if hparams['optimizer'] == 'rmsprop':\n            return tf.keras.optimizers.RMSprop(learning_rate=hparams[\"lr\"])\n        if hparams['optimizer'] == 'adagrad':\n            return tf.keras.optimizers.Adagrad(learning_rate=hparams[\"lr\"])\n        if hparams['optimizer'] == 'adadelta':\n            return tf.keras.optimizers.Adadelta(learning_rate=hparams[\"lr\"])\n\n        return tf.keras.optimizers.Adam(learning_rate=hparams[\"lr\"])\n\n    def get_cosine_schedule_with_warmup(\n        self,\n        lr = 0.00004,\n        num_warmup_steps = 0,\n        num_cycles=0.5):\n        num_training_steps = self.EPOCHES\n        def lrfn(epoch):\n            if epoch < num_warmup_steps:\n                return (float(epoch) / float(max(5, num_warmup_steps))) * lr\n            progress = float(epoch - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n            return max(0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress))) * lr\n\n        return lrfn\n\n\nCONFIG = Config()","metadata":{"execution":{"iopub.status.busy":"2023-11-03T18:11:10.497127Z","iopub.execute_input":"2023-11-03T18:11:10.497806Z","iopub.status.idle":"2023-11-03T18:11:14.029424Z","shell.execute_reply.started":"2023-11-03T18:11:10.497780Z","shell.execute_reply":"2023-11-03T18:11:14.028243Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"CONFIG.BATCH_SIZE","metadata":{"execution":{"iopub.status.busy":"2023-11-03T18:11:14.032791Z","iopub.execute_input":"2023-11-03T18:11:14.033129Z","iopub.status.idle":"2023-11-03T18:11:14.039591Z","shell.execute_reply.started":"2023-11-03T18:11:14.033100Z","shell.execute_reply":"2023-11-03T18:11:14.038565Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"32"},"metadata":{}}]},{"cell_type":"code","source":"class Data():\n    def __init__(self):\n        self.LABELED_TFREC_FORMAT = {\n            \"image_id\": tf.io.FixedLenFeature([], tf.string),\n            \"image\": tf.io.FixedLenFeature([], tf.string),\n            'target10': tf.io.FixedLenFeature([], tf.int64),\n            'gender' : tf.io.FixedLenFeature([], tf.int64),\n            'age_interval' : tf.io.FixedLenFeature([], tf.int64),\n        }\n\n    def process_training_data(self, data_file):\n        data = tf.io.parse_single_example(data_file, self.LABELED_TFREC_FORMAT)\n        img = tf.image.decode_jpeg(data['image'], channels=1)\n        img = tf.cast(img, tf.float32) / 255.0\n        img = tf.reshape(img, [*CONFIG.IMG_TRAIN_SHAPE, 1])\n\n        age = tf.cast(data['age_interval'], tf.float32) / 10.0\n        sex = tf.cast(data['gender'], tf.float32) / 1.0\n        tab_data = [tf.cast(tfeat, dtype = tf.float32) for tfeat in [age, sex]]\n        tabular_data = tf.stack(tab_data)\n\n        target10 = tf.one_hot(data['target10'], depth=10)\n\n        return {'inp1' : img, 'inp2' : tabular_data}, {\"target10\" : target10 }\n\n    def process_testing_data(self, data_file):\n        data = tf.io.parse_single_example(data_file, self.LABELED_TFREC_FORMAT)\n        img = tf.image.decode_jpeg(data['image'], channels=1)\n        img = tf.cast(img, tf.float32) / 255.0\n        img = tf.reshape(img, [*CONFIG.IMG_TRAIN_SHAPE, 1])\n\n        age = tf.cast(data['age_interval'], tf.float32) / 10.0\n        sex = tf.cast(data['gender'], tf.float32) / 1.0\n        tab_data = [tf.cast(tfeat, dtype = tf.float32) for tfeat in [age, sex]]\n        tabular_data = tf.stack(tab_data)\n\n        target10 = tf.one_hot(data['target10'], depth=10)\n        image_id = data[\"image_id\"]\n\n        return {'inp1' : img, 'inp2' : tabular_data}, {\"target10\" : target10, \"image_id\":  data['image_id']}\n\n    def val_dataset(self):\n        ignore_order = tf.data.Options()\n        val_dataset = (\n            tf.data.TFRecordDataset(\n                CONFIG.FOLDS_DICT[\"fold_{}\".format(CONFIG.FOLD_NUMBER)][\"valfiles\"],\n                num_parallel_reads=tf.data.experimental.AUTOTUNE\n            ).with_options(\n                ignore_order\n            ).map(\n                self.process_training_data,\n                num_parallel_calls=tf.data.experimental.AUTOTUNE\n            ).batch(\n                CONFIG.BATCH_SIZE\n            ).prefetch(\n                tf.data.experimental.AUTOTUNE\n            )\n        )\n\n        return val_dataset\n\n    def train_dataset(self):\n        ignore_order = tf.data.Options()\n        ignore_order.experimental_deterministic = False\n        train_dataset = (\n            tf.data.TFRecordDataset(\n                CONFIG.FOLDS_DICT[\"fold_{}\".format(fold_number)][\"trainfiles\"],\n                num_parallel_reads=tf.data.experimental.AUTOTUNE\n            ).with_options(\n                ignore_order\n            ).map(\n                self.process_training_data,\n                num_parallel_calls=tf.data.experimental.AUTOTUNE\n            ).repeat(\n            ).shuffle(\n                CONFIG.SEED\n            ).batch(\n                CONFIG.BATCH_SIZE\n            ).prefetch(\n                tf.data.experimental.AUTOTUNE\n            )\n        )\n\n        return train_dataset\n\n    def test_dataset(self):\n        ignore_order = tf.data.Options()\n        TEST_FILES = sorted(tf.io.gfile.glob('/content/input/train*.tfrec'))[-1]\n        test_dataset = (\n            tf.data.TFRecordDataset(\n                TEST_FILES,\n                num_parallel_reads=tf.data.experimental.AUTOTUNE\n            ).with_options(\n                ignore_order\n            ).map(\n                self.process_testing_data,\n                num_parallel_calls=tf.data.experimental.AUTOTUNE\n            ).batch(\n                CONFIG.BATCH_SIZE *  4\n            ).prefetch(\n                tf.data.experimental.AUTOTUNE\n            )\n        )\n        return test_dataset\n","metadata":{"execution":{"iopub.status.busy":"2023-11-03T18:11:14.040911Z","iopub.execute_input":"2023-11-03T18:11:14.041363Z","iopub.status.idle":"2023-11-03T18:11:14.063824Z","shell.execute_reply.started":"2023-11-03T18:11:14.041335Z","shell.execute_reply":"2023-11-03T18:11:14.062807Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"class SACCLayer(tf.keras.layers.Layer):\n    def __init__(self, output_dim, **kwargs):\n        self.output_dim = output_dim\n        super(SACCLayer, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        self.kernel_1 = self.add_weight(name='weights_ECG',\n                                        shape=(input_shape[0][-1], self.output_dim),\n                                        initializer='he_normal',\n                                        trainable=True)\n        self.kernel_2 = self.add_weight(name='weights_Patient_Metadata',\n                                        shape=(input_shape[1][-1], self.output_dim),\n                                        initializer='he_normal',\n                                        trainable=True)\n        self.attention_weights1 = self.add_weight(name='attention_weights_ECG',\n                                                 shape=(self.output_dim,),\n                                                 initializer='uniform',\n                                                 trainable=True)\n        self.attention_weights2 = self.add_weight(name='attention_weights_Patient_metadata',\n                                                 shape=(self.output_dim,),\n                                                 initializer='uniform',\n                                                 trainable=True)\n        self.dense_layer = tf.keras.layers.Dense(self.output_dim, activation='relu', name='cca_dense')\n        super(SACCLayer, self).build(input_shape)\n\n    def call(self, inputs):\n        proj_1 = K.dot(inputs[0], self.kernel_1)\n        proj_2 = K.dot(inputs[1], self.kernel_2)\n\n        # Apply non-linear transformation\n        proj_1 = tf.keras.activations.relu(proj_1)\n        proj_2 = tf.keras.activations.relu(proj_2)\n\n        # Attention mechanism\n        attention_scores1 = tf.nn.softmax(self.attention_weights1)\n        attention_scores2 = tf.nn.softmax(self.attention_weights2)\n        proj_1 = attention_scores1 * proj_1\n        proj_2 = attention_scores2 * proj_2\n\n        # Non-linear fusion\n        fused_representation = tf.keras.layers.concatenate([proj_1, proj_2])\n        fused_representation = self.dense_layer(fused_representation)\n\n        return fused_representation\n\n    def compute_output_shape(self, input_shape):\n        return (input_shape[0][0], self.output_dim)\n\n\ndef depthwise_separable_conv_with_residual_block(x, filters, stride):\n    # Depthwise Convolution\n    depthwise = DepthwiseConv2D((3, 3), strides=stride, padding='same')(x)\n    depthwise = BatchNormalization()(depthwise)\n    depthwise = ReLU()(depthwise)\n\n    # Pointwise Convolution\n    pointwise = Conv2D(filters, (1, 1), strides=(1, 1), padding='same')(depthwise)\n    pointwise = BatchNormalization()(pointwise)\n    pointwise = ReLU()(pointwise)\n\n\n    return pointwise\n\n\ndef DualPathwayModel(inp1):\n    # Initial Convolution Layers\n    conv1 = Conv2D(32, (3, 3), strides=(2, 2), padding='same')(inp1)\n    conv1 = BatchNormalization()(conv1)\n    conv1 = ReLU()(conv1)\n\n#     conv2 = Conv2D(32, (5, 5), strides=(2, 2), padding='same')(inp1)\n#     conv2 = BatchNormalization()(conv2)\n#     conv2 = ReLU()(conv2)\n    \n\n#     concatenated = tf.keras.layers.concatenate([conv1, conv2])\n\n    x = depthwise_separable_conv_with_residual_block(conv1, 64, (1, 1))\n    x = depthwise_separable_conv_with_residual_block(x, 128, (2, 2))\n    x = tf.keras.layers.Dropout(0.25)(x)\n    x = depthwise_separable_conv_with_residual_block(x, 128, (2, 2))\n    x = depthwise_separable_conv_with_residual_block(x, 256, (2, 2))\n    x = tf.keras.layers.Dropout(0.25)(x)\n    x = depthwise_separable_conv_with_residual_block(x, 256, (2, 2))\n    x = depthwise_separable_conv_with_residual_block(x, 256, (2, 2)) #<--- Can be removed\n\n    return x\n\n    \ndef dpm_sacc():\n    inp1  = tf.keras.layers.Input(shape = (*CONFIG.IMG_TRAIN_SHAPE, 1), name='inp1')\n    inp2  = tf.keras.layers.Input(shape = (2,), name='inp2')\n    x1 = DualPathwayModel(inp1)\n\n    x1 = tf.keras.layers.GlobalMaxPooling2D()(x1) # AVG is not good\n    x1 = tf.keras.layers.Dropout(0.2)(x1)\n\n    x2 = tf.keras.layers.Dense(8, name='metadata_feature_dense_1', activation='relu')(inp2)\n    x2 = tf.keras.layers.concatenate([x2, inp2])\n\n    x = SACCLayer(output_dim=256)([x1, x2])\n    \n    \n    x = tf.keras.layers.Dense(128, name='combine_feature_dense_1', activation='relu')(x)\n    x = tf.keras.layers.Dense(64, name='combine_feature_dense_2', activation='relu')(x)\n    x = tf.keras.layers.Dropout(0.1)(x)\n\n    output10 = tf.keras.layers.Dense(10, activation='softmax', name='target10')(x)\n\n    model = tf.keras.models.Model(inputs = [inp1, inp2], outputs = [output10])\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-11-03T18:11:14.065544Z","iopub.execute_input":"2023-11-03T18:11:14.065838Z","iopub.status.idle":"2023-11-03T18:11:14.092591Z","shell.execute_reply.started":"2023-11-03T18:11:14.065807Z","shell.execute_reply":"2023-11-03T18:11:14.091545Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"dpm_sacc().summary()","metadata":{"execution":{"iopub.status.busy":"2023-11-03T18:11:14.093887Z","iopub.execute_input":"2023-11-03T18:11:14.094252Z","iopub.status.idle":"2023-11-03T18:11:14.932441Z","shell.execute_reply.started":"2023-11-03T18:11:14.094223Z","shell.execute_reply":"2023-11-03T18:11:14.931272Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n inp1 (InputLayer)              [(None, 128, 128, 1  0           []                               \n                                )]                                                                \n                                                                                                  \n conv2d (Conv2D)                (None, 64, 64, 32)   320         ['inp1[0][0]']                   \n                                                                                                  \n batch_normalization (BatchNorm  (None, 64, 64, 32)  128         ['conv2d[0][0]']                 \n alization)                                                                                       \n                                                                                                  \n re_lu (ReLU)                   (None, 64, 64, 32)   0           ['batch_normalization[0][0]']    \n                                                                                                  \n depthwise_conv2d (DepthwiseCon  (None, 64, 64, 32)  320         ['re_lu[0][0]']                  \n v2D)                                                                                             \n                                                                                                  \n batch_normalization_1 (BatchNo  (None, 64, 64, 32)  128         ['depthwise_conv2d[0][0]']       \n rmalization)                                                                                     \n                                                                                                  \n re_lu_1 (ReLU)                 (None, 64, 64, 32)   0           ['batch_normalization_1[0][0]']  \n                                                                                                  \n conv2d_1 (Conv2D)              (None, 64, 64, 64)   2112        ['re_lu_1[0][0]']                \n                                                                                                  \n batch_normalization_2 (BatchNo  (None, 64, 64, 64)  256         ['conv2d_1[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n re_lu_2 (ReLU)                 (None, 64, 64, 64)   0           ['batch_normalization_2[0][0]']  \n                                                                                                  \n depthwise_conv2d_1 (DepthwiseC  (None, 32, 32, 64)  640         ['re_lu_2[0][0]']                \n onv2D)                                                                                           \n                                                                                                  \n batch_normalization_3 (BatchNo  (None, 32, 32, 64)  256         ['depthwise_conv2d_1[0][0]']     \n rmalization)                                                                                     \n                                                                                                  \n re_lu_3 (ReLU)                 (None, 32, 32, 64)   0           ['batch_normalization_3[0][0]']  \n                                                                                                  \n conv2d_2 (Conv2D)              (None, 32, 32, 128)  8320        ['re_lu_3[0][0]']                \n                                                                                                  \n batch_normalization_4 (BatchNo  (None, 32, 32, 128)  512        ['conv2d_2[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n re_lu_4 (ReLU)                 (None, 32, 32, 128)  0           ['batch_normalization_4[0][0]']  \n                                                                                                  \n dropout (Dropout)              (None, 32, 32, 128)  0           ['re_lu_4[0][0]']                \n                                                                                                  \n depthwise_conv2d_2 (DepthwiseC  (None, 16, 16, 128)  1280       ['dropout[0][0]']                \n onv2D)                                                                                           \n                                                                                                  \n batch_normalization_5 (BatchNo  (None, 16, 16, 128)  512        ['depthwise_conv2d_2[0][0]']     \n rmalization)                                                                                     \n                                                                                                  \n re_lu_5 (ReLU)                 (None, 16, 16, 128)  0           ['batch_normalization_5[0][0]']  \n                                                                                                  \n conv2d_3 (Conv2D)              (None, 16, 16, 128)  16512       ['re_lu_5[0][0]']                \n                                                                                                  \n batch_normalization_6 (BatchNo  (None, 16, 16, 128)  512        ['conv2d_3[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n re_lu_6 (ReLU)                 (None, 16, 16, 128)  0           ['batch_normalization_6[0][0]']  \n                                                                                                  \n depthwise_conv2d_3 (DepthwiseC  (None, 8, 8, 128)   1280        ['re_lu_6[0][0]']                \n onv2D)                                                                                           \n                                                                                                  \n batch_normalization_7 (BatchNo  (None, 8, 8, 128)   512         ['depthwise_conv2d_3[0][0]']     \n rmalization)                                                                                     \n                                                                                                  \n re_lu_7 (ReLU)                 (None, 8, 8, 128)    0           ['batch_normalization_7[0][0]']  \n                                                                                                  \n conv2d_4 (Conv2D)              (None, 8, 8, 256)    33024       ['re_lu_7[0][0]']                \n                                                                                                  \n batch_normalization_8 (BatchNo  (None, 8, 8, 256)   1024        ['conv2d_4[0][0]']               \n rmalization)                                                                                     \n                                                                                                  \n re_lu_8 (ReLU)                 (None, 8, 8, 256)    0           ['batch_normalization_8[0][0]']  \n                                                                                                  \n dropout_1 (Dropout)            (None, 8, 8, 256)    0           ['re_lu_8[0][0]']                \n                                                                                                  \n depthwise_conv2d_4 (DepthwiseC  (None, 4, 4, 256)   2560        ['dropout_1[0][0]']              \n onv2D)                                                                                           \n                                                                                                  \n batch_normalization_9 (BatchNo  (None, 4, 4, 256)   1024        ['depthwise_conv2d_4[0][0]']     \n rmalization)                                                                                     \n                                                                                                  \n re_lu_9 (ReLU)                 (None, 4, 4, 256)    0           ['batch_normalization_9[0][0]']  \n                                                                                                  \n conv2d_5 (Conv2D)              (None, 4, 4, 256)    65792       ['re_lu_9[0][0]']                \n                                                                                                  \n batch_normalization_10 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_5[0][0]']               \n ormalization)                                                                                    \n                                                                                                  \n re_lu_10 (ReLU)                (None, 4, 4, 256)    0           ['batch_normalization_10[0][0]'] \n                                                                                                  \n depthwise_conv2d_5 (DepthwiseC  (None, 2, 2, 256)   2560        ['re_lu_10[0][0]']               \n onv2D)                                                                                           \n                                                                                                  \n batch_normalization_11 (BatchN  (None, 2, 2, 256)   1024        ['depthwise_conv2d_5[0][0]']     \n ormalization)                                                                                    \n                                                                                                  \n re_lu_11 (ReLU)                (None, 2, 2, 256)    0           ['batch_normalization_11[0][0]'] \n                                                                                                  \n conv2d_6 (Conv2D)              (None, 2, 2, 256)    65792       ['re_lu_11[0][0]']               \n                                                                                                  \n batch_normalization_12 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_6[0][0]']               \n ormalization)                                                                                    \n                                                                                                  \n re_lu_12 (ReLU)                (None, 2, 2, 256)    0           ['batch_normalization_12[0][0]'] \n                                                                                                  \n inp2 (InputLayer)              [(None, 2)]          0           []                               \n                                                                                                  \n global_max_pooling2d (GlobalMa  (None, 256)         0           ['re_lu_12[0][0]']               \n xPooling2D)                                                                                      \n                                                                                                  \n metadata_feature_dense_1 (Dens  (None, 8)           24          ['inp2[0][0]']                   \n e)                                                                                               \n                                                                                                  \n dropout_2 (Dropout)            (None, 256)          0           ['global_max_pooling2d[0][0]']   \n                                                                                                  \n concatenate (Concatenate)      (None, 10)           0           ['metadata_feature_dense_1[0][0]'\n                                                                 , 'inp2[0][0]']                  \n                                                                                                  \n sacc_layer (SACCLayer)         (None, 256)          199936      ['dropout_2[0][0]',              \n                                                                  'concatenate[0][0]']            \n                                                                                                  \n combine_feature_dense_1 (Dense  (None, 128)         32896       ['sacc_layer[0][0]']             \n )                                                                                                \n                                                                                                  \n combine_feature_dense_2 (Dense  (None, 64)          8256        ['combine_feature_dense_1[0][0]']\n )                                                                                                \n                                                                                                  \n dropout_3 (Dropout)            (None, 64)           0           ['combine_feature_dense_2[0][0]']\n                                                                                                  \n target10 (Dense)               (None, 10)           650         ['dropout_3[0][0]']              \n                                                                                                  \n==================================================================================================\nTotal params: 450,210\nTrainable params: 446,242\nNon-trainable params: 3,968\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"def fitengine(model, traindataset, valdataset = None, istraining = True):\n    model.compile(\n        optimizer   =  CONFIG.OPTIMIZER,\n        loss        =  CONFIG.LOSS,\n        metrics     =  CONFIG.ACCURACY\n    )\n\n    history = model.fit(\n                traindataset,\n                epochs            =   CONFIG.EPOCHES,\n                steps_per_epoch   =   CONFIG.TOTAL_TRAIN_IMG//CONFIG.BATCH_SIZE,\n                callbacks         =   CONFIG.CALLBACKS,\n                validation_data   =   valdataset,\n                validation_steps = (CONFIG.TOTAL_VAL_IMG)//(CONFIG.BATCH_SIZE) + 1,\n                verbose           =   1\n            )\n\n    return history\n\nskf = KFold(n_splits=CONFIG.FOLDS,shuffle=True,random_state=CONFIG.SEED)\nfor fold_number,(idxT,idxV) in enumerate(skf.split(np.arange(len(CONFIG.TRAIN_FILES)))):\n    CONFIG.FOLDS_DICT['fold_{}'.format(fold_number)] = {\n                                            \"trainfiles\" : [CONFIG.TRAIN_FILES[x] for x in idxT],\n                                            \"valfiles\"   : [CONFIG.TRAIN_FILES[x] for x in idxV]\n                                            }\n\nfold_number = CONFIG.FOLD_NUMBER\nprint(CONFIG.FOLDS_DICT['fold_{}'.format(fold_number)]['trainfiles'])\nprint(CONFIG.FOLDS_DICT['fold_{}'.format(fold_number)]['valfiles'])\n\nrun_ = wandb.init(\n    project= WB.EXPERIMENT_NAME,\n    reinit=True,\n    dir = \"/root\",\n    allow_val_change = True,\n    config = hparams\n)\n\nif CONFIG.STRATEGY is not None:\n    with CONFIG.STRATEGY.scope():\n        x2 = tf.keras.metrics.Precision(name='precision')\n        x3 = tf.keras.metrics.BinaryAccuracy(name='accuracy')\n        x4 = tf.keras.metrics.Recall(name='sensitivity')\n\n        CONFIG.ACCURACY.append(x2)\n        CONFIG.ACCURACY.append(x3)\n        CONFIG.ACCURACY.append(x4)\n\n        model = dpm_sacc()\n#         CONFIG.CALLBACKS.append(InLayerLossCallback())\nelse:\n    x2 = tf.keras.metrics.Precision(name='precision')\n    x3 = tf.keras.metrics.BinaryAccuracy(name='accuracy')\n    x4 = tf.keras.metrics.Recall(name='sensitivity')\n    x4 = tf.keras.metrics.Recall(name='sensitivity')\n\n    CONFIG.ACCURACY.append(x2)\n    CONFIG.ACCURACY.append(x3)\n    CONFIG.ACCURACY.append(x4)\n\n    model = dpm_sacc()\n\nCONFIG.CALLBACKS.append(tf.keras.callbacks.ModelCheckpoint(\n                                'model-%s.h5'%(fold_number), monitor='val_loss', verbose=1, save_best_only=True,\n                                save_weights_only=True, mode='min', save_freq='epoch'))\n\nCONFIG.CALLBACKS.append(WandbCallback(save_weights_only=True,\n                                            log_weights=True,\n                                            log_evaluation=True))\n\n\n\n\nDATA = Data()\n\nprint(\"##\"*30)\n\nhistory = fitengine(model, DATA.train_dataset(), valdataset=DATA.val_dataset()) #training model\n\nprint('##'*30)","metadata":{"execution":{"iopub.status.busy":"2023-11-03T18:11:14.934032Z","iopub.execute_input":"2023-11-03T18:11:14.934370Z","iopub.status.idle":"2023-11-03T18:54:26.197549Z","shell.execute_reply.started":"2023-11-03T18:11:14.934342Z","shell.execute_reply":"2023-11-03T18:54:26.196144Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"['/content/input/trainfile_class10_fold0_6117.tfrec', '/content/input/trainfile_class10_fold1_6116.tfrec', '/content/input/trainfile_class10_fold2_6116.tfrec', '/content/input/trainfile_class10_fold4_6116.tfrec', '/content/input/trainfile_class10_fold5_6116.tfrec', '/content/input/trainfile_class10_fold6_6116.tfrec', '/content/input/trainfile_class10_fold7_6117.tfrec', '/content/input/trainfile_class10_fold8_6116.tfrec']\n['/content/input/trainfile_class10_fold3_6116.tfrec']\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.15.12"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/root/wandb/run-20231103_181115-j38ogcs7</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/shreya-srivas02/ECG_BEAT_CLASSIFICATION_PAPER_COMMENTS/runs/j38ogcs7' target=\"_blank\">cool-salad-224</a></strong> to <a href='https://wandb.ai/shreya-srivas02/ECG_BEAT_CLASSIFICATION_PAPER_COMMENTS' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/shreya-srivas02/ECG_BEAT_CLASSIFICATION_PAPER_COMMENTS' target=\"_blank\">https://wandb.ai/shreya-srivas02/ECG_BEAT_CLASSIFICATION_PAPER_COMMENTS</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/shreya-srivas02/ECG_BEAT_CLASSIFICATION_PAPER_COMMENTS/runs/j38ogcs7' target=\"_blank\">https://wandb.ai/shreya-srivas02/ECG_BEAT_CLASSIFICATION_PAPER_COMMENTS/runs/j38ogcs7</a>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n","output_type":"stream"},{"name":"stdout","text":"############################################################\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WandbCallback is unable to log validation data. When using a generator for validation_data, you must pass validation_steps\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/40\n","output_type":"stream"},{"name":"stderr","text":"2023-11-03 18:12:21.985603: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_1/dropout_4/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"1529/1529 [==============================] - ETA: 0s - loss: 0.5118 - precision: 0.9091 - accuracy: 0.9730 - sensitivity: 0.8114\nEpoch 1: val_loss improved from inf to 3.65455, saving model to model-0.h5\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/wandb/run-20231103_181115-j38ogcs7/files/model-best)... Done. 0.0s\n","output_type":"stream"},{"name":"stdout","text":"1529/1529 [==============================] - 89s 44ms/step - loss: 0.5118 - precision: 0.9091 - accuracy: 0.9730 - sensitivity: 0.8114 - val_loss: 3.6545 - val_precision: 0.1015 - val_accuracy: 0.8764 - val_sensitivity: 0.0301 - lr: 0.0100\nEpoch 2/40\n1528/1529 [============================>.] - ETA: 0s - loss: 0.2570 - precision: 0.9400 - accuracy: 0.9865 - sensitivity: 0.9238\nEpoch 2: val_loss did not improve from 3.65455\n1529/1529 [==============================] - 59s 38ms/step - loss: 0.2570 - precision: 0.9400 - accuracy: 0.9865 - sensitivity: 0.9238 - val_loss: 5.1361 - val_precision: 0.0630 - val_accuracy: 0.8157 - val_sensitivity: 0.0608 - lr: 0.0100\nEpoch 3/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.2122 - precision: 0.9494 - accuracy: 0.9887 - sensitivity: 0.9374\nEpoch 3: val_loss improved from 3.65455 to 0.34772, saving model to model-0.h5\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/wandb/run-20231103_181115-j38ogcs7/files/model-best)... Done. 0.0s\n","output_type":"stream"},{"name":"stdout","text":"1529/1529 [==============================] - 67s 44ms/step - loss: 0.2122 - precision: 0.9494 - accuracy: 0.9887 - sensitivity: 0.9374 - val_loss: 0.3477 - val_precision: 0.9238 - val_accuracy: 0.9799 - val_sensitivity: 0.8705 - lr: 0.0099\nEpoch 4/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.1883 - precision: 0.9554 - accuracy: 0.9899 - sensitivity: 0.9435\nEpoch 4: val_loss did not improve from 0.34772\n1529/1529 [==============================] - 58s 38ms/step - loss: 0.1883 - precision: 0.9554 - accuracy: 0.9899 - sensitivity: 0.9435 - val_loss: 2.7038 - val_precision: 0.2815 - val_accuracy: 0.8627 - val_sensitivity: 0.2400 - lr: 0.0099\nEpoch 5/40\n1528/1529 [============================>.] - ETA: 0s - loss: 0.1719 - precision: 0.9587 - accuracy: 0.9906 - sensitivity: 0.9472\nEpoch 5: val_loss did not improve from 0.34772\n1529/1529 [==============================] - 58s 38ms/step - loss: 0.1719 - precision: 0.9587 - accuracy: 0.9906 - sensitivity: 0.9472 - val_loss: 0.7027 - val_precision: 0.8869 - val_accuracy: 0.9638 - val_sensitivity: 0.7309 - lr: 0.0098\nEpoch 6/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.1569 - precision: 0.9620 - accuracy: 0.9912 - sensitivity: 0.9495\nEpoch 6: val_loss did not improve from 0.34772\n1529/1529 [==============================] - 60s 39ms/step - loss: 0.1569 - precision: 0.9620 - accuracy: 0.9912 - sensitivity: 0.9495 - val_loss: 0.5009 - val_precision: 0.9051 - val_accuracy: 0.9701 - val_sensitivity: 0.7830 - lr: 0.0096\nEpoch 7/40\n1528/1529 [============================>.] - ETA: 0s - loss: 0.1420 - precision: 0.9654 - accuracy: 0.9919 - sensitivity: 0.9534\nEpoch 7: val_loss improved from 0.34772 to 0.25260, saving model to model-0.h5\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/wandb/run-20231103_181115-j38ogcs7/files/model-best)... Done. 0.0s\n","output_type":"stream"},{"name":"stdout","text":"1529/1529 [==============================] - 67s 44ms/step - loss: 0.1421 - precision: 0.9653 - accuracy: 0.9919 - sensitivity: 0.9533 - val_loss: 0.2526 - val_precision: 0.9434 - val_accuracy: 0.9863 - val_sensitivity: 0.9184 - lr: 0.0095\nEpoch 8/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.1369 - precision: 0.9658 - accuracy: 0.9922 - sensitivity: 0.9564\nEpoch 8: val_loss improved from 0.25260 to 0.11491, saving model to model-0.h5\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/wandb/run-20231103_181115-j38ogcs7/files/model-best)... Done. 0.0s\n","output_type":"stream"},{"name":"stdout","text":"1529/1529 [==============================] - 68s 44ms/step - loss: 0.1369 - precision: 0.9658 - accuracy: 0.9922 - sensitivity: 0.9564 - val_loss: 0.1149 - val_precision: 0.9708 - val_accuracy: 0.9937 - val_sensitivity: 0.9660 - lr: 0.0093\nEpoch 9/40\n1528/1529 [============================>.] - ETA: 0s - loss: 0.1292 - precision: 0.9675 - accuracy: 0.9926 - sensitivity: 0.9584\nEpoch 9: val_loss did not improve from 0.11491\n1529/1529 [==============================] - 59s 38ms/step - loss: 0.1291 - precision: 0.9675 - accuracy: 0.9926 - sensitivity: 0.9584 - val_loss: 1.4481 - val_precision: 0.7127 - val_accuracy: 0.9355 - val_sensitivity: 0.5952 - lr: 0.0090\nEpoch 10/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.1220 - precision: 0.9690 - accuracy: 0.9931 - sensitivity: 0.9619\nEpoch 10: val_loss did not improve from 0.11491\n1529/1529 [==============================] - 59s 38ms/step - loss: 0.1220 - precision: 0.9690 - accuracy: 0.9931 - sensitivity: 0.9619 - val_loss: 2.2640 - val_precision: 0.4342 - val_accuracy: 0.8888 - val_sensitivity: 0.3685 - lr: 0.0088\nEpoch 11/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.1081 - precision: 0.9716 - accuracy: 0.9937 - sensitivity: 0.9656\nEpoch 11: val_loss did not improve from 0.11491\n1529/1529 [==============================] - 59s 38ms/step - loss: 0.1081 - precision: 0.9716 - accuracy: 0.9937 - sensitivity: 0.9656 - val_loss: 2.7466 - val_precision: 0.3535 - val_accuracy: 0.8741 - val_sensitivity: 0.3121 - lr: 0.0085\nEpoch 12/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.1148 - precision: 0.9704 - accuracy: 0.9934 - sensitivity: 0.9631\nEpoch 12: val_loss improved from 0.11491 to 0.10816, saving model to model-0.h5\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/wandb/run-20231103_181115-j38ogcs7/files/model-best)... Done. 0.0s\n","output_type":"stream"},{"name":"stdout","text":"1529/1529 [==============================] - 70s 46ms/step - loss: 0.1148 - precision: 0.9704 - accuracy: 0.9934 - sensitivity: 0.9631 - val_loss: 0.1082 - val_precision: 0.9726 - val_accuracy: 0.9940 - val_sensitivity: 0.9675 - lr: 0.0082\nEpoch 13/40\n1528/1529 [============================>.] - ETA: 0s - loss: 0.1044 - precision: 0.9733 - accuracy: 0.9941 - sensitivity: 0.9673\nEpoch 13: val_loss did not improve from 0.10816\n1529/1529 [==============================] - 58s 38ms/step - loss: 0.1045 - precision: 0.9732 - accuracy: 0.9941 - sensitivity: 0.9672 - val_loss: 0.6240 - val_precision: 0.8578 - val_accuracy: 0.9620 - val_sensitivity: 0.7436 - lr: 0.0079\nEpoch 14/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.1014 - precision: 0.9735 - accuracy: 0.9942 - sensitivity: 0.9679\nEpoch 14: val_loss did not improve from 0.10816\n1529/1529 [==============================] - 62s 40ms/step - loss: 0.1014 - precision: 0.9735 - accuracy: 0.9942 - sensitivity: 0.9679 - val_loss: 0.6116 - val_precision: 0.8735 - val_accuracy: 0.9655 - val_sensitivity: 0.7664 - lr: 0.0076\nEpoch 15/40\n1528/1529 [============================>.] - ETA: 0s - loss: 0.0908 - precision: 0.9760 - accuracy: 0.9947 - sensitivity: 0.9704\nEpoch 15: val_loss did not improve from 0.10816\n1529/1529 [==============================] - 59s 39ms/step - loss: 0.0909 - precision: 0.9759 - accuracy: 0.9946 - sensitivity: 0.9704 - val_loss: 0.2415 - val_precision: 0.9449 - val_accuracy: 0.9867 - val_sensitivity: 0.9202 - lr: 0.0073\nEpoch 16/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.0891 - precision: 0.9767 - accuracy: 0.9948 - sensitivity: 0.9715\nEpoch 16: val_loss did not improve from 0.10816\n1529/1529 [==============================] - 58s 38ms/step - loss: 0.0891 - precision: 0.9767 - accuracy: 0.9948 - sensitivity: 0.9715 - val_loss: 0.1148 - val_precision: 0.9715 - val_accuracy: 0.9942 - val_sensitivity: 0.9702 - lr: 0.0069\nEpoch 17/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.0869 - precision: 0.9772 - accuracy: 0.9950 - sensitivity: 0.9723\nEpoch 17: val_loss improved from 0.10816 to 0.10780, saving model to model-0.h5\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/wandb/run-20231103_181115-j38ogcs7/files/model-best)... Done. 0.0s\n","output_type":"stream"},{"name":"stdout","text":"1529/1529 [==============================] - 66s 43ms/step - loss: 0.0869 - precision: 0.9772 - accuracy: 0.9950 - sensitivity: 0.9723 - val_loss: 0.1078 - val_precision: 0.9718 - val_accuracy: 0.9937 - val_sensitivity: 0.9652 - lr: 0.0065\nEpoch 18/40\n1528/1529 [============================>.] - ETA: 0s - loss: 0.0799 - precision: 0.9791 - accuracy: 0.9955 - sensitivity: 0.9753\nEpoch 18: val_loss did not improve from 0.10780\n1529/1529 [==============================] - 60s 39ms/step - loss: 0.0799 - precision: 0.9791 - accuracy: 0.9955 - sensitivity: 0.9753 - val_loss: 1.2214 - val_precision: 0.7085 - val_accuracy: 0.9362 - val_sensitivity: 0.6143 - lr: 0.0062\nEpoch 19/40\n1528/1529 [============================>.] - ETA: 0s - loss: 0.0752 - precision: 0.9802 - accuracy: 0.9957 - sensitivity: 0.9766\nEpoch 19: val_loss did not improve from 0.10780\n1529/1529 [==============================] - 59s 39ms/step - loss: 0.0752 - precision: 0.9802 - accuracy: 0.9957 - sensitivity: 0.9766 - val_loss: 0.1215 - val_precision: 0.9715 - val_accuracy: 0.9937 - val_sensitivity: 0.9648 - lr: 0.0058\nEpoch 20/40\n1528/1529 [============================>.] - ETA: 0s - loss: 0.0711 - precision: 0.9812 - accuracy: 0.9959 - sensitivity: 0.9776\nEpoch 20: val_loss did not improve from 0.10780\n1529/1529 [==============================] - 59s 39ms/step - loss: 0.0711 - precision: 0.9813 - accuracy: 0.9959 - sensitivity: 0.9777 - val_loss: 0.3281 - val_precision: 0.9337 - val_accuracy: 0.9832 - val_sensitivity: 0.8958 - lr: 0.0054\nEpoch 21/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.0663 - precision: 0.9828 - accuracy: 0.9963 - sensitivity: 0.9800\nEpoch 21: val_loss did not improve from 0.10780\n1529/1529 [==============================] - 58s 38ms/step - loss: 0.0663 - precision: 0.9828 - accuracy: 0.9963 - sensitivity: 0.9800 - val_loss: 0.1828 - val_precision: 0.9557 - val_accuracy: 0.9898 - val_sensitivity: 0.9415 - lr: 0.0050\nEpoch 22/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.0623 - precision: 0.9835 - accuracy: 0.9964 - sensitivity: 0.9809\nEpoch 22: val_loss improved from 0.10780 to 0.10488, saving model to model-0.h5\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/wandb/run-20231103_181115-j38ogcs7/files/model-best)... Done. 0.0s\n","output_type":"stream"},{"name":"stdout","text":"1529/1529 [==============================] - 67s 44ms/step - loss: 0.0623 - precision: 0.9835 - accuracy: 0.9964 - sensitivity: 0.9809 - val_loss: 0.1049 - val_precision: 0.9720 - val_accuracy: 0.9939 - val_sensitivity: 0.9663 - lr: 0.0046\nEpoch 23/40\n1528/1529 [============================>.] - ETA: 0s - loss: 0.0603 - precision: 0.9837 - accuracy: 0.9965 - sensitivity: 0.9811\nEpoch 23: val_loss improved from 0.10488 to 0.08754, saving model to model-0.h5\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/wandb/run-20231103_181115-j38ogcs7/files/model-best)... Done. 0.0s\n","output_type":"stream"},{"name":"stdout","text":"1529/1529 [==============================] - 68s 44ms/step - loss: 0.0603 - precision: 0.9837 - accuracy: 0.9965 - sensitivity: 0.9811 - val_loss: 0.0875 - val_precision: 0.9800 - val_accuracy: 0.9958 - val_sensitivity: 0.9784 - lr: 0.0042\nEpoch 24/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.0556 - precision: 0.9847 - accuracy: 0.9967 - sensitivity: 0.9823\nEpoch 24: val_loss did not improve from 0.08754\n1529/1529 [==============================] - 58s 38ms/step - loss: 0.0556 - precision: 0.9847 - accuracy: 0.9967 - sensitivity: 0.9823 - val_loss: 0.6523 - val_precision: 0.8342 - val_accuracy: 0.9609 - val_sensitivity: 0.7601 - lr: 0.0038\nEpoch 25/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.0525 - precision: 0.9856 - accuracy: 0.9970 - sensitivity: 0.9840\nEpoch 25: val_loss did not improve from 0.08754\n1529/1529 [==============================] - 61s 40ms/step - loss: 0.0525 - precision: 0.9856 - accuracy: 0.9970 - sensitivity: 0.9840 - val_loss: 0.8141 - val_precision: 0.8333 - val_accuracy: 0.9641 - val_sensitivity: 0.8009 - lr: 0.0035\nEpoch 26/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.0487 - precision: 0.9870 - accuracy: 0.9972 - sensitivity: 0.9847\nEpoch 26: val_loss improved from 0.08754 to 0.08480, saving model to model-0.h5\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/wandb/run-20231103_181115-j38ogcs7/files/model-best)... Done. 0.0s\n","output_type":"stream"},{"name":"stdout","text":"1529/1529 [==============================] - 69s 45ms/step - loss: 0.0487 - precision: 0.9870 - accuracy: 0.9972 - sensitivity: 0.9847 - val_loss: 0.0848 - val_precision: 0.9807 - val_accuracy: 0.9961 - val_sensitivity: 0.9799 - lr: 0.0031\nEpoch 27/40\n1528/1529 [============================>.] - ETA: 0s - loss: 0.0445 - precision: 0.9870 - accuracy: 0.9972 - sensitivity: 0.9847\nEpoch 27: val_loss did not improve from 0.08480\n1529/1529 [==============================] - 62s 40ms/step - loss: 0.0445 - precision: 0.9870 - accuracy: 0.9972 - sensitivity: 0.9848 - val_loss: 0.0901 - val_precision: 0.9817 - val_accuracy: 0.9963 - val_sensitivity: 0.9810 - lr: 0.0027\nEpoch 28/40\n1528/1529 [============================>.] - ETA: 0s - loss: 0.0449 - precision: 0.9872 - accuracy: 0.9973 - sensitivity: 0.9856\nEpoch 28: val_loss improved from 0.08480 to 0.08242, saving model to model-0.h5\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/wandb/run-20231103_181115-j38ogcs7/files/model-best)... Done. 0.0s\n","output_type":"stream"},{"name":"stdout","text":"1529/1529 [==============================] - 67s 44ms/step - loss: 0.0449 - precision: 0.9872 - accuracy: 0.9973 - sensitivity: 0.9856 - val_loss: 0.0824 - val_precision: 0.9825 - val_accuracy: 0.9963 - val_sensitivity: 0.9801 - lr: 0.0024\nEpoch 29/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.0427 - precision: 0.9886 - accuracy: 0.9975 - sensitivity: 0.9864\nEpoch 29: val_loss did not improve from 0.08242\n1529/1529 [==============================] - 59s 39ms/step - loss: 0.0427 - precision: 0.9886 - accuracy: 0.9975 - sensitivity: 0.9864 - val_loss: 0.0948 - val_precision: 0.9792 - val_accuracy: 0.9956 - val_sensitivity: 0.9763 - lr: 0.0021\nEpoch 30/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.0399 - precision: 0.9889 - accuracy: 0.9976 - sensitivity: 0.9870\nEpoch 30: val_loss did not improve from 0.08242\n1529/1529 [==============================] - 59s 39ms/step - loss: 0.0399 - precision: 0.9889 - accuracy: 0.9976 - sensitivity: 0.9870 - val_loss: 0.0865 - val_precision: 0.9834 - val_accuracy: 0.9965 - val_sensitivity: 0.9812 - lr: 0.0018\nEpoch 31/40\n1528/1529 [============================>.] - ETA: 0s - loss: 0.0369 - precision: 0.9897 - accuracy: 0.9978 - sensitivity: 0.9882\nEpoch 31: val_loss improved from 0.08242 to 0.08097, saving model to model-0.h5\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/wandb/run-20231103_181115-j38ogcs7/files/model-best)... Done. 0.0s\n","output_type":"stream"},{"name":"stdout","text":"1529/1529 [==============================] - 70s 46ms/step - loss: 0.0369 - precision: 0.9897 - accuracy: 0.9978 - sensitivity: 0.9882 - val_loss: 0.0810 - val_precision: 0.9838 - val_accuracy: 0.9966 - val_sensitivity: 0.9822 - lr: 0.0015\nEpoch 32/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.0332 - precision: 0.9905 - accuracy: 0.9979 - sensitivity: 0.9889\nEpoch 32: val_loss did not improve from 0.08097\n1529/1529 [==============================] - 59s 38ms/step - loss: 0.0332 - precision: 0.9905 - accuracy: 0.9979 - sensitivity: 0.9889 - val_loss: 0.0828 - val_precision: 0.9831 - val_accuracy: 0.9965 - val_sensitivity: 0.9819 - lr: 0.0012\nEpoch 33/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.0340 - precision: 0.9903 - accuracy: 0.9979 - sensitivity: 0.9888\nEpoch 33: val_loss did not improve from 0.08097\n1529/1529 [==============================] - 61s 40ms/step - loss: 0.0340 - precision: 0.9903 - accuracy: 0.9979 - sensitivity: 0.9888 - val_loss: 0.0839 - val_precision: 0.9817 - val_accuracy: 0.9963 - val_sensitivity: 0.9812 - lr: 9.5492e-04\nEpoch 34/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.0334 - precision: 0.9903 - accuracy: 0.9979 - sensitivity: 0.9889\nEpoch 34: val_loss did not improve from 0.08097\n1529/1529 [==============================] - 61s 40ms/step - loss: 0.0334 - precision: 0.9903 - accuracy: 0.9979 - sensitivity: 0.9889 - val_loss: 0.0842 - val_precision: 0.9825 - val_accuracy: 0.9963 - val_sensitivity: 0.9807 - lr: 7.3680e-04\nEpoch 35/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.0319 - precision: 0.9911 - accuracy: 0.9981 - sensitivity: 0.9894\nEpoch 35: val_loss did not improve from 0.08097\n1529/1529 [==============================] - 59s 39ms/step - loss: 0.0319 - precision: 0.9911 - accuracy: 0.9981 - sensitivity: 0.9894 - val_loss: 0.0820 - val_precision: 0.9823 - val_accuracy: 0.9964 - val_sensitivity: 0.9814 - lr: 5.4497e-04\nEpoch 36/40\n1528/1529 [============================>.] - ETA: 0s - loss: 0.0307 - precision: 0.9907 - accuracy: 0.9980 - sensitivity: 0.9892\nEpoch 36: val_loss improved from 0.08097 to 0.08022, saving model to model-0.h5\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/wandb/run-20231103_181115-j38ogcs7/files/model-best)... Done. 0.0s\n","output_type":"stream"},{"name":"stdout","text":"1529/1529 [==============================] - 71s 46ms/step - loss: 0.0307 - precision: 0.9907 - accuracy: 0.9980 - sensitivity: 0.9892 - val_loss: 0.0802 - val_precision: 0.9823 - val_accuracy: 0.9963 - val_sensitivity: 0.9810 - lr: 3.8060e-04\nEpoch 37/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.0300 - precision: 0.9913 - accuracy: 0.9981 - sensitivity: 0.9899\nEpoch 37: val_loss improved from 0.08022 to 0.07895, saving model to model-0.h5\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/wandb/run-20231103_181115-j38ogcs7/files/model-best)... Done. 0.0s\n","output_type":"stream"},{"name":"stdout","text":"1529/1529 [==============================] - 71s 46ms/step - loss: 0.0300 - precision: 0.9913 - accuracy: 0.9981 - sensitivity: 0.9899 - val_loss: 0.0789 - val_precision: 0.9831 - val_accuracy: 0.9965 - val_sensitivity: 0.9817 - lr: 2.4472e-04\nEpoch 38/40\n1529/1529 [==============================] - ETA: 0s - loss: 0.0287 - precision: 0.9915 - accuracy: 0.9982 - sensitivity: 0.9904\nEpoch 38: val_loss improved from 0.07895 to 0.07874, saving model to model-0.h5\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/wandb/run-20231103_181115-j38ogcs7/files/model-best)... Done. 0.0s\n","output_type":"stream"},{"name":"stdout","text":"1529/1529 [==============================] - 69s 45ms/step - loss: 0.0287 - precision: 0.9915 - accuracy: 0.9982 - sensitivity: 0.9904 - val_loss: 0.0787 - val_precision: 0.9836 - val_accuracy: 0.9966 - val_sensitivity: 0.9823 - lr: 1.3815e-04\nEpoch 39/40\n1528/1529 [============================>.] - ETA: 0s - loss: 0.0266 - precision: 0.9921 - accuracy: 0.9983 - sensitivity: 0.9909\nEpoch 39: val_loss did not improve from 0.07874\n1529/1529 [==============================] - 59s 38ms/step - loss: 0.0266 - precision: 0.9921 - accuracy: 0.9983 - sensitivity: 0.9909 - val_loss: 0.0789 - val_precision: 0.9831 - val_accuracy: 0.9965 - val_sensitivity: 0.9819 - lr: 6.1558e-05\nEpoch 40/40\n1528/1529 [============================>.] - ETA: 0s - loss: 0.0288 - precision: 0.9913 - accuracy: 0.9981 - sensitivity: 0.9901\nEpoch 40: val_loss improved from 0.07874 to 0.07869, saving model to model-0.h5\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/root/wandb/run-20231103_181115-j38ogcs7/files/model-best)... Done. 0.0s\n","output_type":"stream"},{"name":"stdout","text":"1529/1529 [==============================] - 68s 45ms/step - loss: 0.0288 - precision: 0.9913 - accuracy: 0.9981 - sensitivity: 0.9901 - val_loss: 0.0787 - val_precision: 0.9831 - val_accuracy: 0.9965 - val_sensitivity: 0.9822 - lr: 1.5413e-05\n############################################################\n","output_type":"stream"}]},{"cell_type":"code","source":"model.save('model_last_epoch.h5')\nmodel_till_last_epoch = model\nSAVED_MODEL_LOC = \"model-0.h5\"\nmodel = dpm_sacc()\nmodel.load_weights(SAVED_MODEL_LOC)","metadata":{"execution":{"iopub.status.busy":"2023-11-03T18:54:26.198972Z","iopub.execute_input":"2023-11-03T18:54:26.199314Z","iopub.status.idle":"2023-11-03T18:54:26.986847Z","shell.execute_reply.started":"2023-11-03T18:54:26.199285Z","shell.execute_reply":"2023-11-03T18:54:26.985534Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"NAME = ['/', \"A\",  'F', 'L', 'N', 'R', 'V', 'a', 'f', 'j']\nfor model_type, trained_model in zip(['best_epoch', 'last_epoch'], [model, model_till_last_epoch]):\n    test_imgs = DATA.test_dataset().map(lambda data, ids: data)\n    img_labels_ds = DATA.test_dataset().map(lambda data, ids: ids).unbatch()\n\n    STEPS = (CONFIG.TOTAL_TEST_IMG)//(CONFIG.BATCH_SIZE*4) + 1\n\n    y_pred = trained_model.predict(test_imgs,steps = int(STEPS), verbose=1)\n    test_labels = next(iter(img_labels_ds.batch(int(CONFIG.TOTAL_TEST_IMG) + 1)))\n    y_true = test_labels[\"target10\"].numpy()\n    pd.DataFrame({\n            'image_id'  : test_labels[\"image_id\"].numpy(),\n            'actual'  : np.argmax(y_true, axis=1),\n            'predicted'      : np.argmax(y_pred, axis=1)\n            }).to_csv('prediction_{}.csv'.format(model_type), index=False)\n\n    df = pd.read_csv(\"prediction_{}.csv\".format(model_type))\n\n    run_.log({f\"{model_type}_pr\": wandb.plot.pr_curve(np.argmax(y_true, axis=1), y_pred, labels=NAME)})\n    run_.log({f\"{model_type}_roc\": wandb.plot.roc_curve(np.argmax(y_true, axis=1), y_pred, labels=NAME)})\n\n    cm = wandb.plot.confusion_matrix(\n                    y_true=np.argmax(y_true, axis=1),\n                    preds=np.argmax(y_pred, axis=1),\n                    class_names=NAME)\n\n    run_.log({f\"{model_type}_conf_mat\": cm})\n\n    harvest = confusion_matrix(df['actual'], df['predicted'])\n    fig, ax = plt.subplots(figsize=(8,8))\n    im = ax.imshow(harvest)\n    ax.set_xticks(np.arange(len(NAME)))\n    ax.set_yticks(np.arange(len(NAME)))\n    ax.set_xticklabels(NAME)\n    ax.set_yticklabels(NAME)\n\n    # Rotate the tick labels and set their alignment.\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n            rotation_mode=\"anchor\")\n\n    for i in range(len(NAME)):\n        for j in range(len(NAME)):\n            text = ax.text(j, i, harvest[i, j],\n                        ha=\"center\", va=\"center\", color=\"w\")\n\n    fig.tight_layout()\n    run_.log({f\"{model_type}_cm\": plt})\n\n    from sklearn.metrics import classification_report\n    target_names = NAME\n    x_ = classification_report(df['actual'], df['predicted'], target_names=target_names, digits=4)\n    x2 = classification_report(df['actual'], df['predicted'], target_names=target_names, digits=4, output_dict=True)\n    print(x_)\n    run_.log({f\"{model_type}_CR\": x2})\n\n\n## log more\nartifact = wandb.Artifact(\"Full_Logs\", type=\"logs\")\nartifact.add_dir(\"/kaggle/working/\")\nwandb.log_artifact(artifact)","metadata":{"execution":{"iopub.status.busy":"2023-11-03T18:54:26.988309Z","iopub.execute_input":"2023-11-03T18:54:26.988677Z","iopub.status.idle":"2023-11-03T18:54:35.129507Z","shell.execute_reply.started":"2023-11-03T18:54:26.988640Z","shell.execute_reply":"2023-11-03T18:54:35.128240Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"48/48 [==============================] - 1s 14ms/step\n              precision    recall  f1-score   support\n\n           /     0.9974    0.9974    0.9974       382\n           A     0.9258    0.8653    0.8945       245\n           F     0.8904    0.8553    0.8725        76\n           L     0.9988    0.9988    0.9988       801\n           N     0.9826    0.9911    0.9868      3252\n           R     0.9932    0.9915    0.9923       586\n           V     0.9663    0.9649    0.9656       713\n           a     0.7500    0.5455    0.6316        11\n           f     1.0000    0.9524    0.9756        21\n           j     0.7692    0.6897    0.7273        29\n\n    accuracy                         0.9804      6116\n   macro avg     0.9274    0.8852    0.9042      6116\nweighted avg     0.9800    0.9804    0.9801      6116\n\n48/48 [==============================] - 1s 13ms/step\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/kaggle/working)... Done. 0.0s\n","output_type":"stream"},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           /     0.9974    0.9974    0.9974       382\n           A     0.9258    0.8653    0.8945       245\n           F     0.8904    0.8553    0.8725        76\n           L     0.9988    0.9988    0.9988       801\n           N     0.9826    0.9911    0.9868      3252\n           R     0.9932    0.9915    0.9923       586\n           V     0.9663    0.9649    0.9656       713\n           a     0.7500    0.5455    0.6316        11\n           f     1.0000    0.9524    0.9756        21\n           j     0.7692    0.6897    0.7273        29\n\n    accuracy                         0.9804      6116\n   macro avg     0.9274    0.8852    0.9042      6116\nweighted avg     0.9800    0.9804    0.9801      6116\n\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"<Artifact Full_Logs>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 800x800 with 1 Axes>","image/png":"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"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 800x800 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.python.framework.convert_to_constants import  convert_variables_to_constants_v2_as_graph\n\n\ndef get_flops(model):\n    concrete = tf.function(lambda inputs: model(inputs))\n    concrete_func = concrete.get_concrete_function(\n        [tf.TensorSpec([1, *inputs.shape[1:]]) for inputs in model.inputs])\n    frozen_func, graph_def = convert_variables_to_constants_v2_as_graph(concrete_func)\n    with tf.Graph().as_default() as graph:\n        tf.graph_util.import_graph_def(graph_def, name='')\n        run_meta = tf.compat.v1.RunMetadata()\n        opts = tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()\n        flops = tf.compat.v1.profiler.profile(graph=graph, run_meta=run_meta, cmd=\"op\", options=opts)\n        return flops.total_float_ops\n\nmodel = dpm_sacc()\n\nprint(\"The FLOPs is:{}\".format(get_flops(model)) ,flush=True )\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-03T18:54:35.130984Z","iopub.execute_input":"2023-11-03T18:54:35.131779Z","iopub.status.idle":"2023-11-03T18:54:36.213850Z","shell.execute_reply.started":"2023-11-03T18:54:35.131729Z","shell.execute_reply":"2023-11-03T18:54:36.212569Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"\n=========================Options=============================\n-max_depth                  10000\n-min_bytes                  0\n-min_peak_bytes             0\n-min_residual_bytes         0\n-min_output_bytes           0\n-min_micros                 0\n-min_accelerator_micros     0\n-min_cpu_micros             0\n-min_params                 0\n-min_float_ops              1\n-min_occurrence             0\n-step                       -1\n-order_by                   float_ops\n-account_type_regexes       .*\n-start_name_regexes         .*\n-trim_name_regexes          \n-show_name_regexes          .*\n-hide_name_regexes          \n-account_displayed_op_only  true\n-select                     float_ops\n-output                     stdout:\n\n==================Model Analysis Report======================\n\nDoc:\nop: The nodes are operation kernel type, such as MatMul, Conv2D. Graph nodes belonging to the same type are aggregated together.\nflops: Number of float operations. Note: Please read the implementation for the math behind it.\n\nProfile:\nnode name | # float_ops\nConv2D                   51.12m float_ops (100.00%, 90.01%)\nDepthwiseConv2dNative    4.37m float_ops (9.99%, 7.69%)\nBiasAdd                  821.71k float_ops (2.30%, 1.45%)\nMatMul                   481.57k float_ops (0.85%, 0.85%)\nSoftmax                  2.61k float_ops (0.01%, 0.00%)\nMul                        512 float_ops (0.00%, 0.00%)\n\n======================End of Report==========================\nThe FLOPs is:56792868\n","output_type":"stream"}]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-11-03T18:54:36.215216Z","iopub.execute_input":"2023-11-03T18:54:36.215492Z","iopub.status.idle":"2023-11-03T18:54:36.395555Z","shell.execute_reply.started":"2023-11-03T18:54:36.215468Z","shell.execute_reply":"2023-11-03T18:54:36.393928Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Model: \"model_3\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n inp1 (InputLayer)              [(None, 128, 128, 1  0           []                               \n                                )]                                                                \n                                                                                                  \n conv2d_21 (Conv2D)             (None, 64, 64, 32)   320         ['inp1[0][0]']                   \n                                                                                                  \n batch_normalization_39 (BatchN  (None, 64, 64, 32)  128         ['conv2d_21[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n re_lu_39 (ReLU)                (None, 64, 64, 32)   0           ['batch_normalization_39[0][0]'] \n                                                                                                  \n depthwise_conv2d_18 (Depthwise  (None, 64, 64, 32)  320         ['re_lu_39[0][0]']               \n Conv2D)                                                                                          \n                                                                                                  \n batch_normalization_40 (BatchN  (None, 64, 64, 32)  128         ['depthwise_conv2d_18[0][0]']    \n ormalization)                                                                                    \n                                                                                                  \n re_lu_40 (ReLU)                (None, 64, 64, 32)   0           ['batch_normalization_40[0][0]'] \n                                                                                                  \n conv2d_22 (Conv2D)             (None, 64, 64, 64)   2112        ['re_lu_40[0][0]']               \n                                                                                                  \n batch_normalization_41 (BatchN  (None, 64, 64, 64)  256         ['conv2d_22[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n re_lu_41 (ReLU)                (None, 64, 64, 64)   0           ['batch_normalization_41[0][0]'] \n                                                                                                  \n depthwise_conv2d_19 (Depthwise  (None, 32, 32, 64)  640         ['re_lu_41[0][0]']               \n Conv2D)                                                                                          \n                                                                                                  \n batch_normalization_42 (BatchN  (None, 32, 32, 64)  256         ['depthwise_conv2d_19[0][0]']    \n ormalization)                                                                                    \n                                                                                                  \n re_lu_42 (ReLU)                (None, 32, 32, 64)   0           ['batch_normalization_42[0][0]'] \n                                                                                                  \n conv2d_23 (Conv2D)             (None, 32, 32, 128)  8320        ['re_lu_42[0][0]']               \n                                                                                                  \n batch_normalization_43 (BatchN  (None, 32, 32, 128)  512        ['conv2d_23[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n re_lu_43 (ReLU)                (None, 32, 32, 128)  0           ['batch_normalization_43[0][0]'] \n                                                                                                  \n dropout_12 (Dropout)           (None, 32, 32, 128)  0           ['re_lu_43[0][0]']               \n                                                                                                  \n depthwise_conv2d_20 (Depthwise  (None, 16, 16, 128)  1280       ['dropout_12[0][0]']             \n Conv2D)                                                                                          \n                                                                                                  \n batch_normalization_44 (BatchN  (None, 16, 16, 128)  512        ['depthwise_conv2d_20[0][0]']    \n ormalization)                                                                                    \n                                                                                                  \n re_lu_44 (ReLU)                (None, 16, 16, 128)  0           ['batch_normalization_44[0][0]'] \n                                                                                                  \n conv2d_24 (Conv2D)             (None, 16, 16, 128)  16512       ['re_lu_44[0][0]']               \n                                                                                                  \n batch_normalization_45 (BatchN  (None, 16, 16, 128)  512        ['conv2d_24[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n re_lu_45 (ReLU)                (None, 16, 16, 128)  0           ['batch_normalization_45[0][0]'] \n                                                                                                  \n depthwise_conv2d_21 (Depthwise  (None, 8, 8, 128)   1280        ['re_lu_45[0][0]']               \n Conv2D)                                                                                          \n                                                                                                  \n batch_normalization_46 (BatchN  (None, 8, 8, 128)   512         ['depthwise_conv2d_21[0][0]']    \n ormalization)                                                                                    \n                                                                                                  \n re_lu_46 (ReLU)                (None, 8, 8, 128)    0           ['batch_normalization_46[0][0]'] \n                                                                                                  \n conv2d_25 (Conv2D)             (None, 8, 8, 256)    33024       ['re_lu_46[0][0]']               \n                                                                                                  \n batch_normalization_47 (BatchN  (None, 8, 8, 256)   1024        ['conv2d_25[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n re_lu_47 (ReLU)                (None, 8, 8, 256)    0           ['batch_normalization_47[0][0]'] \n                                                                                                  \n dropout_13 (Dropout)           (None, 8, 8, 256)    0           ['re_lu_47[0][0]']               \n                                                                                                  \n depthwise_conv2d_22 (Depthwise  (None, 4, 4, 256)   2560        ['dropout_13[0][0]']             \n Conv2D)                                                                                          \n                                                                                                  \n batch_normalization_48 (BatchN  (None, 4, 4, 256)   1024        ['depthwise_conv2d_22[0][0]']    \n ormalization)                                                                                    \n                                                                                                  \n re_lu_48 (ReLU)                (None, 4, 4, 256)    0           ['batch_normalization_48[0][0]'] \n                                                                                                  \n conv2d_26 (Conv2D)             (None, 4, 4, 256)    65792       ['re_lu_48[0][0]']               \n                                                                                                  \n batch_normalization_49 (BatchN  (None, 4, 4, 256)   1024        ['conv2d_26[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n re_lu_49 (ReLU)                (None, 4, 4, 256)    0           ['batch_normalization_49[0][0]'] \n                                                                                                  \n depthwise_conv2d_23 (Depthwise  (None, 2, 2, 256)   2560        ['re_lu_49[0][0]']               \n Conv2D)                                                                                          \n                                                                                                  \n batch_normalization_50 (BatchN  (None, 2, 2, 256)   1024        ['depthwise_conv2d_23[0][0]']    \n ormalization)                                                                                    \n                                                                                                  \n re_lu_50 (ReLU)                (None, 2, 2, 256)    0           ['batch_normalization_50[0][0]'] \n                                                                                                  \n conv2d_27 (Conv2D)             (None, 2, 2, 256)    65792       ['re_lu_50[0][0]']               \n                                                                                                  \n batch_normalization_51 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_27[0][0]']              \n ormalization)                                                                                    \n                                                                                                  \n re_lu_51 (ReLU)                (None, 2, 2, 256)    0           ['batch_normalization_51[0][0]'] \n                                                                                                  \n inp2 (InputLayer)              [(None, 2)]          0           []                               \n                                                                                                  \n global_max_pooling2d_3 (Global  (None, 256)         0           ['re_lu_51[0][0]']               \n MaxPooling2D)                                                                                    \n                                                                                                  \n metadata_feature_dense_1 (Dens  (None, 8)           24          ['inp2[0][0]']                   \n e)                                                                                               \n                                                                                                  \n dropout_14 (Dropout)           (None, 256)          0           ['global_max_pooling2d_3[0][0]'] \n                                                                                                  \n concatenate_3 (Concatenate)    (None, 10)           0           ['metadata_feature_dense_1[0][0]'\n                                                                 , 'inp2[0][0]']                  \n                                                                                                  \n sacc_layer_3 (SACCLayer)       (None, 256)          199936      ['dropout_14[0][0]',             \n                                                                  'concatenate_3[0][0]']          \n                                                                                                  \n combine_feature_dense_1 (Dense  (None, 128)         32896       ['sacc_layer_3[0][0]']           \n )                                                                                                \n                                                                                                  \n combine_feature_dense_2 (Dense  (None, 64)          8256        ['combine_feature_dense_1[0][0]']\n )                                                                                                \n                                                                                                  \n dropout_15 (Dropout)           (None, 64)           0           ['combine_feature_dense_2[0][0]']\n                                                                                                  \n target10 (Dense)               (None, 10)           650         ['dropout_15[0][0]']             \n                                                                                                  \n==================================================================================================\nTotal params: 450,210\nTrainable params: 446,242\nNon-trainable params: 3,968\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"tf.keras.utils.plot_model(\n    dpm_sacc(),\n    to_file='model.png',\n    show_shapes=True,\n    show_dtype=False,\n    show_layer_names=False,\n    rankdir='TB',\n    expand_nested=False,\n    dpi=96,\n    layer_range=None,\n    show_layer_activations=True,\n    show_trainable=True\n)\n\nrun_.finish()","metadata":{"execution":{"iopub.status.busy":"2023-11-03T18:54:36.397054Z","iopub.execute_input":"2023-11-03T18:54:36.397493Z","iopub.status.idle":"2023-11-03T18:54:43.092776Z","shell.execute_reply.started":"2023-11-03T18:54:36.397454Z","shell.execute_reply":"2023-11-03T18:54:43.091853Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='108.546 MB of 108.546 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0,…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6941d98de7e46afbc3706352cd0b09e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████████</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr</td><td>███████▇▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>precision</td><td>▁▄▄▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇███████████████</td></tr><tr><td>sensitivity</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████████████</td></tr><tr><td>val_accuracy</td><td>▃▁▇▃▇▇██▆▄▃█▇▇███▆█▇███▇▇███████████████</td></tr><tr><td>val_loss</td><td>▆█▁▅▂▂▁▁▃▄▅▁▂▂▁▁▁▃▁▁▁▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_precision</td><td>▁▁█▃▇▇██▆▄▃█▇▇███▆█████▇▇███████████████</td></tr><tr><td>val_sensitivity</td><td>▁▁▇▃▆▇██▅▃▃█▆▆███▅█▇███▆▇███████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.99814</td></tr><tr><td>best_epoch</td><td>39</td></tr><tr><td>best_val_loss</td><td>0.07869</td></tr><tr><td>epoch</td><td>39</td></tr><tr><td>loss</td><td>0.02882</td></tr><tr><td>lr</td><td>2e-05</td></tr><tr><td>precision</td><td>0.99132</td></tr><tr><td>sensitivity</td><td>0.99007</td></tr><tr><td>val_accuracy</td><td>0.99653</td></tr><tr><td>val_loss</td><td>0.07869</td></tr><tr><td>val_precision</td><td>0.98314</td></tr><tr><td>val_sensitivity</td><td>0.98218</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">cool-salad-224</strong> at: <a href='https://wandb.ai/shreya-srivas02/ECG_BEAT_CLASSIFICATION_PAPER_COMMENTS/runs/j38ogcs7' target=\"_blank\">https://wandb.ai/shreya-srivas02/ECG_BEAT_CLASSIFICATION_PAPER_COMMENTS/runs/j38ogcs7</a><br/>Synced 6 W&B file(s), 9 media file(s), 85 artifact file(s) and 1 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>/root/wandb/run-20231103_181115-j38ogcs7/logs</code>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}